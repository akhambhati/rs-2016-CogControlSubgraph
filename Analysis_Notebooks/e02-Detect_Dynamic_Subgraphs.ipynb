{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Optimize-Dynamic-Subgraphs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Optimize Dynamic Subgraphs</a></div><div class=\"lev2\"><a href=\"#Initialize-Environment-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev2\"><a href=\"#Generate-List-of-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Generate List of Data</a></div><div class=\"lev2\"><a href=\"#Construct-Configuration-Matrices-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Construct Configuration Matrices</a></div><div class=\"lev2\"><a href=\"#Parameter-Search-Space-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Parameter Search Space</a></div><div class=\"lev2\"><a href=\"#Run-Non-Negative-Matrix-Factorization-Algorithm-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Run Non-Negative Matrix Factorization Algorithm</a></div><div class=\"lev2\"><a href=\"#Analyze-Parameter-Search-Space-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Analyze Parameter Search Space</a></div><div class=\"lev3\"><a href=\"#Display-Parameter-Search-Space-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Display Parameter Search Space</a></div><div class=\"lev3\"><a href=\"#Display-Relationship-Between-Parameters-and-Quality-Measures-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>Display Relationship Between Parameters and Quality Measures</a></div><div class=\"lev3\"><a href=\"#Display-Bivariate-Distribution-of-Error-and-Sparsity-1.6.3\"><span class=\"toc-item-num\">1.6.3&nbsp;&nbsp;</span>Display Bivariate Distribution of Error and Sparsity</a></div><div class=\"lev3\"><a href=\"#Find-Optimal-Parameters-1.6.4\"><span class=\"toc-item-num\">1.6.4&nbsp;&nbsp;</span>Find Optimal Parameters</a></div><div class=\"lev3\"><a href=\"#Plot-closest-optimization-example-1.6.5\"><span class=\"toc-item-num\">1.6.5&nbsp;&nbsp;</span>Plot closest optimization example</a></div><div class=\"lev1\"><a href=\"#Detect-Dynamic-Subgraphs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Detect Dynamic Subgraphs</a></div><div class=\"lev2\"><a href=\"#Initialize-Environment-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev2\"><a href=\"#Run-Non-Negative-Matrix-Factorization-Algorithm-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Run Non-Negative Matrix Factorization Algorithm</a></div><div class=\"lev2\"><a href=\"#Consensus-NMF-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Consensus NMF</a></div><div class=\"lev2\"><a href=\"#Consensus-Subgraphs-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Consensus Subgraphs</a></div><div class=\"lev2\"><a href=\"#Subgraphs-of-Brain-Systems-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Subgraphs of Brain Systems</a></div><div class=\"lev3\"><a href=\"#Formulate-ROI-Dict-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Formulate ROI Dict</a></div><div class=\"lev3\"><a href=\"#Convert-ROI-Subgraphs-to-Brain-System-Subgraphs-2.5.2\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>Convert ROI Subgraphs to Brain System Subgraphs</a></div><div class=\"lev3\"><a href=\"#Plot-all-Brain-System-Subgraphs-2.5.3\"><span class=\"toc-item-num\">2.5.3&nbsp;&nbsp;</span>Plot all Brain System Subgraphs</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    \n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import fig_plotting\n",
    "rcParams = fig_plotting.update_rcparams(rcParams)\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "os.chdir('../')\n",
    "import Codebase\n",
    "conv_adj_matr_to_cfg_matr = Codebase.Networks.configuration.convert_adj_matr_to_cfg_matr\n",
    "conv_cfg_vec_to_adj_matr = Codebase.Networks.configuration.convert_conn_vec_to_adj_matr\n",
    "os.chdir('./Analysis Notebooks/')\n",
    "\n",
    "path_CoreData = '/home/akhambhati/JagHome/hoth_research/CoreData/Sync_Cog_Control-Medaglia'\n",
    "path_PeriphData = '/home/akhambhati/JagHome/hoth_research/PeriphData/ds-NMF_CogControl'\n",
    "path_InpData = path_PeriphData + '/e01-FuncNetw'\n",
    "path_ExpData = path_PeriphData + '/e02-FuncSubg'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate List of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp_fname = glob.glob('{}/*.npz'.format(path_InpData))\n",
    "\n",
    "expr_dict = {}\n",
    "for fname in inp_fname:\n",
    "    subj_id = fname.split('/')[-1].split('.')[0]\n",
    "    expr_id = fname.split('/')[-1].split('.')[1]\n",
    "    \n",
    "    try:\n",
    "        expr_dict[expr_id]['adj_files'].append(fname)\n",
    "    except:\n",
    "        expr_dict[expr_id] = {}\n",
    "        expr_dict[expr_id]['adj_files'] = []\n",
    "        expr_dict[expr_id]['adj_files'].append(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Configuration Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_ord = ['adj_rs_pos', 'adj_rs_neg',\n",
    "           'adj_lo_pos', 'adj_lo_neg',\n",
    "           'adj_hi_pos', 'adj_hi_neg']\n",
    "\n",
    "cfg_list = []\n",
    "cfg_key = []\n",
    "for expr_id in expr_dict.keys():    \n",
    "    for fname in expr_dict[expr_id]['adj_files']:\n",
    "        df = np.load(fname)\n",
    "        \n",
    "        for key in key_ord:\n",
    "            cfg_matr = conv_adj_matr_to_cfg_matr(df[key])\n",
    "            for cfg_vec in cfg_matr:\n",
    "                cfg_list.append(cfg_vec)\n",
    "                cfg_key.append('{}_{}'.format(key, expr_id))\n",
    "        \n",
    "np.savez('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData),\n",
    "         cfg_matr=np.array(cfg_list),\n",
    "         cfg_key=np.array(cfg_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set search ranges\n",
    "search_alpha_log = [0.01, 2.0]\n",
    "search_beta_log = [0.01, 2.0]\n",
    "search_rank = [2, 61]\n",
    "n_search = 10000\n",
    "\n",
    "# Generate parameter set\n",
    "param_set = []\n",
    "param_alpha = np.zeros(n_search)\n",
    "param_beta = np.zeros(n_search)\n",
    "param_rank = np.zeros(n_search)\n",
    "for ii in xrange(n_search):\n",
    "    alpha = np.random.uniform(low=search_alpha_log[0],\n",
    "                              high=search_alpha_log[1])\n",
    "\n",
    "    beta = np.random.uniform(low=search_beta_log[0],\n",
    "                             high=search_beta_log[1])\n",
    "    \n",
    "    rank = np.random.randint(low=search_rank[0],\n",
    "                             high=search_rank[1])\n",
    "    \n",
    "    param_alpha[ii] = alpha\n",
    "    param_beta[ii] = beta\n",
    "    param_rank[ii] = rank\n",
    "    param_set.append({'id': ii+1,\n",
    "                      'alpha': alpha,\n",
    "                      'beta': beta,\n",
    "                      'rank': rank})\n",
    "\n",
    "    \n",
    "# Display Joint-Distributions Parameter Space\n",
    "%matplotlib inline\n",
    "g = sns.jointplot(param_alpha, param_beta, kind='kde')\n",
    "g.set_axis_labels('Alpha', 'Beta')\n",
    "\n",
    "g = sns.jointplot(param_alpha, param_rank, kind='kde')\n",
    "g.set_axis_labels('Alpha', 'Rank')\n",
    "\n",
    "g = sns.jointplot(param_beta, param_rank, kind='kde')\n",
    "g.set_axis_labels('Beta', 'Rank')\n",
    "\n",
    "np.savez('{}/NMF_Optimization.Params.npz'.format(path_ExpData), param_set=param_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Non-Negative Matrix Factorization Algorithm\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove all existing output (retains pipe/pipeline definitions)\n",
    "rm_outp = glob.glob(\"{}/NMF_Optimization.Param_*\".format(path_ExpData))\n",
    "\n",
    "for rm_type in [rm_outp]:\n",
    "    for path in rm_type:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            print(\"{} not found\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_set = np.load('{}/NMF_Optimization.Params.npz'.format(path_ExpData))['param_set']\n",
    "path_cfg_matr = glob.glob('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData))[0]\n",
    "\n",
    "proc_item = []\n",
    "for param in param_set:\n",
    "    res_path = '{}/NMF_Optimization.Param_{}.npz'.format(path_ExpData, param['id'])\n",
    "    if os.path.exists(res_path):\n",
    "        continue\n",
    "    else:\n",
    "        proc_item.append({'path_cfg_matr': path_cfg_matr,\n",
    "                          'param': param})\n",
    "print('There are {} jobs to process.'.format(len(proc_item)))\n",
    "    \n",
    "# Submit proc_item list as jobs to qsub\n",
    "job_file = open('./e02-job-NMF_Optimization', 'w')\n",
    "job_file.write('#!/bin/bash\\n\\n')\n",
    "for pitem in proc_item:    \n",
    "    stdout_path = '{}/NMF_Optimization.Param_{}.stdout'.format(path_ExpData, pitem['param']['id'])\n",
    "    stderr_path = '{}/NMF_Optimization.Param_{}.stderr'.format(path_ExpData, pitem['param']['id'])\n",
    "    \n",
    "    py_str = './pywrap-nmf_optimization {} {} {} {} {} {}'.format(\n",
    "        pitem['path_cfg_matr'], pitem['param']['id'], \n",
    "        pitem['param']['alpha'], pitem['param']['beta'],\n",
    "        pitem['param']['rank'], path_ExpData)\n",
    "\n",
    "    cmd_str = 'qsub -cwd -o {} -e {} -l h_vmem=6.1G,s_vmem=6G'.format(stdout_path, stderr_path)\n",
    "\n",
    "    job_file.write('{} {}\\n'.format(cmd_str, py_str))\n",
    "job_file.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Analyze Parameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "param_set = np.load('{}/NMF_Optimization.Params.npz'.format(path_ExpData))['param_set']\n",
    "param_run = glob.glob('{}/NMF_Optimization.Param_*.npz'.format(path_ExpData))\n",
    "n_param = len(param_run)\n",
    "\n",
    "param_alpha = np.zeros(n_param)\n",
    "param_beta = np.zeros(n_param)\n",
    "param_rank = np.zeros(n_param)\n",
    "\n",
    "err = np.zeros(n_param)\n",
    "subnet_sparsity = np.zeros(n_param)\n",
    "coef_sparsity = np.zeros(n_param)\n",
    "\n",
    "ii = 0\n",
    "for path in param_run:\n",
    "    if (ii % 500) == 0:\n",
    "        print('Processed optimization: {} of {}'.format(ii, n_param))\n",
    "    \n",
    "    try:\n",
    "        data = np.load(path, mmap_mode='r')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    p_id = int(path.split('/')[-1].split('.')[1].split('_')[1])\n",
    "    param_alpha[ii] = param_set[p_id-1]['alpha']\n",
    "    param_beta[ii] = param_set[p_id-1]['beta']\n",
    "    param_rank[ii] = param_set[p_id-1]['rank']\n",
    "\n",
    "    err[ii] = data['err'][-1]\n",
    "    subnet_sparsity[ii] = (data['fac_subnet'] == 0).mean()\n",
    "    coef_sparsity[ii] = (data['fac_coef'] == 0).mean()\n",
    "    \n",
    "    ii += 1\n",
    "    data.close()\n",
    "\n",
    "param_alpha = param_alpha[:ii]\n",
    "param_beta = param_beta[:ii]\n",
    "param_rank = param_rank[:ii]\n",
    "\n",
    "err = err[:ii]\n",
    "subnet_sparsity = subnet_sparsity[:ii]\n",
    "coef_sparsity = coef_sparsity[:ii]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Parameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(param_alpha, param_beta, param_rank, alpha=0.3)\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('Beta')\n",
    "ax.set_zlabel('Rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Relationship Between Parameters and Quality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for qmeas, qname in [(err, 'Residual Error'),\n",
    "                     (subnet_sparsity, 'Pct Subgraph Sparse'),\n",
    "                     (coef_sparsity, 'Pct Coef Sparse')]:\n",
    "    print('Plotting -- {}'.format(qname))\n",
    "    \n",
    "    g = sns.jointplot(param_rank, qmeas, kind='kde',\n",
    "                       ylim=[np.min(qmeas), np.max(qmeas)])\n",
    "    g.set_axis_labels('Rank', qname)\n",
    "\n",
    "    g = sns.jointplot((param_alpha), qmeas, kind='kde',\n",
    "                       ylim=[np.min(qmeas), np.max(qmeas)])\n",
    "    g.set_axis_labels('Alpha', qname)\n",
    "\n",
    "    g = sns.jointplot((param_beta), qmeas, kind='kde',\n",
    "                       ylim=[np.min(qmeas), np.max(qmeas)])\n",
    "    g.set_axis_labels('Beta', qname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Bivariate Distribution of Error and Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.jointplot(subnet_sparsity, err, kind='kde',\n",
    "                  xlim=[np.min(subnet_sparsity), np.max(subnet_sparsity)],\n",
    "                  ylim=[np.min(err), np.max(err)])\n",
    "g.set_axis_labels('Pct Subgraph Sparse', 'Residual Error')\n",
    "\n",
    "g = sns.jointplot(coef_sparsity, err, kind='kde',\n",
    "                  xlim=[np.min(coef_sparsity), np.max(coef_sparsity)],\n",
    "                  ylim=[np.min(err), np.max(err)])\n",
    "g.set_axis_labels('Pct Coef Sparse', 'Residual Error')\n",
    "\n",
    "g = sns.jointplot(subnet_sparsity, coef_sparsity, kind='kde',\n",
    "                  xlim=[np.min(subnet_sparsity), np.max(subnet_sparsity)],\n",
    "                  ylim=[np.min(coef_sparsity), np.max(coef_sparsity)])\n",
    "g.set_axis_labels('Pct Subgraph Sparse', 'Pct Coef Sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Optimal Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize the residual error and maximize subgraph and temporal coefficient sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify ranges\n",
    "err_range = [np.percentile(err, 0), np.percentile(err, 25)]\n",
    "subnet_sparsity_range = [np.percentile(subnet_sparsity, 75), np.percentile(subnet_sparsity, 100)]\n",
    "coef_sparsity_range = [np.percentile(coef_sparsity, 75), np.percentile(coef_sparsity, 100)]\n",
    "\n",
    "err_ix = np.flatnonzero((err >= err_range[0]) & (err <= err_range[1]))\n",
    "subnet_sparsity_ix = np.flatnonzero((subnet_sparsity >= subnet_sparsity_range[0]) &\n",
    "                                    (subnet_sparsity <= subnet_sparsity_range[1]))\n",
    "coef_sparsity_ix = np.flatnonzero((coef_sparsity >= coef_sparsity_range[0]) &\n",
    "                                    (coef_sparsity <= coef_sparsity_range[1]))\n",
    "\n",
    "param_ix = np.intersect1d(np.intersect1d(err_ix, subnet_sparsity_ix), coef_sparsity_ix)\n",
    "n_param = len(param_ix)\n",
    "\n",
    "print('Alpha: {} +/- {}'.format(np.mean(param_alpha[param_ix]),\n",
    "                                np.std(param_alpha[param_ix]) / np.sqrt(n_param)))\n",
    "print('Beta: {} +/- {}'.format(np.mean(param_beta[param_ix]),\n",
    "                               np.std(param_beta[param_ix]) / np.sqrt(n_param)))\n",
    "print('Rank: {} +/- {}'.format(np.mean(param_rank[param_ix]),\n",
    "                               np.std(param_rank[param_ix]) / np.sqrt(n_param)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot closest optimization example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find param id that is a close match to optimal\n",
    "opt_alpha = 0.95\n",
    "opt_beta = 0.90\n",
    "opt_rank = 54\n",
    "\n",
    "param_set = np.load('{}/NMF_Optimization.Params.npz'.format(path_ExpData))['param_set']\n",
    "param_rank = np.array([p['rank'] for p in param_set])\n",
    "param_beta = np.array([p['beta'] for p in param_set])\n",
    "param_alpha = np.array([p['alpha'] for p in param_set])\n",
    "\n",
    "opt_rank_ix = np.flatnonzero(param_rank == opt_rank)\n",
    "opt_beta_ix = np.argsort(np.abs(param_beta - opt_beta))[:2000]\n",
    "opt_alpha_ix = np.argsort(np.abs(param_alpha - opt_alpha))[:2000]\n",
    "\n",
    "\n",
    "opt_ix = np.intersect1d(np.intersect1d(opt_alpha_ix, opt_beta_ix), opt_rank_ix)[-1]\n",
    "print(param_rank[opt_ix],\n",
    "      param_alpha[opt_ix],\n",
    "      param_beta[opt_ix])\n",
    "\n",
    "print('Plotting All Subgraphs...')\n",
    "df = np.load('{}/NMF_Optimization.Param_{}.npz'.format(path_ExpData, opt_ix+1))\n",
    "rank = df['fac_subnet'].shape[0]\n",
    "n_col = int(np.sqrt(rank))\n",
    "n_row = int(np.ceil(rank / n_col))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(16, 12))\n",
    "for ii in xrange(opt_rank):\n",
    "    ax = plt.subplot(n_row, n_col, ii+1)\n",
    "    ax.matshow(conv_cfg_vec_to_adj_matr(df['fac_subnet'][ii, :]), cmap='rainbow')\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    \n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import fig_plotting\n",
    "rcParams = fig_plotting.update_rcparams(rcParams)\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "os.chdir('../')\n",
    "import Codebase\n",
    "conv_adj_matr_to_cfg_matr = Codebase.Networks.configuration.convert_adj_matr_to_cfg_matr\n",
    "conv_cfg_vec_to_adj_matr = Codebase.Networks.configuration.convert_conn_vec_to_adj_matr\n",
    "os.chdir('./Analysis Notebooks/')\n",
    "\n",
    "path_CoreData = '/home/akhambhati/JagHome/hoth_research/CoreData/Sync_Cog_Control-Medaglia'\n",
    "path_PeriphData = '/home/akhambhati/JagHome/hoth_research/PeriphData/ds-NMF_CogControl'\n",
    "path_InpData = path_PeriphData + '/e01-FuncNetw'\n",
    "path_ExpData = path_PeriphData + '/e02-FuncSubg'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Non-Negative Matrix Factorization Algorithm\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove all existing output (retains pipe/pipeline definitions)\n",
    "rm_outp = glob.glob(\"{}/NMF_Optimized.Seed_*\".format(path_ExpData))\n",
    "\n",
    "for rm_type in [rm_outp]:\n",
    "    for path in rm_type:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            print(\"{} not found\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Optimal Parameter Set\n",
    "opt_alpha = 0.95\n",
    "opt_beta = 0.90\n",
    "opt_rank = 54\n",
    "n_seed = 1000\n",
    "\n",
    "param_set = []\n",
    "for seed in xrange(n_seed):\n",
    "    param_set.append({'id': seed+1,\n",
    "                      'alpha': opt_alpha,\n",
    "                      'beta': opt_beta,\n",
    "                      'rank': opt_rank})\n",
    "    \n",
    "\n",
    "path_cfg_matr = glob.glob('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData))[0]\n",
    "\n",
    "proc_item = []\n",
    "for param in param_set:\n",
    "    res_path = '{}/NMF_Optimized.Seed_{}.npz'.format(path_ExpData, param['id'])\n",
    "    if os.path.exists(res_path):\n",
    "        continue\n",
    "    else:\n",
    "        proc_item.append({'path_cfg_matr': path_cfg_matr,\n",
    "                          'param': param})\n",
    "print('There are {} jobs to process.'.format(len(proc_item)))\n",
    "\n",
    "# Submit proc_item list as jobs to qsub\n",
    "job_file = open('./e02-job-NMF_Optimized', 'w')\n",
    "job_file.write('#!/bin/bash\\n\\n')\n",
    "for pitem in proc_item:    \n",
    "    stdout_path = '{}/NMF_Optimized.Seed_{}.stdout'.format(path_ExpData, pitem['param']['id'])\n",
    "    stderr_path = '{}/NMF_Optimized.Seed_{}.stderr'.format(path_ExpData, pitem['param']['id'])\n",
    "    \n",
    "    py_str = './pywrap-nmf_optimized {} {} {} {} {} {}'.format(\n",
    "        pitem['path_cfg_matr'],\n",
    "        pitem['param']['id'], pitem['param']['alpha'], pitem['param']['beta'],\n",
    "        pitem['param']['rank'], path_ExpData)\n",
    "\n",
    "    cmd_str = 'qsub -cwd -o {} -e {} -l h_vmem=6.1G,s_vmem=6G'.format(stdout_path, stderr_path)\n",
    "    \n",
    "    job_file.write('{} {}\\n'.format(cmd_str, py_str))\n",
    "job_file.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consensus NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Codebase.Networks.SubgraphDetection.nonnegfac import nmf\n",
    "\n",
    "path_cfg_matr = glob.glob('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData))\n",
    "seed_path = glob.glob('{}/NMF_Optimized.Seed_*.npz'.format(path_ExpData))\n",
    "n_seed_block = 100\n",
    "seed_path_blocks = np.random.permutation(seed_path).reshape(-1, n_seed_block)\n",
    "\n",
    "for block_ix, seed_path_block in enumerate(seed_path_blocks):\n",
    "    print('Processing Block: {}'.format(block_ix+1))\n",
    "\n",
    "    # Concatenate subgraphs from block seeds\n",
    "    fac_subnet_seeds = []\n",
    "    for path_block in seed_path_block:\n",
    "        data = np.load(path_block, mmap_mode='r')\n",
    "        fac_subnet = data['fac_subnet'][:, :]\n",
    "        data.close()\n",
    "\n",
    "        n_fac = fac_subnet.shape[0]\n",
    "        n_conn = fac_subnet.shape[1]\n",
    "\n",
    "        for fac_ix in xrange(n_fac):\n",
    "            fac_subnet_seeds.append(fac_subnet[fac_ix, :])\n",
    "    fac_subnet_seeds = np.array(fac_subnet_seeds)\n",
    "\n",
    "    n_obs = fac_subnet_seeds.shape[0]\n",
    "    n_conn = fac_subnet_seeds.shape[1]\n",
    "    \n",
    "    if block_ix == 0:\n",
    "        fac_subnet_init = np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_conn))\n",
    "    else:\n",
    "        fac_subnet_init = fac_cons_subnet\n",
    "    fac_coef_init = np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_obs))\n",
    "\n",
    "    # Consensus Subgraphs\n",
    "    fac_cons_subnet, fac_cons_seeds, err = nmf.snmf_bcd(\n",
    "        fac_subnet_seeds,\n",
    "        alpha=0.0,\n",
    "        beta=0.0,\n",
    "        fac_subnet_init=fac_subnet_init,\n",
    "        fac_coef_init=fac_coef_init,\n",
    "        max_iter=100, verbose=True)\n",
    "\n",
    "# Consensus Coefficients\n",
    "data_cfg = np.load(path_cfg_matr, mmap_mode='r')\n",
    "cfg_matr = np.nan_to_num(data_cfg['cfg_matr'][:, :])\n",
    "n_win = cfg_matr.shape[0]\n",
    "fac_cons_subnet_2, fac_cons_coef_2, err = nmf.snmf_bcd(\n",
    "    cfg_matr,\n",
    "    alpha=0.0,\n",
    "    beta=0.0,\n",
    "    fac_subnet_init=fac_cons_subnet,\n",
    "    fac_coef_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_win)),\n",
    "    max_iter=100, verbose=True)\n",
    "\n",
    "# Cache the Consensus NMF result\n",
    "np.savez(\"{}/NMF_Consensus.npz\".format(path_ExpData),\n",
    "         fac_subnet=fac_cons_subnet_2, fac_coef=fac_cons_coef_2, err=err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consensus Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Plotting All Subgraphs...')\n",
    "df = np.load('{}/NMF_Consensus.npz'.format(path_ExpData))\n",
    "rank = df['fac_subnet'].shape[0]\n",
    "n_col = int(np.sqrt(rank))\n",
    "n_row = int(np.ceil(rank / n_col))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(16, 12))\n",
    "for ii in xrange(rank):\n",
    "    ax = plt.subplot(n_row, n_col, ii+1)\n",
    "    ax.matshow(conv_cfg_vec_to_adj_matr(df['fac_subnet'][ii, :]), cmap='rainbow')\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Subgraphs of Brain Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulate ROI Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_parcel = pd.read_csv('{}/LausanneScale125.csv'.format(path_CoreData))\n",
    "\n",
    "all_roi_names = []\n",
    "\n",
    "roi_dict = {}\n",
    "for lbl_id, lbl_roi, lbl_hemi in zip(df_parcel.Label_ID, df_parcel.ROI, df_parcel.Hemisphere):\n",
    "    roi_name = '{}_{}'.format(lbl_hemi, lbl_roi.split('_')[0])\n",
    "    #roi_name = lbl_roi.split('_')[0]\n",
    "    \n",
    "    if roi_name not in all_roi_names:\n",
    "        all_roi_names.append(roi_name)\n",
    "\n",
    "    try:\n",
    "        roi_dict[roi_name]\n",
    "    except KeyError:\n",
    "        roi_dict[roi_name] = []\n",
    "\n",
    "    roi_dict[roi_name].append(lbl_id-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert ROI Subgraphs to Brain System Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bs_fac_subnet = np.zeros((rank, len(all_roi_names), len(all_roi_names)))\n",
    "\n",
    "for fac_i, subg in enumerate(df['fac_subnet']):\n",
    "    adj = conv_cfg_vec_to_adj_matr(subg)\n",
    "    \n",
    "    for ij_ii, ij_roi in enumerate(all_roi_names):\n",
    "        for ik_ii, ik_roi in enumerate(all_roi_names):\n",
    "            \n",
    "            mean_conn = adj[roi_dict[ij_roi], :][:, roi_dict[ik_roi]].mean()\n",
    "            bs_fac_subnet[fac_i, ij_ii, ik_ii] = mean_conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all Brain System Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Plotting All Subgraphs...')\n",
    "rank = bs_fac_subnet.shape[0]\n",
    "n_col = int(np.sqrt(rank))\n",
    "n_row = int(np.ceil(rank / n_col))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(16, 12))\n",
    "for ii in xrange(rank):\n",
    "    ax = plt.subplot(n_row, n_col, ii+1)\n",
    "    ax.matshow(bs_fac_subnet[ii, :, :], cmap='rainbow')\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,18))\n",
    "sns.heatmap(bs_fac_subnet[15,:,:], cmap='rainbow', xticklabels=all_roi_names, yticklabels=all_roi_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(all_roi_names)[np.argsort(np.sum(bs_fac_subnet[15,:,:], axis=0))[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env-Echobase",
   "language": "python",
   "name": "env-echobase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_section_display": "none",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "625px",
   "left": "1410.77px",
   "right": "20px",
   "top": "151px",
   "width": "251px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
