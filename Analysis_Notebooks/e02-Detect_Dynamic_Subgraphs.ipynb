{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev2 toc-item\"><a href=\"#Generate-List-of-Data\" data-toc-modified-id=\"Generate-List-of-Data-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Generate List of Data</a></div><div class=\"lev2 toc-item\"><a href=\"#Construct-Configuration-Matrices\" data-toc-modified-id=\"Construct-Configuration-Matrices-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Construct Configuration Matrices</a></div><div class=\"lev3 toc-item\"><a href=\"#Distribution-of-Positive-/-Negative-Edge-Weights\" data-toc-modified-id=\"Distribution-of-Positive-/-Negative-Edge-Weights-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Distribution of Positive / Negative Edge Weights</a></div><div class=\"lev1 toc-item\"><a href=\"#Optimize-Dynamic-Subgraphs\" data-toc-modified-id=\"Optimize-Dynamic-Subgraphs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Optimize Dynamic Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Generate-Cross-Validation-Parameter-Sets\" data-toc-modified-id=\"Generate-Cross-Validation-Parameter-Sets-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Generate Cross-Validation Parameter Sets</a></div><div class=\"lev2 toc-item\"><a href=\"#SGE-Helper-Script-for-NMF-Cross-Validation\" data-toc-modified-id=\"SGE-Helper-Script-for-NMF-Cross-Validation-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>SGE Helper Script for NMF Cross-Validation</a></div><div class=\"lev2 toc-item\"><a href=\"#Quality-Measures-in-Parameter-Space\" data-toc-modified-id=\"Quality-Measures-in-Parameter-Space-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Quality Measures in Parameter Space</a></div><div class=\"lev1 toc-item\"><a href=\"#Detect-Dynamic-Subgraphs\" data-toc-modified-id=\"Detect-Dynamic-Subgraphs-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Detect Dynamic Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Map-NMF-Consensus-to-Identify-Seed-Subgraphs\" data-toc-modified-id=\"Map-NMF-Consensus-to-Identify-Seed-Subgraphs-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Map NMF Consensus to Identify Seed Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Reduce-Seed-Subgraphs-to-Consensus-Subgraphs\" data-toc-modified-id=\"Reduce-Seed-Subgraphs-to-Consensus-Subgraphs-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Reduce Seed Subgraphs to Consensus Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Plot-Subgraphs\" data-toc-modified-id=\"Plot-Subgraphs-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Plot Subgraphs</a></div><div class=\"lev1 toc-item\"><a href=\"#Subgraphs-of-Brain-Systems\" data-toc-modified-id=\"Subgraphs-of-Brain-Systems-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Subgraphs of Brain Systems</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Subgraphs-and-Expression\" data-toc-modified-id=\"Load-Subgraphs-and-Expression-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Load Subgraphs and Expression</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Atlas\" data-toc-modified-id=\"Load-Atlas-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Load Atlas</a></div><div class=\"lev3 toc-item\"><a href=\"#Render-brain-systems\" data-toc-modified-id=\"Render-brain-systems-421\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Render brain systems</a></div><div class=\"lev2 toc-item\"><a href=\"#Condense-Subgraphs-into-a-Dictionary\" data-toc-modified-id=\"Condense-Subgraphs-into-a-Dictionary-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Condense Subgraphs into a Dictionary</a></div><div class=\"lev2 toc-item\"><a href=\"#Circle-Plot\" data-toc-modified-id=\"Circle-Plot-44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Circle Plot</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "#echobase_path = '/data/jag/akhambhati/hoth_research/Echobase'\n",
    "echobase_path = '/Users/akhambhati/Developer/hoth_research/Echobase'\n",
    "sys.path.append(echobase_path)\n",
    "import Echobase\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "subgraph = Echobase.Network.Partitioning.Subgraph\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "\n",
    "path_Remotes = '/Users/akhambhati/Remotes'\n",
    "path_CoreData = path_Remotes + '/CORE.fMRI_cogcontrol.medaglia'\n",
    "path_PeriphData = path_Remotes + '/RSRCH.NMF_CogControl'\n",
    "path_InpData = path_PeriphData + '/e01-FuncNetw'\n",
    "path_ExpData = path_PeriphData + '/e02-FuncSubg'\n",
    "path_Figures = './e02-Figures'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData, path_Figures]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate List of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expr_dict = {}\n",
    "for expr_id in ['Stroop', 'Navon']:    \n",
    "    df_list = glob.glob('{}/*.Stroop.npz'.format(path_InpData))\n",
    "    \n",
    "    for df_subj in df_list:\n",
    "        subj_id = int(df_subj.split('/')[-1].split('.')[0].split('_')[1])\n",
    "        if subj_id not in expr_dict.keys():\n",
    "            expr_dict[subj_id] = {}\n",
    "        \n",
    "        expr_dict[subj_id][expr_id] = df_subj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Configuration Matrices\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove all existing output (retains pipe/pipeline definitions)\n",
    "rm_outp = glob.glob(\"{}/NMF_Optimization.CfgMatr.npz\".format(path_ExpData))\n",
    "\n",
    "for rm_type in [rm_outp]:\n",
    "    for path in rm_type:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            print(\"{} not found\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the network configuration matrix over the whole population\n",
    "cfg_key = []\n",
    "cfg_matr = []\n",
    "for subj_id in expr_dict.keys():\n",
    "    for expr_id in expr_dict[subj_id].keys():\n",
    "        adj_dict = np.load(expr_dict[subj_id][expr_id])['adj_dict'][()]\n",
    "        \n",
    "        for cnd_id in adj_dict.keys():\n",
    "            for tsk_id in adj_dict[cnd_id].keys():\n",
    "                for cor_id in adj_dict[cnd_id][tsk_id].keys():\n",
    "                    for cfg_ii, cfg_vec in enumerate(convert_adj_matr_to_cfg_matr(adj_dict[cnd_id][tsk_id][cor_id])):\n",
    "                        cfg_key.append('{}.{}.{}.{}.{}.{}'.format(subj_id, expr_id, cnd_id, tsk_id, cor_id, cfg_ii))\n",
    "                        cfg_matr.append(cfg_vec)\n",
    "cfg_key = np.array(cfg_key)\n",
    "cfg_matr = np.array(cfg_matr)\n",
    "\n",
    "# Generate a lookup table for the observations of cfg_matr\n",
    "# subjects, task conditions + pos/neg interactions, blocks\n",
    "n_obs, n_conn = cfg_matr.shape\n",
    "subj_id = np.unique([int(key.split('.')[0]) for key in cfg_key])\n",
    "expr_id = np.unique([key.split('.')[1] for key in cfg_key])\n",
    "cnd_id = np.unique([key.split('.')[2] for key in cfg_key])\n",
    "tsk_id = np.unique([key.split('.')[3] for key in cfg_key])\n",
    "cor_id = np.unique([key.split('.')[4] for key in cfg_key])\n",
    "blk_id = np.unique([int(key.split('.')[5]) for key in cfg_key])\n",
    "\n",
    "cfg_obs_lut = np.zeros((len(subj_id), len(expr_id), len(cnd_id),\n",
    "                        len(tsk_id), len(cor_id), len(blk_id)))\n",
    "\n",
    "for key_ii, key in enumerate(cfg_key):\n",
    "    ix_1 = np.flatnonzero(subj_id == int(key.split('.')[0]))[0]\n",
    "    ix_2 = np.flatnonzero(expr_id == key.split('.')[1])[0]\n",
    "    ix_3 = np.flatnonzero(cnd_id == key.split('.')[2])[0]\n",
    "    ix_4 = np.flatnonzero(tsk_id == key.split('.')[3])[0]\n",
    "    ix_5 = np.flatnonzero(cor_id == key.split('.')[4])[0]\n",
    "    ix_6 = np.flatnonzero(blk_id == int(key.split('.')[5]))[0]\n",
    "    \n",
    "    cfg_obs_lut[ix_1, ix_2, ix_3,\n",
    "                ix_4, ix_5, ix_6] = key_ii\n",
    "\n",
    "np.savez('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData),\n",
    "         cfg_matr=cfg_matr,\n",
    "         cfg_key=cfg_key,\n",
    "         cfg_obs_lut=cfg_obs_lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Cross-Validation Parameter Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load configuration matrix\n",
    "cfg_data = np.load('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData))\n",
    "cfg_matr = cfg_data['cfg_matr']\n",
    "cfg_obs_lut = cfg_data['cfg_obs_lut']\n",
    "\n",
    "# Generate folds\n",
    "n_subj_per_fold = 2\n",
    "subj_obs = cfg_obs_lut.reshape(cfg_obs_lut.shape[0], -1)\n",
    "fold_obs = subj_obs.reshape(-1, n_subj_per_fold, subj_obs.shape[-1])\n",
    "fold_obs = fold_obs.reshape(fold_obs.shape[0], -1)\n",
    "fold_list = [list(ff) for ff in fold_obs]\n",
    "\n",
    "# Cross-Validation Progress\n",
    "str_path = '{}/NMF_CrossValidation.Progress.txt'.format(path_ExpData)\n",
    "if os.path.exists(str_path):\n",
    "    os.remove(str_path)\n",
    "\n",
    "# Get parameter search space\n",
    "param_list = Echobase.Network.Partitioning.Subgraph.optimize_nmf.gen_random_sampling_paramset(\n",
    "    rank_range=(2, 51),\n",
    "    alpha_range=(0.01, 1.0),\n",
    "    beta_range=(0.01, 1.0),\n",
    "    n_param=1000,\n",
    "    fold_list=fold_list,\n",
    "    str_path=str_path)\n",
    "\n",
    "# Save param_list for sge run\n",
    "np.savez('{}/NMF_CrossValidation.Param_List.npz'.format(path_ExpData),\n",
    "         param_list=param_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGE Helper Script for NMF Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map NMF xval to all the parameter sets\n",
    "job_str = './NMF_xval.py {} {}'.format(echobase_path, path_ExpData)\n",
    "qsub_str = 'qsub -t 1-{} {}'.format(len(param_list), job_str)\n",
    "\n",
    "os.chdir('./e02-SGE_Scripts/')\n",
    "!sh {qsub_str}\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reduce NMF xval output to a qmeas_list\n",
    "\n",
    "path_xval_out = glob.glob('{}/NMF_CrossValidation.Param.*.npz'.format(path_ExpData))\n",
    "qmeas_list = [np.load(pth)['qmeas_dict'][()] for pth in path_xval_out]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Measures in Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_list = np.load('{}/NMF_CrossValidation.Param_List.npz'.format(path_ExpData))['param_list']\n",
    "all_param, opt_param = Echobase.Network.Partitioning.Subgraph.optimize_nmf.find_optimum_xval_paramset(param_list, qmeas_list)\n",
    "np.savez('{}/NMF_CrossValidation.Optimal_Param.npz'.format(path_ExpData),\n",
    "         opt_param=opt_param,\n",
    "         all_param=all_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt_dict = np.load('{}/NMF_CrossValidation.Optimal_Param.npz'.format(path_ExpData))['all_param'][()]\n",
    "opt_params = {}\n",
    "opt_params['rank'] = int(opt_dict['rank'][opt_dict['error'] < np.percentile(opt_dict['error'], 25)].mean().round())\n",
    "opt_params['alpha'] = opt_dict['alpha'][opt_dict['error'] < np.percentile(opt_dict['error'], 25)].mean()\n",
    "opt_params['beta'] = opt_dict['beta'][opt_dict['error'] < np.percentile(opt_dict['error'], 25)].mean()\n",
    "print('Optimal Rank: {}'.format(opt_params['rank']))\n",
    "print('Optimal Alpha: {}'.format(opt_params['alpha']))\n",
    "print('Optimal Beta: {}'.format(opt_params['beta']))\n",
    "\n",
    "# Generate quality measure plots\n",
    "for qmeas in ['error', 'pct_sparse_subgraph', 'pct_sparse_coef']:\n",
    "    for param in ['rank', 'alpha', 'beta']:\n",
    "\n",
    "        param_unq = np.unique(opt_dict[param])\n",
    "        qmeas_mean = [np.mean(opt_dict[qmeas][opt_dict[param]==pp]) for pp in param_unq]\n",
    "        \n",
    "        ax_jp = sns.jointplot(opt_dict[param], opt_dict[qmeas], kind='kde', \n",
    "                              space=0, n_levels=60, shade_lowest=False)\n",
    "        ax = ax_jp.ax_joint\n",
    "        ax.plot([opt_params[param], opt_params[param]], \n",
    "                [ax.get_ylim()[0], ax.get_ylim()[1]],\n",
    "                lw=1.0, alpha=0.75, linestyle='--')\n",
    "\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.set_xlabel(param)\n",
    "        ax.set_ylabel(qmeas)\n",
    "        \n",
    "        plt.savefig('{}/NMF_Optimization.{}.{}.svg'.format(path_Figures, param, qmeas))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "opt_dict.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map NMF Consensus to Identify Seed Subgraphs\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Map NMF consensus to all the parameter sets\n",
    "n_opt = 1000\n",
    "job_str = './NMF_consensus_map.py {} {}'.format(echobase_path, path_ExpData)\n",
    "qsub_str = 'qsub -t 1-{} {}'.format(n_opt, job_str)\n",
    "\n",
    "os.chdir('./e02b-SGE_Scripts/')\n",
    "!sh {qsub_str}\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Seed Subgraphs to Consensus Subgraphs\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reduce NMF consensus from all seed subgraphs\n",
    "job_str = './NMF_consensus_reduce.py {} {}'.format(echobase_path, path_ExpData)\n",
    "qsub_str = 'qsub {}'.format(job_str)\n",
    "\n",
    "os.chdir('./e02b-SGE_Scripts/')\n",
    "!sh {qsub_str}\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the consensus data\n",
    "data = np.load(\"{}/NMF_Consensus.Param.All.npz\".format(path_ExpData),\n",
    "               mmap_mode='r')\n",
    "fac_subnet = data['fac_subnet']\n",
    "fac_coef = data['fac_coef']\n",
    "\n",
    "# Normalize\n",
    "fac_subnet = fac_subnet / fac_subnet.max()\n",
    "fac_coef = fac_coef / fac_coef.max()\n",
    "\n",
    "n_fac = fac_subnet.shape[0]\n",
    "n_conn = fac_subnet.shape[1]\n",
    "n_win = fac_coef.shape[1]\n",
    "\n",
    "# Plot subgraph matrix\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "mat = ax.matshow(fac_subnet.T, aspect=float(n_fac)/n_conn, cmap='rainbow', vmin=0, vmax=1)\n",
    "#plt.colorbar(mat, ax=ax)\n",
    "\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "#ax.set_xticks(np.linspace(0, 80, 5))\n",
    "ax.set_ylabel('Functional Interactions')\n",
    "ax.set_xlabel('Subgraphs')\n",
    "\n",
    "plt.savefig('{}/Subgraph-Cfg_Matrix.svg'.format(path_Figures))\n",
    "plt.show()\n",
    "plt.close()      \n",
    "\n",
    "# Plot subgraph adjacency\n",
    "plt.figure()\n",
    "n_row = np.floor(np.sqrt(n_fac))\n",
    "n_col = np.ceil(n_fac / n_row)\n",
    "for ii, subg in enumerate(fac_subnet):\n",
    "    adj = convert_conn_vec_to_adj_matr(subg)\n",
    "\n",
    "    ax = plt.subplot(n_row, n_col, ii+1)\n",
    "    mat = ax.matshow(adj, cmap='rainbow', vmin=0, vmax=1)\n",
    "    #plt.colorbar(mat, ax=ax)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "plt.savefig('{}/Subgraph-Adj_Matrices.svg'.format(path_Figures))\n",
    "plt.show()\n",
    "plt.close()      \n",
    "\n",
    "# Plot Coefficients\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "fac_coef = fac_coef.T\n",
    "norm_fac = fac_coef - fac_coef.mean(axis=0)\n",
    "for ff in xrange(n_fac):\n",
    "    ax.plot(ff + norm_fac[:, ff] / (3*np.std(norm_fac[:, ff])), color=[66/256., 152/256., 221./256])\n",
    "\n",
    "# Axis Settings\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_ylim([-1, n_fac+1])\n",
    "ax.set_xlim([0, int(n_win/28*3)])\n",
    "ax.set_ylabel('Subgraphs')\n",
    "ax.set_xlabel('Time Windows')\n",
    "\n",
    "plt.savefig('{}/Subgraph-Coefs.svg'.format(path_Figures))\n",
    "plt.show()\n",
    "plt.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgraphs of Brain Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Subgraphs and Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grab the subgraphs and expression from consensus NMF\n",
    "df_nmf = np.load(\"{}/NMF_Consensus.Param.All.npz\".format(path_ExpData),\n",
    "                 mmap_mode='r')\n",
    "fac_subnet = df_nmf['fac_subnet']\n",
    "fac_coef = df_nmf['fac_coef']\n",
    "n_fac = fac_subnet.shape[0]\n",
    "n_conn = fac_subnet.shape[1]\n",
    "n_node = np.int(np.ceil(np.sqrt(n_conn*2)))\n",
    "n_obs = fac_coef.shape[1]\n",
    "\n",
    "# Retrieve the configuration matrix\n",
    "# Get expression for: subgraphs, subjects, task conditions + pos/neg interactions, blocks\n",
    "df_cfg = np.load('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData), mmap_mode='r')\n",
    "key_type = np.unique(df_cfg['cfg_key'])\n",
    "cfg_obs_lut = np.array(df_cfg['cfg_obs_lut'], dtype=np.int)\n",
    "fac_coef_subj = np.take(fac_coef, cfg_obs_lut, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Get the Lausanne Labels\n",
    "df_parcel = pd.read_csv('{}/LausanneScale125.csv'.format(path_CoreData))\n",
    "\n",
    "lausanne_lbl = []\n",
    "for lbl_id, lbl_roi, lbl_hemi in zip(df_parcel.Label_ID, df_parcel.ROI, df_parcel.Hemisphere):\n",
    "    roi_name = '{}_{}'.format(lbl_hemi, lbl_roi)\n",
    "    lausanne_lbl.append(roi_name)\n",
    "lausanne_lbl = np.array(lausanne_lbl)\n",
    "\n",
    "### Get the system assignments for each ROI\n",
    "df_sys = h5py.File('{}/sysInfo234.mat'.format(path_CoreData), 'r')\n",
    "system_lbl = [''.join(unichr(c) for c in df_sys[rr])\n",
    "              for rr in df_sys['sysInfo']['system'][0, :]]\n",
    "for ii in xrange(len(system_lbl), n_node):\n",
    "    system_lbl.append(u'cerebellum')\n",
    "system_lbl = np.array(system_lbl)\n",
    "system_name = np.unique(system_lbl)\n",
    "\n",
    "### Get the sizes for each system\n",
    "system_size = []\n",
    "for sys_name in system_name:\n",
    "    system_size.append(len(np.flatnonzero(system_lbl == sys_name)))\n",
    "\n",
    "### Reorder systems by alternating size\n",
    "system_ix = np.argsort(system_size)[::-1]\n",
    "system_ix_large = system_ix[:len(system_ix)//2]\n",
    "system_ix_small = system_ix[len(system_ix)//2:][::-1]\n",
    "system_ord = []\n",
    "for ii, ij in zip(system_ix_large, system_ix_small):\n",
    "    system_ord.append(ii)\n",
    "    system_ord.append(ij)\n",
    "if len(system_ord)+1 == len(system_ix):\n",
    "    system_ord.append(system_ix_small[-1])\n",
    "    \n",
    "new_system_name = system_name.copy()\n",
    "for ii, sys_ix in enumerate(system_ord):\n",
    "    new_system_name[ii] = system_name[sys_ix]\n",
    "system_name = np.array(new_system_name)\n",
    "\n",
    "### Reorder the parcellation based on re-ordered systems labels\n",
    "srt_system_ix = []\n",
    "for sys_name in system_name:\n",
    "    for ll_ix in np.flatnonzero(system_lbl == sys_name):\n",
    "        srt_system_ix.append(ll_ix)\n",
    "srt_system_ix = np.array(srt_system_ix)\n",
    "srt_system_lbl = system_lbl[srt_system_ix]\n",
    "srt_lausanne_lbl = lausanne_lbl[srt_system_ix]\n",
    "\n",
    "df_sys.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render brain systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixmap_path = '{}/brain_system_pixmap.npz'.format(path_Figures)\n",
    "if os.path.exists(pixmap_path):\n",
    "    brain_system_pixmap = np.load(pixmap_path)['brain_system_pixmap']\n",
    "else:\n",
    "    from mayavi import mlab\n",
    "    import nibabel as nib\n",
    "\n",
    "    brain_system_pixmap = []\n",
    "\n",
    "    sys_scalar = [5, 18, 2, 0, 3, 4, 6, 8, 10, 9, 15]\n",
    "    view_angle = {'Sag_PA': [0.0, 90.0],\n",
    "                  'Sag_AP': [180.0, 90.0]}\n",
    "\n",
    "    # Get the pial surface recons\n",
    "    pial_hemi = {'LH': {},\n",
    "                 'RH': {}}\n",
    "    pial_hemi['LH']['vert'], pial_hemi['LH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/lh.pial'.format(path_CoreData))\n",
    "    pial_hemi['RH']['vert'], pial_hemi['RH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/rh.pial'.format(path_CoreData))\n",
    "\n",
    "    # Get the Lausanne label files for each ROI\n",
    "    label_files = []\n",
    "    for roi in lausanne_lbl:\n",
    "        hemi = roi.split('_')[0].lower()\n",
    "\n",
    "        # Parse the atlas name and find the label file if it exists\n",
    "        if len(roi.split('_')) == 2:\n",
    "            lbl_file = ('%s.%s.label' % tuple(roi.split('_'))).lower()\n",
    "        elif len(roi.split('_')) == 3:\n",
    "            lbl_file = ('%s.%s_%s.label' % tuple(roi.split('_'))).lower()\n",
    "        else:\n",
    "            raise Exception\n",
    "        lbl_file = lbl_file.replace(' ', '')\n",
    "\n",
    "        label_files.append('{}/BrainRenderSubject15/label/regenerated_{}_125/{}'.format(path_CoreData, hemi, lbl_file))\n",
    "\n",
    "    # Iterate over hemisphere of the pial surface\n",
    "    for hemi in pial_hemi.keys():\n",
    "        n_vert = len(pial_hemi[hemi]['vert'])\n",
    "\n",
    "        # Iterate over brain system\n",
    "        for sys_id, sys_lbl in enumerate(system_name):\n",
    "            print(sys_lbl)\n",
    "            sys_ix = np.flatnonzero(system_lbl == sys_lbl)\n",
    "\n",
    "            # Find the label file for each ROI and get vertices\n",
    "            if sys_lbl == 'subcortical':\n",
    "                pial_scalars = sys_scalar[sys_id]*np.ones(n_vert)\n",
    "            else:\n",
    "                pial_scalars = 15*np.ones(n_vert)\n",
    "            for roi_ix, (roi, lbl_file) in enumerate(zip(lausanne_lbl, label_files)):\n",
    "                if roi.split('_')[0] != hemi:\n",
    "                    continue\n",
    "\n",
    "                if not os.path.exists(lbl_file):\n",
    "                    continue\n",
    "\n",
    "                # Load the file and add scalar to the vertices\n",
    "                parc_lbl = nib.freesurfer.io.read_label(lbl_file)                \n",
    "                if roi_ix in sys_ix:\n",
    "                    pial_scalars[parc_lbl] = sys_scalar[sys_id]\n",
    "                else:\n",
    "                    pial_scalars[parc_lbl] = 15               \n",
    "\n",
    "            # Plot the colored Brain System\n",
    "            fig = mlab.figure(bgcolor=(1.0, 1.0, 1.0))\n",
    "            src = mlab.pipeline.triangular_mesh_source(pial_hemi[hemi]['vert'][:,0],\n",
    "                                                       pial_hemi[hemi]['vert'][:,1],\n",
    "                                                       pial_hemi[hemi]['vert'][:,2],\n",
    "                                                       pial_hemi[hemi]['tria'], scalars=pial_scalars, opacity=0.75, figure=fig)\n",
    "            norms = mlab.pipeline.poly_data_normals(src, figure=fig)\n",
    "            norms.filter.splitting = False\n",
    "            surf = mlab.pipeline.surface(norms, figure=fig)\n",
    "            surf.parent.scalar_lut_manager.set(lut_mode='Vega20', data_range=[0, 19], use_default_range=False)\n",
    "            lut = surf.module_manager.scalar_lut_manager.lut.table.to_array()\n",
    "            lut[188:213, 3] = 220\n",
    "            surf.module_manager.scalar_lut_manager.lut.table = lut\n",
    "\n",
    "            # Rotate the view and save a screenshot\n",
    "            pixmap = {}\n",
    "            for ang in view_angle.keys():\n",
    "                mlab.view(azimuth=view_angle[ang][0],\n",
    "                          elevation=view_angle[ang][1])\n",
    "                pixmap['{}_{}'.format(hemi, ang)] = mlab.screenshot(mode='rgba')\n",
    "            brain_system_pixmap.append(pixmap)\n",
    "            mlab.close(all=True)\n",
    "\n",
    "    np.savez('{}/brain_system_pixmap.npz'.format(path_Figures),\n",
    "             brain_system_pixmap=brain_system_pixmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condense Subgraphs into a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys_subgraph_path = '{}/Subgraph.All.npz'.format(path_ExpData)\n",
    "if os.path.exists(sys_subgraph_path):\n",
    "    df_subg = np.load('{}/Subgraph.All.npz'.format(path_ExpData))\n",
    "else:\n",
    "    system_subgraph = []\n",
    "    for fac_i, subg in enumerate(fac_subnet):\n",
    "        print('Processed: {} of {}'.format(fac_i+1, len(fac_subnet)))\n",
    "\n",
    "        adj = convert_conn_vec_to_adj_matr(subg)\n",
    "        adj = adj[srt_system_ix, :][:, srt_system_ix]\n",
    "        adj_thrsh = adj.copy()   \n",
    "        cfg_thrsh = adj_thrsh[triu_ix, triu_iy]\n",
    "        coef = fac_coef_subj[fac_i, ...]\n",
    "        \n",
    "        # Compute Brain System Adjacency Matrices\n",
    "        n_roi = adj.shape[0]\n",
    "        triu_ix, triu_iy = np.triu_indices(n_roi, k=1)\n",
    "        n_system = len(system_name)\n",
    "        adj_sys = np.zeros((n_system, n_system))\n",
    "        \n",
    "        n_perm = 10000\n",
    "        null_subg = np.array([np.random.permutation(subg) for n_ii in xrange(n_perm)])\n",
    "        alpha = 0.05 / ((n_system*(n_system+1)) / 2)\n",
    "        for sys_ix, sys_iy in zip(*np.triu_indices(n_system, k=0)):\n",
    "            sys1 = system_name[sys_ix]\n",
    "            sys2 = system_name[sys_iy]\n",
    "            sys1_ix = np.flatnonzero(system_lbl[triu_ix] == sys1)\n",
    "            sys2_iy = np.flatnonzero(system_lbl[triu_iy] == sys2)\n",
    "            inter_sys_ii = np.intersect1d(sys1_ix, sys2_iy)\n",
    "\n",
    "            mean_conn_sys1_sys2 = np.mean(subg[inter_sys_ii])\n",
    "\n",
    "            null_mean = np.mean(null_subg[:, inter_sys_ii], axis=1)\n",
    "            if np.mean(null_mean > mean_conn_sys1_sys2) < alpha:\n",
    "                adj_sys[sys_ix, sys_iy] = mean_conn_sys1_sys2\n",
    "                \n",
    "            else:\n",
    "                # If the system connectivity is not greater than chance, remove those connections\n",
    "                cfg_thrsh[inter_sys_ii] = 0\n",
    "        adj_sys += adj_sys.T\n",
    "        \n",
    "        adj_thrsh = convert_conn_vec_to_adj_matr(cfg_thrsh)\n",
    "        \n",
    "        # Generate subgraph dictionary\n",
    "        system_subgraph.append({'Subgraph_ID': fac_i+1,\n",
    "                                'full_subg': adj,\n",
    "                                'thrsh_subg': adj_thrsh,\n",
    "                                'sys_subg': adj_sys,\n",
    "                                'expr_coef': coef})\n",
    "        \n",
    "    np.savez('{}/Subgraph.All.npz'.format(path_ExpData),\n",
    "             system_subgraph=system_subgraph,\n",
    "             lausanne_labels=srt_lausanne_lbl,\n",
    "             system_labels=srt_system_lbl,\n",
    "             system_names=system_name,\n",
    "             brain_system_pixmap=brain_system_pixmap,\n",
    "             task_key=key_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circle Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage, TextArea\n",
    "from scipy import ndimage\n",
    "\n",
    "df_subg = np.load('{}/Subgraph.All.npz'.format(path_ExpData))\n",
    "sys_subgraph = df_subg['system_subgraph']\n",
    "sys_name = df_subg['system_names']\n",
    "sys_label = df_subg['system_labels']\n",
    "sys_pixmap = df_subg['brain_system_pixmap']\n",
    "n_sys = len(sys_name)\n",
    "n_lbl = len(sys_label)\n",
    "\n",
    "vega20_cmap = np.array([[31, 119, 180],\n",
    "                        [174, 199, 232],\n",
    "                        [255, 127, 14],\n",
    "                        [255, 187, 120],\n",
    "                        [44, 160, 44],\n",
    "                        [152, 223, 138],\n",
    "                        [214, 39, 40],\n",
    "                        [255, 152, 150],\n",
    "                        [148, 103, 189],\n",
    "                        [197, 176, 213],\n",
    "                        [140, 86, 75],\n",
    "                        [196, 156, 148],\n",
    "                        [227, 119, 194],\n",
    "                        [247, 182, 210],\n",
    "                        [127, 127, 127],\n",
    "                        [199, 199, 199],\n",
    "                        [188, 189, 34],\n",
    "                        [219, 219, 141], \n",
    "                        [23, 190, 207],\n",
    "                        [158, 218, 229]])\n",
    "vega20_sys = np.array([5, 18, 2, 0, 3, 4, 6, 8, 10, 9, 14])\n",
    "node_clr = np.array([vega20_cmap[vega20_sys[sys_name == sys_lbl]][0, :] / 255.  for sys_lbl in sys_label])\n",
    "\n",
    "\n",
    "system_pos = []\n",
    "node_rads = np.linspace(0, 2*np.pi - (2*np.pi/n_lbl), n_lbl)\n",
    "for sys_ii, sys_nm in enumerate(sys_name):\n",
    "    sys_rad = np.mean(node_rads[sys_label == sys_nm])\n",
    "    if sys_ii % 2 == 0:\n",
    "        dd = 16\n",
    "    else:\n",
    "        dd = 16\n",
    "    system_pos.append((sys_rad, dd))\n",
    "        \n",
    "plt.close()\n",
    "for f_ii, sys_subg in enumerate(sys_subgraph):\n",
    "    sys_con = convert_adj_matr_to_cfg_matr(sys_subg['thrsh_subg'].reshape(1, \n",
    "                                                                         sys_subg['full_subg'].shape[0],\n",
    "                                                                         sys_subg['full_subg'].shape[0])).squeeze()\n",
    "    fig, ax = Echobase.Plotting.render_circle_connectivity.draw(conn_list=sys_con,\n",
    "                                                                conn_pct=[95, 100],\n",
    "                                                                conn_cmap='YlGnBu',\n",
    "                                                                conn_linewidth=0.5,\n",
    "                                                                node_color=node_clr)\n",
    "    \"\"\"\n",
    "    fig.axes[0].set_ylim(0, 20)\n",
    "\n",
    "    for sys_ii in xrange(n_sys):\n",
    "        if sys_name[sys_ii] in ['dorsal_attention', 'cerebellum', 'subcortical', 'default_mode']:\n",
    "            arr = sys_pixmap[sys_ii+11]['LH_Sag_PA']\n",
    "        elif sys_name[sys_ii] in ['ventral_attention']:\n",
    "            arr = sys_pixmap[sys_ii+11]['LH_Sag_AP']\n",
    "            arr = np.fliplr(arr)\n",
    "        else:\n",
    "            arr = sys_pixmap[sys_ii]['RH_Sag_PA']\n",
    "        arr = ndimage.rotate(arr, (system_pos[sys_ii][0] - np.pi/2) * 180/np.pi, reshape=False)\n",
    "\n",
    "        imagebox = OffsetImage(arr, zoom=0.3)\n",
    "        imagebox.axes = fig.axes[0]\n",
    "\n",
    "        ab = AnnotationBbox(imagebox, \n",
    "                            xy=system_pos[sys_ii],\n",
    "                            xycoords='data',\n",
    "                            frameon=False,\n",
    "                            pad=0.0)\n",
    "        fig.axes[0].add_artist(ab)\n",
    "    \"\"\"    \n",
    "       \n",
    "    fig.savefig('{}/Circle_Subgraph.{}.svg'.format(path_Figures, f_ii))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(np.random.uniform(size=(1000,1000)), cmap='YlGnBu');\n",
    "plt.colorbar()\n",
    "plt.savefig('{}/YlGnBu.svg'.format(path_Figures))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "897px",
    "left": "0px",
    "right": "1707px",
    "top": "106px",
    "width": "329px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
