{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev1 toc-item\"><a href=\"#Generate-list-of-data\" data-toc-modified-id=\"Generate-list-of-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Generate list of data</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load Data</a></div><div class=\"lev1 toc-item\"><a href=\"#!!!-NMF-TEST-!!!\" data-toc-modified-id=\"!!!-NMF-TEST-!!!-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>!!! NMF TEST !!!</a></div><div class=\"lev1 toc-item\"><a href=\"#Rank-Subgraphs-Based-on-Pos/Neg-Expression\" data-toc-modified-id=\"Rank-Subgraphs-Based-on-Pos/Neg-Expression-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Rank Subgraphs Based on Pos/Neg Expression</a></div><div class=\"lev1 toc-item\"><a href=\"#Subgraph-Motion-Detection\" data-toc-modified-id=\"Subgraph-Motion-Detection-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Subgraph Motion-Detection</a></div><div class=\"lev1 toc-item\"><a href=\"#Plot-Ranked-System-Subgraph-Matrices\" data-toc-modified-id=\"Plot-Ranked-System-Subgraph-Matrices-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Plot Ranked System Subgraph Matrices</a></div><div class=\"lev1 toc-item\"><a href=\"#Expression-Constrasts\" data-toc-modified-id=\"Expression-Constrasts-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Expression Constrasts</a></div><div class=\"lev2 toc-item\"><a href=\"#Stroop-vs-Navon\" data-toc-modified-id=\"Stroop-vs-Navon-71\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Stroop vs Navon</a></div><div class=\"lev3 toc-item\"><a href=\"#Expression-Plot\" data-toc-modified-id=\"Expression-Plot-711\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>Expression Plot</a></div><div class=\"lev2 toc-item\"><a href=\"#Lo-vs-Hi\" data-toc-modified-id=\"Lo-vs-Hi-72\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Lo vs Hi</a></div><div class=\"lev3 toc-item\"><a href=\"#Expression-Plot\" data-toc-modified-id=\"Expression-Plot-721\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Expression Plot</a></div><div class=\"lev3 toc-item\"><a href=\"#Render-t-stat-map\" data-toc-modified-id=\"Render-t-stat-map-722\"><span class=\"toc-item-num\">7.2.2&nbsp;&nbsp;</span>Render t-stat map</a></div><div class=\"lev1 toc-item\"><a href=\"#Subgraph-Regime-Switching\" data-toc-modified-id=\"Subgraph-Regime-Switching-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Subgraph Regime Switching</a></div><div class=\"lev1 toc-item\"><a href=\"#Task-Performance\" data-toc-modified-id=\"Task-Performance-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Task Performance</a></div><div class=\"lev2 toc-item\"><a href=\"#Behavioral-Correlation\" data-toc-modified-id=\"Behavioral-Correlation-91\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Behavioral Correlation</a></div><div class=\"lev2 toc-item\"><a href=\"#Regional-Contribution-to-Modulation-in-Performance\" data-toc-modified-id=\"Regional-Contribution-to-Modulation-in-Performance-92\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Regional Contribution to Modulation in Performance</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(matplotlib.rcParams)\n",
    "\n",
    "path_Remotes = '/Users/akhambhati/Remotes'\n",
    "path_CoreData = path_Remotes + '/CORE.fMRI_cogcontrol.medaglia'\n",
    "path_PeriphData = path_Remotes + '/RSRCH.NMF_CogControl'\n",
    "path_InpData_Netw = path_PeriphData + '/e01-FuncNetw'\n",
    "path_InpData_Subg = path_PeriphData + '/e02-FuncSubg'\n",
    "path_ExpData = path_PeriphData + '/e03-FuncSubg_Dynamics'\n",
    "path_Figures = './e03-Figures/'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate list of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load Functional Data\n",
    "df_cfg = np.load('{}/Population.Configuration_Matrix.npz'.format(path_InpData_Netw))\n",
    "df_subgraph = np.load('{}/Yeo_Subgraph.All.npz'.format(path_InpData_Subg))\n",
    "df_to_yeo = np.load('{}/Lausanne125_to_Yeo.npz'.format(path_InpData_Netw))\n",
    "\n",
    "n_subj, _, _, _, _, n_block = df_cfg['cfg_obs_lut'].shape\n",
    "n_fac = len(df_subgraph['system_subgraph'])\n",
    "\n",
    "\n",
    "# Load Behavioral Data\n",
    "df_blk = io.loadmat('{}/BlockwiseDataCorrectTrialsOnly.mat'.format(path_CoreData))\n",
    "bad_subj_ix = [1, 6]\n",
    "good_subj_ix = np.setdiff1d(np.arange(n_subj+2), bad_subj_ix)\n",
    "\"\"\"\n",
    "'high control accuracy', 'low control accuracy', 'high control mean RT',\n",
    "'high control median RT', 'low control mean RT', 'low control median RT'\n",
    "\"\"\"\n",
    "df_perf = {'Stroop': {'lo': {'accuracy': df_blk['StroopData'][good_subj_ix, 1, :],\n",
    "                             'meanRT': df_blk['StroopData'][good_subj_ix, 4, :],\n",
    "                             'medianRT': df_blk['StroopData'][good_subj_ix, 5, :]},\n",
    "                      'hi': {'accuracy': df_blk['StroopData'][good_subj_ix, 0, :],\n",
    "                             'meanRT': df_blk['StroopData'][good_subj_ix, 2, :],\n",
    "                             'medianRT': df_blk['StroopData'][good_subj_ix, 3, :]}\n",
    "                     },\n",
    "           'Navon' : {'lo': {'accuracy': df_blk['NavonData'][good_subj_ix, 1, :],\n",
    "                             'meanRT': df_blk['NavonData'][good_subj_ix, 4, :],\n",
    "                             'medianRT': df_blk['NavonData'][good_subj_ix, 5, :]},\n",
    "                      'hi': {'accuracy': df_blk['NavonData'][good_subj_ix, 0, :],\n",
    "                             'meanRT': df_blk['NavonData'][good_subj_ix, 2, :],\n",
    "                             'medianRT': df_blk['NavonData'][good_subj_ix, 3, :]}\n",
    "                     }\n",
    "          }\n",
    "\n",
    "\n",
    "# Load Motion Data\n",
    "df_motion = {'Stroop': io.loadmat('{}/StroopMove.mat'.format(path_CoreData))['move'][:, 0],\n",
    "             'Navon': io.loadmat('{}/NavonMove.mat'.format(path_CoreData))['move'][:, 0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!! NMF TEST !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_matr = df_cfg['cfg_matr'].copy()\n",
    "#cfg_matr = (df_cfg['cfg_matr'].T * df_cfg['cfg_L2']).T\n",
    "\n",
    "rank = 13\n",
    "alpha = 1e-7\n",
    "beta = 1e-7\n",
    "n_fac = rank\n",
    "\n",
    "# Grab the task ID of the current job (and the associated parameter dictionary)\n",
    "fac_subnet = np.random.uniform(low=0, high=1.0, size=(rank, cfg_matr.shape[1]))\n",
    "fac_coef = np.random.uniform(low=0, high=1.0, size=(rank, cfg_matr.shape[0]))\n",
    "\n",
    "# Run NMF Algorithm\n",
    "fac_subnet, fac_coef, err = Echobase.Network.Partitioning.Subgraph.nmf.snmf_bcd(\n",
    "    cfg_matr, alpha=alpha, beta=beta, fac_subnet_init=fac_subnet, fac_coef_init=fac_coef, \n",
    "    max_iter=20, sparse_dim='conn', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Subgraphs Based on Pos/Neg Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "abcd = list(string.ascii_uppercase)\n",
    "\n",
    "coef_ix = np.array(df_cfg['cfg_obs_lut'], dtype=int)\n",
    "\n",
    "# Re-rank subgraphs based on positive/negative expression\n",
    "del_expr_mean = []\n",
    "del_expr_stdv = []\n",
    "for fac_ii in xrange(n_fac):\n",
    "    #sel_fac_coef = df_subgraph['system_subgraph'][fac_ii]['expr_coef'][coef_ix]\n",
    "    sel_fac_coef = fac_coef[fac_ii, :][coef_ix]\n",
    "    pos_expr = sel_fac_coef[:, :, :, :, 0, :]\n",
    "    neg_expr = sel_fac_coef[:, :, :, :, 1, :]\n",
    "    del_expr = (pos_expr-neg_expr).mean(axis=-1).mean(axis=-1).mean(axis=-1).mean(axis=-1)\n",
    "    \n",
    "    del_expr_mean.append(del_expr.mean())\n",
    "    del_expr_stdv.append(del_expr.std() / np.sqrt(n_subj))    \n",
    "del_expr_mean = np.array(del_expr_mean)\n",
    "del_expr_stdv = np.array(del_expr_stdv)\n",
    "sort_fac = np.argsort(del_expr_mean)[::-1]\n",
    "\n",
    "# Create a sorted dictionary\n",
    "sort_fac_dict = {}\n",
    "for ltr, fac_ii in zip(abcd, sort_fac):\n",
    "    sort_fac_dict[ltr] = fac_ii\n",
    "\n",
    "\n",
    "# Plot distribution of mean relative expression\n",
    "plt.figure(dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(xrange(n_fac), del_expr_mean[sort_fac], yerr=del_expr_stdv[sort_fac], lw=0)\n",
    "\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.set_xticks(np.arange(n_fac)+0.4);\n",
    "ax.set_xticklabels(np.sort(sort_fac_dict.keys()));\n",
    "\n",
    "ax.set_xlim([0, n_fac])\n",
    "\n",
    "ax.set_xlabel('Subgraphs')\n",
    "ax.set_ylabel('Mean Relative Expression')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgraph Motion-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 / n_fac\n",
    "\n",
    "motion_rv = []\n",
    "motion_color = []\n",
    "motion_fac = []\n",
    "coef_ix = np.array(df_cfg['cfg_obs_lut'], dtype=int)\n",
    "for fac_key in np.sort(sort_fac_dict.keys()):\n",
    "    fac_ii = sort_fac_dict[fac_key]\n",
    "    #sel_fac_coef = df_subgraph['system_subgraph'][fac_ii]['expr_coef'][coef_ix]\n",
    "    sel_fac_coef = fac_coef[fac_ii, :][coef_ix]    \n",
    "    fac_expr_subj = sel_fac_coef.reshape(n_subj, -1).mean(axis=-1)\n",
    "\n",
    "    rv, pv = stats.pearsonr(0.5*(df_motion['Stroop'] + df_motion['Navon']),\n",
    "                            fac_expr_subj)\n",
    "    motion_rv.append(rv)\n",
    "    \n",
    "    if pv < alpha:\n",
    "        motion_color.append('r')\n",
    "        motion_fac.append(fac_key)\n",
    "    else:\n",
    "        motion_color.append('k')\n",
    "        \n",
    "motion_rv = np.array(motion_rv)\n",
    "motion_color = np.array(motion_color)\n",
    "motion_fac = np.array(motion_fac)\n",
    "\n",
    "\n",
    "# Identify Subgraphs that correlate with motion\n",
    "plt.figure(dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(xrange(n_fac), motion_rv,\n",
    "       lw=0, color=motion_color)\n",
    "\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.set_xticks(np.arange(n_fac)+0.4);\n",
    "ax.set_xticklabels(np.sort(sort_fac_dict.keys()));\n",
    "\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_xlim([0, n_fac])\n",
    "\n",
    "ax.set_xlabel('Subgraphs')\n",
    "ax.set_ylabel('PearsonR(Expression, Motion)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Ranked System Subgraph Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "n_laus = len(df_to_yeo['yeo_lbl'])\n",
    "n_yeo = len(df_to_yeo['yeo_name'])\n",
    "\n",
    "fsize = 5.5\n",
    "fig = plt.figure(figsize=(6.9, 6.9), dpi=300)\n",
    "for ii, fac_key in enumerate(np.sort(sort_fac_dict.keys())):\n",
    "    if fac_key in motion_fac:\n",
    "        continue        \n",
    "    fac_ii = sort_fac_dict[fac_key]\n",
    "    \n",
    "    vmin, vmax = fac_subnet[fac_ii, :].min(), fac_subnet[fac_ii, :].max()\n",
    "    \n",
    "    ax = fig.add_subplot(5, 5, ii+1)\n",
    "    #sel_fac_subnet = df_subgraph['system_subgraph'][fac_ii]['subnet_roi']\n",
    "    sel_fac_subnet = convert_conn_vec_to_adj_matr(fac_subnet[fac_ii, :])[df_to_yeo['sort_laus_to_yeo'], :][:, df_to_yeo['sort_laus_to_yeo']]\n",
    "    mat = ax.matshow(sel_fac_subnet, cmap='magma', vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    for xx in df_to_yeo['yeo_adj_demarc']:\n",
    "        ax.vlines(xx, 0, n_laus, color='w', lw=0.25)\n",
    "        ax.hlines(xx, 0, n_laus, color='w', lw=0.25)\n",
    "\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_tick_params(width=0)                                \n",
    "    ax.xaxis.set_tick_params(width=0)\n",
    "    ax.grid(False)\n",
    "    ax.tick_params(axis='both', which='major', pad=-3)\n",
    "\n",
    "    ax.set_xticks((df_to_yeo['yeo_adj_demarc'][:-1] + (np.diff(df_to_yeo['yeo_adj_demarc']) * 0.5)));\n",
    "    ax.set_xticklabels(df_to_yeo['yeo_name'], fontsize=5.0, rotation=45)\n",
    "\n",
    "    ax.set_yticks((df_to_yeo['yeo_adj_demarc'][:-1] + (np.diff(df_to_yeo['yeo_adj_demarc']) * 0.5)));\n",
    "    ax.set_yticklabels(df_to_yeo['yeo_name'], fontsize=5.0, rotation=45)\n",
    "    \n",
    "fig.tight_layout(pad=0.01, h_pad=0.001, w_pad=0.001)\n",
    "fig.savefig('{}/Ranked_System_Subgraph.svg'.format(path_Figures))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expression Constrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stroop vs Navon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "coef_ix = np.array(df_cfg['cfg_obs_lut'], dtype=int)\n",
    "alpha = 0.05 #/ n_fac\n",
    "pv = []\n",
    "\n",
    "plt.figure(figsize=(4,6), dpi=300)\n",
    "for ii, fac_key in enumerate(np.sort(sort_fac_dict.keys())):\n",
    "    if fac_key in motion_fac:\n",
    "        continue        \n",
    "    fac_ii = sort_fac_dict[fac_key]\n",
    "\n",
    "    #sel_fac_coef = df_subgraph['system_subgraph'][fac_ii]['expr_coef'][coef_ix]\n",
    "    sel_fac_coef = fac_coef[fac_ii, :][coef_ix]    \n",
    "    pos_expr = sel_fac_coef[:, :, :, :, 0, :]\n",
    "    neg_expr = sel_fac_coef[:, :, :, :, 1, :]\n",
    "    \n",
    "    del_expr = (pos_expr-neg_expr).mean(axis=-1)[:, :, :, 1].mean(axis=-1)\n",
    "    del_expr_mean = del_expr.mean(axis=0)\n",
    "    del_expr_stdv = del_expr.std(axis=0) / np.sqrt(n_subj)    \n",
    "\n",
    "    # Within-experiment Stats\n",
    "    tv_expr, pv_expr = stats.ttest_rel(*del_expr.T)\n",
    "    pv.append(pv_expr)\n",
    "    \n",
    "    ax = plt.subplot(5,5,ii+1)\n",
    "    ax.bar([0,1], del_expr_mean,\n",
    "           yerr=del_expr_stdv,\n",
    "           width=0.4, lw=0)\n",
    "    \n",
    "    #ax.text(0.5, -4, 't={:2.2f}\\np={:2.1e}'.format(tv_expr, pv_expr), fontsize=3.0)\n",
    "    if pv_expr < alpha:\n",
    "        print(fac_key, '*')\n",
    "        #ax.text(0.65, -5, '*', fontsize=3.0)\n",
    "    \n",
    "    ax.set_title(fac_key)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xticks(np.array([0, 1]) + 0.2)\n",
    "    ax.set_xticklabels(df_cfg['cfg_key_label'][()]['Experiment_ID'])\n",
    "    #ax.set_ylim([-6.5, 6.5])\n",
    "\n",
    "#fig.savefig('{}/Ranked_System_Subgraph.svg'.format(path_Figures))\n",
    "plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lo vs Hi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "coef_ix = np.array(df_cfg['cfg_obs_lut'], dtype=int)\n",
    "alpha = 0.05 #/ n_fac\n",
    "\n",
    "color = [np.array([95, 127, 237]) / 255,\n",
    "         np.array([218, 85, 65]) / 255]\n",
    "\n",
    "plt.figure(figsize=(4,6), dpi=300)\n",
    "for ii, fac_key in enumerate(np.sort(sort_fac_dict.keys())):\n",
    "    if fac_key in motion_fac:\n",
    "        continue        \n",
    "    fac_ii = sort_fac_dict[fac_key]\n",
    "\n",
    "    ax = plt.subplot(5,5,ii+1)\n",
    "    \n",
    "    for expr_ii, expr_id in enumerate(df_cfg['cfg_key_label'][()]['Experiment_ID']):\n",
    "        #sel_fac_coef = df_subgraph['system_subgraph'][fac_ii]['expr_coef'][coef_ix]\n",
    "        sel_fac_coef = fac_coef[fac_ii, :][coef_ix]\n",
    "        pos_expr = sel_fac_coef[:, expr_ii, :, :, :, :][:, :, :, 0, :][:, :, 1, :]\n",
    "        neg_expr = sel_fac_coef[:, expr_ii, :, :, :, :][:, :, :, 1, :][:, :, 1, :]\n",
    "\n",
    "        del_expr = (pos_expr-neg_expr).mean(axis=-1)\n",
    "        del_expr_mean = del_expr.mean(axis=0)\n",
    "        del_expr_stdv = del_expr.std(axis=0) / np.sqrt(n_subj)    \n",
    "\n",
    "        # Within-experiment Stats\n",
    "        tv_expr, pv_expr = stats.ttest_rel(*del_expr.T)\n",
    "        if pv_expr < alpha:\n",
    "            clr = color[expr_ii]\n",
    "        else:\n",
    "            clr = [0.5, 0.5, 0.5]\n",
    "        \n",
    "\n",
    "        ax.bar([3*expr_ii+0, 3*expr_ii+1], del_expr_mean,\n",
    "               yerr=del_expr_stdv, color=clr,\n",
    "               width=0.4, lw=0)\n",
    "    #ax.text(0, 7, df_cfg['cfg_key_label'][()]['Experiment_ID'][0], fontsize=4.0)\n",
    "    #ax.text(3, 7, df_cfg['cfg_key_label'][()]['Experiment_ID'][1], fontsize=4.0)\n",
    "\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xticks(np.array([0, 1, 3, 4]) + 0.2)\n",
    "    ax.set_xticklabels(np.concatenate((df_cfg['cfg_key_label'][()]['Condition_ID'],\n",
    "                                       df_cfg['cfg_key_label'][()]['Condition_ID'])))\n",
    "    #ax.set_ylim([-6.5, 6.5])\n",
    "\n",
    "#fig.savefig('{}/Ranked_System_Subgraph.svg'.format(path_Figures))\n",
    "plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render t-stat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mayavi import mlab\n",
    "import nibabel as nib\n",
    "\n",
    "roi_ptcp = np.array([np.sum(tv[ii]*df_subgraph['system_subgraph'][fac_ii]['subnet_roi'], axis=0)\n",
    "                     for ii, fac_ii in enumerate(sort_fac)]).sum(axis=0)\n",
    "xmax = 10 #np.max([np.abs(roi_ptcp.min()), roi_ptcp.max()])\n",
    "\n",
    "brain_system_pixmap = {}\n",
    "view_angle = {'Sag_PA': [0.0, 90.0],\n",
    "              'Sag_AP': [180.0, 90.0]}\n",
    "\n",
    "# Get the pial surface recons\n",
    "pial_hemi = {'LH': {},\n",
    "             'RH': {}}\n",
    "pial_hemi['LH']['vert'], pial_hemi['LH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/lh.pial'.format(path_CoreData))\n",
    "pial_hemi['RH']['vert'], pial_hemi['RH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/rh.pial'.format(path_CoreData))\n",
    "\n",
    "# Get the Lausanne label files for each ROI\n",
    "label_files = []\n",
    "for roi in df_to_yeo['df_laus_yeo']:\n",
    "    laus_lbl = roi[1].lower()\n",
    "    hemi = roi[2].lower()\n",
    "\n",
    "    # Parse the atlas name and find the label file if it exists\n",
    "    lbl_file = '{}.{}.label'.format(hemi, laus_lbl)\n",
    "    lbl_file = lbl_file.replace(' ', '')\n",
    "\n",
    "    label_files.append('{}/BrainRenderSubject15/label/regenerated_{}_125/{}'.format(path_CoreData, hemi, lbl_file))\n",
    "\n",
    "# Iterate over hemisphere of the pial surface\n",
    "for hemi in pial_hemi.keys():\n",
    "    n_vert = len(pial_hemi[hemi]['vert'])\n",
    "    pial_scalars = np.ones(n_vert)\n",
    "\n",
    "    # Iterate over brain regions\n",
    "    for roi_ix, (roi, lbl_file) in enumerate(zip(df_to_yeo['df_laus_yeo'], label_files)):\n",
    "        if roi[2] != hemi:\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(lbl_file):\n",
    "            continue\n",
    "\n",
    "        # Load the file and add scalar to the vertices\n",
    "        parc_lbl = nib.freesurfer.io.read_label(lbl_file)                \n",
    "        pial_scalars[parc_lbl] = roi_ptcp[roi_ix]\n",
    "\n",
    "    # Plot the colored Brain System\n",
    "    fig = mlab.figure(bgcolor=(1.0, 1.0, 1.0))\n",
    "    src = mlab.pipeline.triangular_mesh_source(pial_hemi[hemi]['vert'][:,0],\n",
    "                                               pial_hemi[hemi]['vert'][:,1],\n",
    "                                               pial_hemi[hemi]['vert'][:,2],\n",
    "                                               pial_hemi[hemi]['tria'], scalars=pial_scalars, opacity=0.75, figure=fig)\n",
    "    norms = mlab.pipeline.poly_data_normals(src, figure=fig)\n",
    "    norms.filter.splitting = False\n",
    "    surf = mlab.pipeline.surface(norms, figure=fig)\n",
    "    surf.parent.scalar_lut_manager.set(lut_mode='coolwarm', data_range=[-xmax, xmax], use_default_range=False)\n",
    "    lut = surf.module_manager.scalar_lut_manager.lut.table.to_array()\n",
    "    surf.module_manager.scalar_lut_manager.lut.table = lut\n",
    "\n",
    "    # Rotate the view and save a screenshot\n",
    "    pixmap = {}\n",
    "    for ang in view_angle.keys():\n",
    "        mlab.view(azimuth=view_angle[ang][0],\n",
    "                  elevation=view_angle[ang][1])\n",
    "        pixmap[ang] = mlab.screenshot(mode='rgba')\n",
    "    mlab.close(all=True)\n",
    "\n",
    "    # Save to system pixmap dictionary\n",
    "    if not hemi in brain_system_pixmap.keys():\n",
    "        brain_system_pixmap[hemi] = pixmap\n",
    "\n",
    "#np.savez(pixmap_path,\n",
    "#     brain_system_pixmap=brain_system_pixmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgraph Regime Switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "coef_ix = np.array(df_cfg['cfg_obs_lut'], dtype=int)\n",
    "\n",
    "for expr_ii, expr_id in enumerate(df_cfg['cfg_key_label'][()]['Experiment_ID']):\n",
    "    \n",
    "    fac_pos_neg = np.zeros((len(df_cfg['cfg_key_label'][()]['Subject_ID']), n_fac, len(df_cfg['cfg_key_label'][()]['CorSign_ID'])))        \n",
    "    for ii, fac_key in enumerate(np.sort(sort_fac_dict.keys())):\n",
    "        if fac_key in motion_fac:\n",
    "            continue\n",
    "        fac_ii = sort_fac_dict[fac_key]\n",
    "        sel_fac_coef = df_subgraph['system_subgraph'][fac_ii]['expr_coef'][coef_ix] \n",
    "        sel_fac_coef = fac_coef[fac_ii, :][coef_ix]\n",
    "        for sgn_ii, sgn_id in enumerate(df_cfg['cfg_key_label'][()]['CorSign_ID']):     \n",
    "            lo_expr = sel_fac_coef[:, expr_ii, :, :, :, :][:, :, :, sgn_ii, :][:, 0, 1, :]\n",
    "            hi_expr = sel_fac_coef[:, expr_ii, :, :, :, :][:, :, :, sgn_ii, :][:, 1, 1, :]\n",
    "            \n",
    "            diff_expr = (hi_expr-lo_expr) / (hi_expr+lo_expr)\n",
    "            diff_expr = np.nan_to_num(diff_expr)\n",
    "            \n",
    "            rel_expr = np.nanmean(diff_expr, axis=-1)\n",
    "            \n",
    "            fac_pos_neg[:, ii, sgn_ii] = rel_expr\n",
    "\n",
    "    plt.figure(dpi=300)\n",
    "    ax = plt.subplot(111)\n",
    "    ax.scatter(fac_pos_neg.mean(axis=0)[:, 0], fac_pos_neg.mean(axis=0)[:, 1]);\n",
    "    print(stats.pearsonr(*fac_pos_neg.mean(axis=0).T))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "coef_ix = np.array(df_cfg['cfg_obs_lut'], dtype=int)\n",
    "\n",
    "for expr_ii, expr_id in enumerate(df_cfg['cfg_key_label'][()]['Experiment_ID']):\n",
    "    \n",
    "    lo_task = np.zeros((len(df_cfg['cfg_key_label'][()]['Subject_ID']), n_fac-len(motion_fac), len(df_cfg['cfg_key_label'][()]['CorSign_ID'])))\n",
    "    hi_task = np.zeros((len(df_cfg['cfg_key_label'][()]['Subject_ID']), n_fac-len(motion_fac), len(df_cfg['cfg_key_label'][()]['CorSign_ID'])))\n",
    "    \n",
    "    cnt = 0\n",
    "    for ii, fac_key in enumerate(np.sort(sort_fac_dict.keys())):\n",
    "        if fac_key in motion_fac:\n",
    "            continue\n",
    "        fac_ii = sort_fac_dict[fac_key]\n",
    "        #sel_fac_coef = df_subgraph['system_subgraph'][fac_ii]['expr_coef'][coef_ix] \n",
    "        sel_fac_coef = fac_coef[fac_ii, :][coef_ix]\n",
    "\n",
    "        for sgn_ii, sgn_id in enumerate(df_cfg['cfg_key_label'][()]['CorSign_ID']):\n",
    "            lo_task[:, cnt, sgn_ii] = sel_fac_coef[:, expr_ii, :, :, :, :][:, 0, 1, :, :][:, sgn_ii, :].mean(axis=-1)\n",
    "            hi_task[:, cnt, sgn_ii] = sel_fac_coef[:, expr_ii, :, :, :, :][:, 1, 1, :, :][:, sgn_ii, :].mean(axis=-1)\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    \n",
    "    plt.figure(dpi=300)\n",
    "    ax = plt.subplot(111)\n",
    "    ax.scatter(lo_task.mean(axis=0)[:, 0], lo_task.mean(axis=0)[:, 1], color='b')\n",
    "    ax.scatter(hi_task.mean(axis=0)[:, 0], hi_task.mean(axis=0)[:, 1], color='r')    \n",
    "    #print(stats.ttest_rel(lo_r, hi_r))\n",
    "    plt.show()\n",
    "    \n",
    "    lo_r = [np.arctanh(stats.spearmanr(*lo_task[:, ii, :].T)[0]) for ii in xrange(n_fac-len(motion_fac))]\n",
    "    hi_r = [np.arctanh(stats.spearmanr(*hi_task[:, ii, :].T)[0]) for ii in xrange(n_fac-len(motion_fac))]\n",
    "\n",
    "    plt.boxplot([lo_r, hi_r])\n",
    "    plt.show()\n",
    "    print(stats.ttest_rel(lo_r, hi_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "coef_ix = np.array(df_cfg['cfg_obs_lut'], dtype=int)\n",
    "perf_id = 'meanRT'\n",
    "\n",
    "for expr_ii, expr_id in enumerate(df_cfg['cfg_key_label'][()]['Experiment_ID']):\n",
    "    print\n",
    "    print(expr_id)\n",
    "    for ii, fac_key in enumerate(np.sort(sort_fac_dict.keys())):\n",
    "        #if fac_key in motion_fac:\n",
    "        #    continue\n",
    "        fac_ii = sort_fac_dict[fac_key]\n",
    "        #sel_fac_coef = df_subgraph['system_subgraph'][fac_ii]['expr_coef'][coef_ix]\n",
    "        sel_fac_coef = fac_coef[fac_ii, :][coef_ix]        \n",
    "        \n",
    "        pos_expr = sel_fac_coef[:, expr_ii, :, :, :, :][:, 0, 1, 0, :]\n",
    "        neg_expr = sel_fac_coef[:, expr_ii, :, :, :, :][:, 0, 1, 1, :]        \n",
    "        rel_expr_lo = pos_expr#-neg_expr\n",
    "\n",
    "        pos_expr = sel_fac_coef[:, expr_ii, :, :, :, :][:, 1, 1, 0, :]\n",
    "        neg_expr = sel_fac_coef[:, expr_ii, :, :, :, :][:, 1, 1, 1, :]        \n",
    "        rel_expr_hi = pos_expr#-neg_expr\n",
    "    \n",
    "        rel_expr = rel_expr_hi-rel_expr_lo\n",
    "        \n",
    "        rv, pv = stats.spearmanr(rel_expr.mean(axis=-1),\n",
    "                                 (df_perf[expr_id]['hi'][perf_id]-df_perf[expr_id]['lo'][perf_id]).mean(axis=-1))\n",
    "        print(rv, pv)\n",
    "        \n",
    "        if pv < 0.05:\n",
    "            plt.figure(figsize=(3,3), dpi=200.0)\n",
    "            ax = plt.subplot(111)\n",
    "            ax.scatter(rel_expr.mean(axis=-1),\n",
    "                       (df_perf[expr_id]['hi'][perf_id]-df_perf[expr_id]['lo'][perf_id]).mean(axis=-1))\n",
    "            ax.set_xlim([1.1*rel_expr.mean(axis=-1).min(), 1.1*rel_expr.mean(axis=-1).max()])\n",
    "            plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subgraph_beh_path = '{}/Subgraph.Behavior_Corr.npz'.format(path_ExpData)\n",
    "if not os.path.exists(subgraph_beh_path):\n",
    "    beh_stats_table = np.load(subgraph_beh_path)['stats_table'][()]\n",
    "else:\n",
    "    import statsmodels.api as sm\n",
    "    import statsmodels.graphics.regressionplots as regplot\n",
    "\n",
    "    beh_stats_table = {'Subgraph_ID': [],\n",
    "                       'Task': [],\n",
    "                       'Task_Cond': [],\n",
    "                       'Expr_Type': [],\n",
    "                       'rho': [],\n",
    "                       'pval': []}\n",
    "    \n",
    "    for task in df['Task_Type'].unique():\n",
    "        sel_task = df[df['Task_Type'] == task]\n",
    "        subg_task = sel_task.groupby(['Subgraph_ID', 'Subject_ID', 'Intr_Type', 'Cond_Type']).mean().unstack()\n",
    "\n",
    "        rs_pos = np.array(subg_task['Expression']['rs'].unstack()['pos'].unstack())\n",
    "        rs_neg = np.array(subg_task['Expression']['rs'].unstack()['neg'].unstack())    \n",
    "        hi_pos = np.array(subg_task['Expression']['hi'].unstack()['pos'].unstack())\n",
    "        hi_neg = np.array(subg_task['Expression']['hi'].unstack()['neg'].unstack())\n",
    "        lo_pos = np.array(subg_task['Expression']['lo'].unstack()['pos'].unstack())\n",
    "        lo_neg = np.array(subg_task['Expression']['lo'].unstack()['neg'].unstack())\n",
    "\n",
    "        hi_perf = subg_task['Performance']['hi'].unstack()['pos'].unstack().mean(axis=0)\n",
    "        lo_perf = subg_task['Performance']['lo'].unstack()['pos'].unstack().mean(axis=0)\n",
    "        cost_perf = hi_perf-lo_perf    \n",
    "\n",
    "        prf_pairs = [('Lo-Rs', lo_perf), ('Hi-Lo', cost_perf)]\n",
    "        pos_pairs = [[lo_pos, rs_pos], [hi_pos, lo_pos]]\n",
    "        neg_pairs = [[lo_neg, rs_neg], [hi_neg, lo_neg]]\n",
    "\n",
    "        print('\\n\\n\\n\\n\\n*****{}*****'.format(task))\n",
    "        for fac_ii in xrange(n_subgraph):\n",
    "            llbl = letter_lbl[subgraph_rank == fac_ii][0]\n",
    "            print(llbl)\n",
    "\n",
    "            for prf, pos, neg in zip(prf_pairs, pos_pairs, neg_pairs):\n",
    "                model1 = sm.OLS(prf[1], df_motion[task].T)\n",
    "                res1 = model1.fit().resid           \n",
    "\n",
    "                for mod_dir in [('Pos', pos),\n",
    "                                ('Neg', neg)]:\n",
    "                    mod_idx = mod_dir[1][0][fac_ii, :]-mod_dir[1][1][fac_ii, :]\n",
    "\n",
    "                    model2 = sm.OLS(mod_idx, df_motion[task].T)\n",
    "                    res2 = mod_idx #model2.fit().resid           \n",
    "\n",
    "                    real_rho, real_pval = stats.spearmanr(res2, res1)\n",
    "\n",
    "                    real_m, real_b, _, _, _ = stats.linregress(res2, res1)\n",
    "                    \"\"\"\n",
    "                    ### Permutation Tests\n",
    "                    null_rho_dist = []\n",
    "                    for n_i in xrange(10000):\n",
    "                        null_expr = np.random.permutation(np.array(subg_task['Expression']).reshape(-1)).reshape(n_subgraph, n_subj, 6)\n",
    "                        null_expr_1 = null_expr[fac_ii, :, 0]\n",
    "                        null_expr_2 = null_expr[fac_ii, :, 1]\n",
    "                        mod_idx_null = null_expr_1-null_expr_2\n",
    "\n",
    "                        model3 = sm.OLS(mod_idx_null, df_motion[task].T)\n",
    "                        res3 = mod_idx_null\n",
    "\n",
    "                        null_rho, _ = stats.spearmanr(res3, res1)\n",
    "                        null_rho_dist.append(null_rho)\n",
    "\n",
    "                    null_rho_dist = np.array(null_rho_dist)\n",
    "                    if real_rho > 0:\n",
    "                        real_pval = np.mean(null_rho_dist > real_rho)\n",
    "                    else:\n",
    "                        real_pval = np.mean(null_rho_dist < real_rho)\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    if real_pval < 0.05:\n",
    "                        sig = '*'\n",
    "                    else:\n",
    "                        sig = ' '\n",
    "                                        \n",
    "                    # Cache and Print output\n",
    "                    beh_stats_table['Subgraph_ID'].append(fac_ii)\n",
    "                    beh_stats_table['Task'].append(task)\n",
    "                    beh_stats_table['Task_Cond'].append(prf[0])\n",
    "                    beh_stats_table['Expr_Type'].append(mod_dir[0])\n",
    "                    beh_stats_table['rho'].append(real_rho)\n",
    "                    beh_stats_table['pval'].append(real_pval)\n",
    "                    \n",
    "                    print('%s, %s, %0.4f, %0.4f, %s' % \n",
    "                          (prf[0], mod_dir[0], real_rho, real_pval, sig))\n",
    "\n",
    "                    \"\"\"\n",
    "                    # First, plot the 2D real distribution and ellipsoid errors\n",
    "                    plt.figure()\n",
    "                    ax = plt.subplot(111)\n",
    "\n",
    "                    ax.scatter(res2, res1,\n",
    "                               s=20, lw=0, color=[0.5, 0.5, 0.5])        \n",
    "\n",
    "\n",
    "                    # Next, plot the linear fits\n",
    "                    x = np.array([res2.min(), res2.max()])\n",
    "                    y = real_m*x + real_b\n",
    "                    ax.plot(x, y, color='k', lw=1.0)   \n",
    "                    ax.text(0.75*(x.max()+x.min()),\n",
    "                            0.75*(y.max()+y.min()),\n",
    "                            'r=%0.3f\\np=%0.3f' % (real_rho, real_pval))  \n",
    "\n",
    "                    # Get the axis boundaries\n",
    "                    x_bound = 1.05*np.max([np.abs(res2.min()),\n",
    "                                           np.abs(res2.max())])\n",
    "                    y_bound = 1.05*np.max([np.abs(res1.min()),\n",
    "                                           np.abs(res1.max())])\n",
    "                    ax.set_xlim([-x_bound, x_bound])\n",
    "                    ax.set_ylim([-y_bound, y_bound])                \n",
    "\n",
    "                    plt.savefig('{}/{}.Subgraph_{}.{}.{}.svg'.format(path_Figures, task, llbl,\n",
    "                                                                     prf[0], mod_dir[0]))\n",
    "\n",
    "                    plt.close()\n",
    "                    \"\"\"\n",
    "    df_stats_table = pd.DataFrame(beh_stats_table, columns=beh_stats_table.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional Contribution to Modulation in Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_subgraph = np.array([subg['full_subg'] for subg in sys_subgraph])\n",
    "all_subg_cfg = convert_adj_matr_to_cfg_matr(all_subgraph)\n",
    "\n",
    "roi_subg_partc = np.mean(all_subgraph, axis=2)\n",
    "\n",
    "### Surrogate ROI Participation Coefficient\n",
    "\"\"\"\n",
    "n_perm = 1000\n",
    "null_roi_subg_partc = []\n",
    "for null_ii in xrange(n_perm):\n",
    "    null_subg_cfg = np.array([convert_conn_vec_to_adj_matr(subg)\n",
    "                              for subg in np.random.permutation(all_subg_cfg.T).T])    \n",
    "    null_roi_subg_partc.append(np.mean(null_subg_cfg, axis=2))\n",
    "null_roi_subg_partc = np.array(null_roi_subg_partc)\n",
    "\"\"\"\n",
    "\n",
    "### Project Subgraph Performance to the ROI Participation Coefficient\n",
    "roi_corr_partc_thrshd = {}\n",
    "for task in np.unique(df_stats_table['Task']):\n",
    "    for task_cond in np.unique(df_stats_table['Task_Cond']):\n",
    "        sel_stats = df_stats_table.loc[(df_stats_table['Task'] == task) & \n",
    "                                       (df_stats_table['Task_Cond'] == task_cond)]\n",
    "\n",
    "        pos_rho = sel_stats[sel_stats['Expr_Type'] == 'Pos']['rho']\n",
    "        neg_rho = -1*sel_stats[sel_stats['Expr_Type'] == 'Neg']['rho']\n",
    "        subg_corr = (np.array(pos_rho) + np.array(neg_rho)) / 2.0\n",
    "        behpos_ix = subg_corr > 0\n",
    "        behneg_ix = subg_corr < 0        \n",
    "        \n",
    "        for perf_type in [('BehPos', behpos_ix),\n",
    "                          ('BehNeg', behneg_ix)]:\n",
    "            key_name = '{}.{}.{}'.format(task, task_cond, perf_type[0])\n",
    "            \n",
    "            if perf_type[0] == 'BehNeg':\n",
    "                sel_subg_corr = -1*subg_corr[perf_type[1]]\n",
    "            else:\n",
    "                sel_subg_corr = subg_corr[perf_type[1]]\n",
    "                \n",
    "            roi_corr_partc = np.dot(sel_subg_corr, roi_subg_partc[perf_type[1], :])\n",
    "\n",
    "            ### Threshold using the null distribution\n",
    "            null_roi_corr_partc = []\n",
    "            for null_ii in xrange(n_perm):\n",
    "                null_roi_corr_partc.append(np.dot(sel_subg_corr,  null_roi_subg_partc[null_ii, :, :][perf_type[1], :]))\n",
    "            null_roi_corr_partc = np.array([null_roi_corr_partc]).reshape(-1)\n",
    "\n",
    "            null_max_thr = np.percentile(null_roi_corr_partc, 100)\n",
    "\n",
    "            roi_corr_partc_thrshd[key_name] = roi_corr_partc.copy()\n",
    "            roi_corr_partc_thrshd[key_name][roi_corr_partc < null_max_thr] = np.nan\n",
    "            \n",
    "\n",
    "            # Compute the histogram bin range using the\n",
    "            # real and null distribution range\n",
    "            xmin = roi_corr_partc.min()\n",
    "            xmax = roi_corr_partc.max()\n",
    "            real_bin_range = np.linspace(xmin, xmax, 50)            \n",
    "            null_xmin = null_roi_corr_partc.min()\n",
    "            null_xmax = null_roi_corr_partc.max()\n",
    "            null_bin_range = np.linspace(null_xmin, null_xmax, 1000)            \n",
    "\n",
    "            ### Histogram Plots            \n",
    "            fig = plt.figure(figsize=(3,3), dpi=300)\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.hist(roi_corr_partc, bins=real_bin_range,\n",
    "                    color='r', alpha=0.3, lw=0, normed=True)\n",
    "            ax.hist(null_roi_corr_partc, bins=null_bin_range,\n",
    "                    color='k', alpha=0.3, lw=0, normed=True)\n",
    "            ax.vlines(null_xmin, 0, 800)\n",
    "            ax.vlines(null_xmax, 0, 800)            \n",
    "            ax.xaxis.set_ticks_position('bottom')\n",
    "            ax.yaxis.set_ticks_position('left')\n",
    "            ax.set_xlim([0.0, 0.01])\n",
    "            ax.set_ylim([0.0, 5000])            \n",
    "            ax.set_title(key_name)\n",
    "            fig.savefig('{}/ROI_Partc_Perf.{}.svg'.format(path_Figures, key_name))\n",
    "            plt.close()\n",
    "            \n",
    "            ### Print an ordered list of the significant brain regions\n",
    "            print\n",
    "            print\n",
    "            print('***** {} *****'.format(key_name))\n",
    "            good_ix = ~np.isnan(np.sort(roi_corr_partc_thrshd[key_name])[::-1])\n",
    "            sig_roi = atlas_lbl[np.argsort(roi_corr_partc_thrshd[key_name])[::-1]][good_ix] \n",
    "            sig_roi, ind = np.unique([roi.split('_')[1] for roi in sig_roi], return_index=True)\n",
    "            print(sig_roi[np.argsort(ind)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage, TextArea\n",
    "from mayavi import mlab\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "view_angle = {'Sag_PA': [0.0, 90.0],\n",
    "              'Sag_AP': [180.0, 90.0]}\n",
    "\n",
    "# Get the pial surface recons\n",
    "pial_hemi = {'LH': {},\n",
    "             'RH': {}}\n",
    "pial_hemi['LH']['vert'], pial_hemi['LH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/lh.pial'.format(path_CoreData))\n",
    "pial_hemi['RH']['vert'], pial_hemi['RH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/rh.pial'.format(path_CoreData))\n",
    "\n",
    "# Get the Lausanne label files for each ROI\n",
    "label_files = []\n",
    "for roi in df_system['lausanne_labels']:\n",
    "    hemi = roi.split('_')[0].lower()\n",
    "\n",
    "    # Parse the atlas name and find the label file if it exists\n",
    "    if len(roi.split('_')) == 2:\n",
    "        lbl_file = ('%s.%s.label' % tuple(roi.split('_'))).lower()\n",
    "    elif len(roi.split('_')) == 3:\n",
    "        lbl_file = ('%s.%s_%s.label' % tuple(roi.split('_'))).lower()\n",
    "    else:\n",
    "        raise Exception\n",
    "    lbl_file = lbl_file.replace(' ', '')\n",
    "\n",
    "    label_files.append('{}/BrainRenderSubject15/label/regenerated_{}_125/{}'.format(path_CoreData, hemi, lbl_file))\n",
    "\n",
    "    \n",
    "# Iterate over experimental conditions\n",
    "for corr_key in roi_corr_partc_thrshd.keys():\n",
    "    xmin = np.percentile(roi_corr_partc_thrshd[corr_key][~np.isnan(roi_corr_partc_thrshd[corr_key])], 0)\n",
    "    xmax = np.percentile(roi_corr_partc_thrshd[corr_key][~np.isnan(roi_corr_partc_thrshd[corr_key])], 95)\n",
    "    \n",
    "    pixmap = {}\n",
    "    for hemi in pial_hemi.keys():\n",
    "        n_vert = len(pial_hemi[hemi]['vert'])\n",
    "        pial_scalars = np.zeros(n_vert)\n",
    "\n",
    "        # Iterate over ROIs\n",
    "        for roi_ix, (roi, lbl_file) in enumerate(zip(df_system['lausanne_labels'],\n",
    "                                                     label_files)):\n",
    "            if roi.split('_')[0] != hemi:\n",
    "                continue\n",
    "\n",
    "            if not os.path.exists(lbl_file):\n",
    "                continue\n",
    "\n",
    "            # Load the file and add scalar to the vertices\n",
    "            parc_lbl = nib.freesurfer.io.read_label(lbl_file)   \n",
    "            if not np.isnan(roi_corr_partc_thrshd[corr_key][roi_ix]):\n",
    "                pial_scalars[parc_lbl] = roi_corr_partc_thrshd[corr_key][roi_ix]\n",
    "\n",
    "        # Plot the colored Brain System\n",
    "        fig = mlab.figure(bgcolor=(1.0, 1.0, 1.0))\n",
    "        src = mlab.pipeline.triangular_mesh_source(pial_hemi[hemi]['vert'][:,0],\n",
    "                                                   pial_hemi[hemi]['vert'][:,1],\n",
    "                                                   pial_hemi[hemi]['vert'][:,2],\n",
    "                                                   pial_hemi[hemi]['tria'], scalars=pial_scalars, opacity=0.45, figure=fig)\n",
    "        norms = mlab.pipeline.poly_data_normals(src, figure=fig)\n",
    "        norms.filter.splitting = False\n",
    "        surf = mlab.pipeline.surface(norms, figure=fig)\n",
    "        if corr_key.split('.')[-1] == 'BehNeg':\n",
    "            cmap = 'Blues'\n",
    "        else:\n",
    "            cmap = 'Reds'\n",
    "        surf.parent.scalar_lut_manager.set(lut_mode=cmap, data_range=[xmin, xmax], use_default_range=False)\n",
    "        lut = surf.module_manager.scalar_lut_manager.lut.table.to_array()\n",
    "        surf.module_manager.scalar_lut_manager.lut.table = lut\n",
    "\n",
    "        # Rotate the view and save a screenshot\n",
    "        for ang in view_angle.keys():\n",
    "            mlab.view(azimuth=view_angle[ang][0],\n",
    "                      elevation=view_angle[ang][1])\n",
    "            pixmap['{}_{}'.format(hemi, ang)] = mlab.screenshot(mode='rgba')\n",
    "        mlab.close(all=True)\n",
    "    \n",
    "    ### Plot the pixmap\n",
    "    fig = plt.figure(figsize=(2,2), dpi=300)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    pixmap_key = [('LH_Sag_AP', False, (0.25, 0.575)),\n",
    "                  ('RH_Sag_PA', False, (0.75, 0.575)),\n",
    "                  ('LH_Sag_PA', True, (0.25, 0.225)),\n",
    "                  ('RH_Sag_AP', True, (0.75, 0.225))]\n",
    "\n",
    "    for px_key in pixmap_key:\n",
    "        if px_key[1] == True:\n",
    "            imagebox = OffsetImage(pixmap[px_key[0]][:, ::-1, :], zoom=0.65)\n",
    "        else:\n",
    "            imagebox = OffsetImage(pixmap[px_key[0]], zoom=0.65)\n",
    "        imagebox.axes = fig.axes[0]\n",
    "        ab = AnnotationBbox(imagebox, \n",
    "                            xy=px_key[2],\n",
    "                            xycoords='data',\n",
    "                            frameon=False,\n",
    "                            pad=0.0)\n",
    "        fig.axes[0].add_artist(ab)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title('{}\\n{}'.format(corr_key, xmax))\n",
    "    fig.savefig('{}/ROI_Partc_Perf.Atlas.{}.svg'.format(path_Figures, corr_key))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.subplot(211)\n",
    "mat = ax.imshow(pixmap[px_key[0]], cmap='Blues')\n",
    "ax.set_axis_off()\n",
    "plt.colorbar(mat, ax=ax)\n",
    "\n",
    "ax = plt.subplot(221)\n",
    "mat = ax.imshow(pixmap[px_key[0]], cmap='Reds')\n",
    "ax.set_axis_off()\n",
    "plt.colorbar(mat, ax=ax)\n",
    "\n",
    "plt.savefig('{}/Blues_Reds_CB.svg'.format(path_Figures))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "282px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "897px",
    "left": "0px",
    "right": "1707px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "376px",
   "left": "1514.75px",
   "right": "20px",
   "top": "210px",
   "width": "327px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
