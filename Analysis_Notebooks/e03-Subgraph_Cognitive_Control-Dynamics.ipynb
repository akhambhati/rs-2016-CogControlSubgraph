{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev1 toc-item\"><a href=\"#Generate-list-of-data\" data-toc-modified-id=\"Generate-list-of-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Generate list of data</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load Data</a></div><div class=\"lev2 toc-item\"><a href=\"#Organize-DataFrame\" data-toc-modified-id=\"Organize-DataFrame-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Organize DataFrame</a></div><div class=\"lev1 toc-item\"><a href=\"#Rank-Subgraphs-Based-on-Sparsity\" data-toc-modified-id=\"Rank-Subgraphs-Based-on-Sparsity-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Rank Subgraphs Based on Sparsity</a></div><div class=\"lev1 toc-item\"><a href=\"#Plot-Ranked-System-Subgraph-Matrices\" data-toc-modified-id=\"Plot-Ranked-System-Subgraph-Matrices-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Plot Ranked System Subgraph Matrices</a></div><div class=\"lev1 toc-item\"><a href=\"#Task-Related-Constrasts\" data-toc-modified-id=\"Task-Related-Constrasts-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Task-Related Constrasts</a></div><div class=\"lev2 toc-item\"><a href=\"#Check-Biases\" data-toc-modified-id=\"Check-Biases-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Check Biases</a></div><div class=\"lev3 toc-item\"><a href=\"#Task-Type\" data-toc-modified-id=\"Task-Type-511\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Task Type</a></div><div class=\"lev3 toc-item\"><a href=\"#Interaction-Type\" data-toc-modified-id=\"Interaction-Type-512\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Interaction Type</a></div><div class=\"lev2 toc-item\"><a href=\"#Between-Task-Subgraph-Contrast\" data-toc-modified-id=\"Between-Task-Subgraph-Contrast-52\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Between-Task Subgraph Contrast</a></div><div class=\"lev2 toc-item\"><a href=\"#Within-Task-Subgraph-Contrast\" data-toc-modified-id=\"Within-Task-Subgraph-Contrast-53\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Within-Task Subgraph Contrast</a></div><div class=\"lev1 toc-item\"><a href=\"#Task-Performance\" data-toc-modified-id=\"Task-Performance-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Task Performance</a></div><div class=\"lev2 toc-item\"><a href=\"#Behavioral-Correlation\" data-toc-modified-id=\"Behavioral-Correlation-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Behavioral Correlation</a></div><div class=\"lev2 toc-item\"><a href=\"#Regional-Contribution-to-Modulation-in-Performance\" data-toc-modified-id=\"Regional-Contribution-to-Modulation-in-Performance-62\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Regional Contribution to Modulation in Performance</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(matplotlib.rcParams)\n",
    "\n",
    "path_Remotes = '/Users/akhambhati/Remotes'\n",
    "path_CoreData = path_Remotes + '/CORE.fMRI_cogcontrol.medaglia'\n",
    "path_PeriphData = path_Remotes + '/RSRCH.NMF_CogControl'\n",
    "path_InpData = path_PeriphData + '/e02b-FuncSubg'\n",
    "path_ExpData = path_PeriphData + '/e03-FuncSubg_Dynamics'\n",
    "path_Figures = './e03-Figures/'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate list of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load Subgraph Data\n",
    "df_system = np.load('{}/Subgraph.All.npz'.format(path_InpData))\n",
    "sys_names = df_system['system_names']\n",
    "sys_lbl = df_system['system_labels']\n",
    "atlas_lbl = df_system['lausanne_labels']\n",
    "sys_subgraph = df_system['system_subgraph']\n",
    "\n",
    "n_subgraph = len(sys_subgraph)\n",
    "key_type = df_system['task_key']\n",
    "\n",
    "task_order = ['Stroop', 'Navon']\n",
    "intr_order = ['pos', 'neg']\n",
    "cond_order = ['rs', 'lo', 'hi']\n",
    "n_subj = sys_subgraph[0]['expr_coef'].shape[0]\n",
    "n_block = sys_subgraph[0]['expr_coef'].shape[2]\n",
    "\n",
    "\n",
    "# Load Behavioral Data\n",
    "df_blk = io.loadmat('{}/BlockwiseDataCorrectTrialsOnly.mat'.format(path_CoreData))\n",
    "bad_subj_ix = [1, 6]\n",
    "good_subj_ix = np.setdiff1d(np.arange(n_subj+2), bad_subj_ix)\n",
    "df_perf = {'Stroop': {'lo': df_blk['StroopData'][good_subj_ix, 4, :],\n",
    "                      'hi': df_blk['StroopData'][good_subj_ix, 2, :]},\n",
    "           'Navon' : {'lo': df_blk['NavonData'][good_subj_ix, 4, :],\n",
    "                      'hi': df_blk['NavonData'][good_subj_ix, 2, :]}}\n",
    "\n",
    "\"\"\"\n",
    "'high control accuracy', 'low control accuracy', 'high control mean RT',\n",
    "'high control median RT', 'low control mean RT', 'low control median RT'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Load Motion Data\n",
    "df_motion = {'Stroop': io.loadmat('{}/StroopMove.mat'.format(path_CoreData))['move'][:, 0],\n",
    "             'Navon': io.loadmat('{}/NavonMove.mat'.format(path_CoreData))['move'][:, 0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fac_expr_dict = {'Subgraph_ID': [],\n",
    "                 'Subject_ID': [],\n",
    "                 'Block_ID': [],\n",
    "                 'Performance': [],\n",
    "                 'Task_Type': [],\n",
    "                 'Intr_Type': [],\n",
    "                 'Cond_Type': [],\n",
    "                 'Expression': []}\n",
    "\n",
    "for fac_ii in xrange(n_subgraph):    \n",
    "    for task in task_order:        \n",
    "        for intr in intr_order:\n",
    "            for cond in cond_order:\n",
    "                key_ix = np.flatnonzero(key_type == 'adj_{}_{}_{}'.format(cond, intr, task))\n",
    "                subj_coef = sys_subgraph[fac_ii]['expr_coef'][:, key_ix, :].squeeze()\n",
    "                                \n",
    "                for subj_id in xrange(n_subj):\n",
    "                    for block_id in xrange(n_block):\n",
    "                        \n",
    "                        # performance\n",
    "                        try:\n",
    "                            perf = df_perf[task][cond][subj_id, block_id]\n",
    "                        except:\n",
    "                            perf = np.nan\n",
    "\n",
    "                        fac_expr_dict['Subgraph_ID'].append(fac_ii)\n",
    "                        fac_expr_dict['Subject_ID'].append(subj_id)\n",
    "                        fac_expr_dict['Block_ID'].append(block_id)\n",
    "                        fac_expr_dict['Performance'].append(perf)\n",
    "                        fac_expr_dict['Task_Type'].append(task)\n",
    "                        fac_expr_dict['Intr_Type'].append(intr)\n",
    "                        fac_expr_dict['Cond_Type'].append(cond)\n",
    "                        fac_expr_dict['Expression'].append(subj_coef[subj_id, block_id]) \n",
    "df = pd.DataFrame(fac_expr_dict, columns=fac_expr_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Subgraphs Based on Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_sparsity = np.array([np.mean(sys_subgraph[fac_ii]['expr_coef'] == 0)\n",
    "                                for fac_ii in xrange(n_subgraph)])\n",
    "\n",
    "subgraph_rank = np.argsort(expression_sparsity)[::-1]\n",
    "letter_lbl = np.array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'])\n",
    "for fac_ii in xrange(n_subgraph):\n",
    "    print(subgraph_rank[fac_ii], letter_lbl[fac_ii])\n",
    "    \n",
    "    \n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(expression_sparsity[subgraph_rank])\n",
    "ax.set_xlim([-0.5, 16.5])\n",
    "ax.set_ylim([0, 1.0])\n",
    "\n",
    "ax.set_xlabel('Ranked Subgraphs')\n",
    "ax.set_ylabel('Expression Sparsity')\n",
    "ax.set_xticks(np.arange(0, 16))\n",
    "ax.set_xticklabels(letter_lbl)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig('{}/Subgraph_Rank.svg'.format(path_Figures))\n",
    "\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Ranked System Subgraph Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Colormap thresholds\n",
    "all_sys_edge = np.array([fac['sys_subg'].reshape(-1) for fac in sys_subgraph]).reshape(-1)\n",
    "vmin = np.percentile(all_sys_edge[np.nonzero(all_sys_edge)], 10)\n",
    "vmax = np.percentile(all_sys_edge[np.nonzero(all_sys_edge)], 90)\n",
    "\n",
    "fsize = 5.5\n",
    "fig = plt.figure(figsize=(6.9, 6.9), dpi=300)\n",
    "for ii in xrange(n_subgraph):\n",
    "    ax = fig.add_subplot(4, 4, ii+1)\n",
    "    mat = ax.matshow(sys_subgraph[subgraph_rank[ii]]['sys_subg'], cmap='Reds') #, vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    ax.set_yticks(xrange(len(sys_names)))\n",
    "    ax.set_xticks(xrange(len(sys_names)))    \n",
    "    if ii+1 in [1,5,9]:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels(sys_names, fontsize=fsize)      \n",
    "    elif ii+1 in [14,15,16]:\n",
    "        ax.set_yticklabels([])   \n",
    "        ax.set_xticklabels(sys_names, fontsize=fsize, rotation=90)        \n",
    "    elif ii+1 in [13]:  \n",
    "        ax.set_yticklabels(sys_names, fontsize=fsize)      \n",
    "        ax.set_xticklabels(sys_names, fontsize=fsize, rotation=90)        \n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([]) \n",
    "    ax.set_title('Subgraph {}'.format(letter_lbl[ii]), fontsize=fsize)\n",
    "        \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "fig.tight_layout(pad=0.01, h_pad=0.001, w_pad=0.001)\n",
    "fig.savefig('{}/Ranked_System_Subgraph.svg'.format(path_Figures))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-Related Constrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_task = df.groupby(['Subject_ID', 'Task_Type']).mean().unstack()\n",
    "print(stats.ttest_rel(subj_task['Expression']['Navon'],\n",
    "                      subj_task['Expression']['Stroop']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_task = df.groupby(['Subject_ID', 'Intr_Type']).mean().unstack()\n",
    "print(stats.ttest_rel(subj_task['Expression']['pos'],\n",
    "                      subj_task['Expression']['neg']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Between-Task Subgraph Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "    \n",
    "# Subgraph/Task Bias Plot\n",
    "for intr in df['Intr_Type'].unique():\n",
    "    sel_intr = df[df['Intr_Type'] == intr]\n",
    "    subg_task = sel_intr.groupby(['Subgraph_ID', 'Subject_ID', 'Cond_Type', 'Task_Type']).mean().unstack()\n",
    "    \n",
    "    # Get the expression difference\n",
    "    diff_distrib_task = (subg_task['Expression']['Stroop'] - subg_task['Expression']['Navon']).unstack()\n",
    "    diff_distrib = np.array((0.5*diff_distrib_task['hi'] + 0.5*diff_distrib_task['lo']).unstack())\n",
    "    diff_means = diff_distrib.mean(axis=1)\n",
    "    diff_stderrs = diff_distrib.std(axis=1) / np.sqrt(diff_distrib.shape[1]) \n",
    "    \n",
    "    print(stats.f_oneway(*diff_distrib))\n",
    "        \n",
    "    # Permutation test\n",
    "    diff_distrib_null = []\n",
    "    for n_i in xrange(1000):\n",
    "        diff_distrib_null.append(np.random.permutation(diff_distrib.reshape(-1)).reshape(n_subgraph, -1).mean(axis=1))\n",
    "    min_null_thr = np.percentile(diff_distrib_null, 1.25)\n",
    "    max_null_thr = np.percentile(diff_distrib_null, 98.75)    \n",
    "    \n",
    "    # Color based on permutation test\n",
    "    colors = []\n",
    "    for fac_ii in xrange(n_subgraph):\n",
    "        if diff_means[fac_ii] < min_null_thr:\n",
    "            colors.append('r')\n",
    "        elif diff_means[fac_ii] > max_null_thr:\n",
    "                colors.append('b')\n",
    "        else:\n",
    "            colors.append('k')\n",
    "    colors = np.array(colors)    \n",
    "\n",
    "    # Reorder factors based on the expression difference\n",
    "    ord_ix = np.argsort(diff_means)[::-1]\n",
    "    subgraph_rank_ord = np.array([np.flatnonzero(subgraph_rank == o_ii)[0]\n",
    "                                  for o_ii in ord_ix])\n",
    "    print(ord_ix)\n",
    "    print(letter_lbl[subgraph_rank_ord])\n",
    "    \n",
    "    # Multiple T-Tests\n",
    "    n_comp = n_subgraph * (n_subgraph-1) * 0.5\n",
    "    alpha = 0.05 / n_comp\n",
    "    t_table = np.zeros((n_subgraph, n_subgraph))\n",
    "    for iix in xrange(n_subgraph):\n",
    "        for iiy in xrange(n_subgraph):\n",
    "            tval, pval = stats.ttest_rel(diff_distrib[iix, :],\n",
    "                                         diff_distrib[iiy, :])\n",
    "            if pval < alpha:\n",
    "                t_table[ord_ix[iix], ord_ix[iiy]] = np.abs(tval)\n",
    "        \n",
    "    # Plot routine\n",
    "    plt.figure(figsize=(3,3), dpi=300)\n",
    "    ax = plt.subplot(111)\n",
    "    ax.barh(np.arange(n_subgraph),\n",
    "            diff_means[ord_ix],\n",
    "            xerr=diff_stderrs[ord_ix], \n",
    "            color=colors[ord_ix])\n",
    "    \n",
    "    ax.fill_between(np.linspace(min_null_thr, max_null_thr, 100),\n",
    "                    y1=-1, y2=n_subgraph, lw=0, alpha=0.2)\n",
    "    ax.vlines(0, -1, n_subgraph, color='k')\n",
    "    \n",
    "    max_expr = np.max(np.abs(diff_means)) + np.max(diff_stderrs)\n",
    "    ax.set_xlim([-1.1*max_expr, 1.1*max_expr])\n",
    "    ax.set_ylim([-1, n_subgraph])\n",
    "    \n",
    "    ax.set_xlabel('Difference in Expression')\n",
    "    ax.set_ylabel('Ranked Subgraphs')\n",
    "    ax.set_title(intr)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    plt.savefig('{}/Task_Specificity.{}.svg'.format(path_Figures, intr))\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(3,3), dpi=300)\n",
    "    ax = plt.subplot(111)\n",
    "    ax.matshow(t_table, cmap='Reds')\n",
    "    ax.set_xticks(np.arange(n_subgraph))\n",
    "    ax.set_xticklabels(letter_lbl[subgraph_rank_ord])\n",
    "    ax.set_yticks(np.arange(n_subgraph))    \n",
    "    ax.set_yticklabels(letter_lbl[subgraph_rank_ord])\n",
    "    \"\"\"\n",
    "    \n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Within-Task Subgraph Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "clr = [plt.cm.Set1(float(ii)/n_subgraph) for ii in xrange(n_subgraph)]\n",
    "\n",
    "\n",
    "for task in df['Task_Type'].unique():\n",
    "    \n",
    "    sel_task = df[df['Task_Type'] == task]\n",
    "    subg_task = sel_task.groupby(['Subgraph_ID', 'Subject_ID', 'Intr_Type', 'Cond_Type']).mean().unstack()\n",
    "\n",
    "    rs_pos = np.array(subg_task['Expression']['rs'].unstack()['pos'].unstack())\n",
    "    rs_neg = np.array(subg_task['Expression']['rs'].unstack()['neg'].unstack())    \n",
    "    hi_pos = np.array(subg_task['Expression']['hi'].unstack()['pos'].unstack())\n",
    "    hi_neg = np.array(subg_task['Expression']['hi'].unstack()['neg'].unstack())\n",
    "    lo_pos = np.array(subg_task['Expression']['lo'].unstack()['pos'].unstack())\n",
    "    lo_neg = np.array(subg_task['Expression']['lo'].unstack()['neg'].unstack())\n",
    "            \n",
    "    hi_perf = subg_task['Performance']['hi'].unstack()['pos'].unstack().mean(axis=0)\n",
    "    lo_perf = subg_task['Performance']['lo'].unstack()['pos'].unstack().mean(axis=0)\n",
    "    cost_perf = hi_perf-lo_perf    \n",
    "    \n",
    "    prf_pairs = [('Lo-Rs', lo_perf), ('Hi-Lo', cost_perf)]\n",
    "    pos_pairs = [[lo_pos, rs_pos], [hi_pos, lo_pos]]\n",
    "    neg_pairs = [[lo_neg, rs_neg], [hi_neg, lo_neg]]\n",
    "    \n",
    "    \n",
    "    print('\\n\\n\\n\\n\\n*****{}*****'.format(task))\n",
    "    for prf, pos, neg in zip(prf_pairs, pos_pairs, neg_pairs):\n",
    "        \n",
    "        pos_idx = (pos[0]-pos[1])\n",
    "        neg_idx = (neg[0]-neg[1])\n",
    "        \n",
    "        pos_idx_mean = pos_idx.mean(axis=1)\n",
    "        neg_idx_mean = neg_idx.mean(axis=1)        \n",
    "        pos_idx_stderr = pos_idx.std(axis=1) / np.sqrt(n_subj)\n",
    "        neg_idx_stderr = neg_idx.std(axis=1) / np.sqrt(n_subj)        \n",
    "        \n",
    "        real_m, real_b, _, _, _ = stats.linregress(pos_idx_mean, neg_idx_mean)\n",
    "        real_rho, real_pval = stats.spearmanr(pos_idx_mean, neg_idx_mean)\n",
    "\n",
    "        \"\"\"\n",
    "        ### Permutation Tests\n",
    "        null_rho_dist = []\n",
    "        for n_i in xrange(10000):\n",
    "            pos_null_1 = np.random.permutation(pos[0].reshape(-1)).reshape(n_subgraph, n_subj)\n",
    "            pos_null_2 = np.random.permutation(pos[1].reshape(-1)).reshape(n_subgraph, n_subj)\n",
    "            neg_null_1 = np.random.permutation(neg[0].reshape(-1)).reshape(n_subgraph, n_subj)\n",
    "            neg_null_2 = np.random.permutation(neg[1].reshape(-1)).reshape(n_subgraph, n_subj)\n",
    "            \n",
    "            pos_null_idx = (pos_null_1-pos_null_2).mean(axis=1)\n",
    "            neg_null_idx = (neg_null_1-neg_null_2).mean(axis=1)            \n",
    "            \n",
    "            null_rho, _ = stats.spearmanr(pos_null_idx, neg_null_idx)\n",
    "            null_rho_dist.append(null_rho)\n",
    "\n",
    "        null_rho_dist = np.array(null_rho_dist)\n",
    "        if real_rho > 0:\n",
    "            real_pval = np.mean(null_rho_dist > real_rho)\n",
    "        else:\n",
    "            real_pval = np.mean(null_rho_dist < real_rho)\n",
    "        \"\"\"\n",
    "            \n",
    "        ## Print out salient control subgraphs\n",
    "        # Find the subgraphs in each quadrant\n",
    "        q1 = np.intersect1d(np.flatnonzero(pos_idx_mean > 0),\n",
    "                            np.flatnonzero(neg_idx_mean > 0))\n",
    "        q2 = np.intersect1d(np.flatnonzero(pos_idx_mean < 0),\n",
    "                            np.flatnonzero(neg_idx_mean > 0))\n",
    "        q3 = np.intersect1d(np.flatnonzero(pos_idx_mean < 0),\n",
    "                            np.flatnonzero(neg_idx_mean < 0))\n",
    "        q4 = np.intersect1d(np.flatnonzero(pos_idx_mean > 0),\n",
    "                            np.flatnonzero(neg_idx_mean < 0))\n",
    "\n",
    "        # Order by distance away from (0,0)\n",
    "        for qi, qq in enumerate([q1, q2, q3, q4]):\n",
    "            qq_dist = qq[np.argsort(np.sqrt(pos_idx_mean[qq]**2 + neg_idx_mean[qq]**2))]  \n",
    "            qq_letter = [letter_lbl[np.flatnonzero(subgraph_rank == subg_id)][0]\n",
    "                         for subg_id in qq_dist]\n",
    "            print('Quadrant {}: {}'.format(qi+1, qq_letter))\n",
    "        \n",
    "        \n",
    "        # First, plot the 2D real distribution and ellipsoid errors\n",
    "        plt.figure()\n",
    "        ax = plt.subplot(111)\n",
    "        \n",
    "        for ii, fac_ii in enumerate(subgraph_rank):\n",
    "            \"\"\"\n",
    "            ang = (np.arctan2(pos_mod_idx_mean[fac_ii] - pos_mod_idx[fac_ii, :],\n",
    "                              neg_mod_idx_mean[fac_ii] - neg_mod_idx[fac_ii, :])\n",
    "                   * 180/np.pi)\n",
    "\n",
    "\n",
    "            ell = Ellipse(xy=(pos_mod_idx_mean[fac_ii],\n",
    "                              neg_mod_idx_mean[fac_ii]),\n",
    "                          width=pos_mod_idx_stderr[fac_ii],\n",
    "                          height=neg_mod_idx_stderr[fac_ii],\n",
    "                          angle=np.nanmean(ang))\n",
    "\n",
    "            #ax.add_artist(ell)\n",
    "            ell.set_alpha(0.4)\n",
    "            ell.set_facecolor(clr[ii])\n",
    "            ell.set_linewidth(0.0)\n",
    "            \"\"\"\n",
    "            ax.scatter(pos_idx_mean[fac_ii], neg_idx_mean[fac_ii],\n",
    "                       s=50, lw=0, color=clr[ii])        \n",
    "        \n",
    "        ax.legend(letter_lbl)  \n",
    "\n",
    "        # Next, plot the linear fits\n",
    "        x = np.array([-2.5, 2.5])\n",
    "        y = real_m*x + real_b\n",
    "        ax.plot(x, y, color='k', lw=1.0)   \n",
    "        ax.text(1.0, 0.3, 'rho=%0.3f\\np=%0.3f' % (real_rho, real_pval))     \n",
    "        \n",
    "        ax.set_xlim([-3.2, 3.2])\n",
    "        ax.set_ylim([-0.6, 0.6])\n",
    "        \n",
    "        plt.savefig('{}/{}_Control_Matrix.{}.svg'.format(path_Figures, task, prf[0]))\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subgraph_beh_path = '{}/Subgraph.Behavior_Corr.npz'.format(path_ExpData)\n",
    "if not os.path.exists(subgraph_beh_path):\n",
    "    beh_stats_table = np.load(subgraph_beh_path)['stats_table'][()]\n",
    "else:\n",
    "    import statsmodels.api as sm\n",
    "    import statsmodels.graphics.regressionplots as regplot\n",
    "\n",
    "    beh_stats_table = {'Subgraph_ID': [],\n",
    "                       'Task': [],\n",
    "                       'Task_Cond': [],\n",
    "                       'Expr_Type': [],\n",
    "                       'rho': [],\n",
    "                       'pval': []}\n",
    "    \n",
    "    for task in df['Task_Type'].unique():\n",
    "        sel_task = df[df['Task_Type'] == task]\n",
    "        subg_task = sel_task.groupby(['Subgraph_ID', 'Subject_ID', 'Intr_Type', 'Cond_Type']).mean().unstack()\n",
    "\n",
    "        rs_pos = np.array(subg_task['Expression']['rs'].unstack()['pos'].unstack())\n",
    "        rs_neg = np.array(subg_task['Expression']['rs'].unstack()['neg'].unstack())    \n",
    "        hi_pos = np.array(subg_task['Expression']['hi'].unstack()['pos'].unstack())\n",
    "        hi_neg = np.array(subg_task['Expression']['hi'].unstack()['neg'].unstack())\n",
    "        lo_pos = np.array(subg_task['Expression']['lo'].unstack()['pos'].unstack())\n",
    "        lo_neg = np.array(subg_task['Expression']['lo'].unstack()['neg'].unstack())\n",
    "\n",
    "        hi_perf = subg_task['Performance']['hi'].unstack()['pos'].unstack().mean(axis=0)\n",
    "        lo_perf = subg_task['Performance']['lo'].unstack()['pos'].unstack().mean(axis=0)\n",
    "        cost_perf = hi_perf-lo_perf    \n",
    "\n",
    "        prf_pairs = [('Lo-Rs', lo_perf), ('Hi-Lo', cost_perf)]\n",
    "        pos_pairs = [[lo_pos, rs_pos], [hi_pos, lo_pos]]\n",
    "        neg_pairs = [[lo_neg, rs_neg], [hi_neg, lo_neg]]\n",
    "\n",
    "        print('\\n\\n\\n\\n\\n*****{}*****'.format(task))\n",
    "        for fac_ii in xrange(n_subgraph):\n",
    "            llbl = letter_lbl[subgraph_rank == fac_ii][0]\n",
    "            print(llbl)\n",
    "\n",
    "            for prf, pos, neg in zip(prf_pairs, pos_pairs, neg_pairs):\n",
    "                model1 = sm.OLS(prf[1], df_motion[task].T)\n",
    "                res1 = model1.fit().resid           \n",
    "\n",
    "                for mod_dir in [('Pos', pos),\n",
    "                                ('Neg', neg)]:\n",
    "                    mod_idx = mod_dir[1][0][fac_ii, :]-mod_dir[1][1][fac_ii, :]\n",
    "\n",
    "                    model2 = sm.OLS(mod_idx, df_motion[task].T)\n",
    "                    res2 = mod_idx #model2.fit().resid           \n",
    "\n",
    "                    real_rho, real_pval = stats.spearmanr(res2, res1)\n",
    "\n",
    "                    real_m, real_b, _, _, _ = stats.linregress(res2, res1)\n",
    "                    \"\"\"\n",
    "                    ### Permutation Tests\n",
    "                    null_rho_dist = []\n",
    "                    for n_i in xrange(10000):\n",
    "                        null_expr = np.random.permutation(np.array(subg_task['Expression']).reshape(-1)).reshape(n_subgraph, n_subj, 6)\n",
    "                        null_expr_1 = null_expr[fac_ii, :, 0]\n",
    "                        null_expr_2 = null_expr[fac_ii, :, 1]\n",
    "                        mod_idx_null = null_expr_1-null_expr_2\n",
    "\n",
    "                        model3 = sm.OLS(mod_idx_null, df_motion[task].T)\n",
    "                        res3 = mod_idx_null\n",
    "\n",
    "                        null_rho, _ = stats.spearmanr(res3, res1)\n",
    "                        null_rho_dist.append(null_rho)\n",
    "\n",
    "                    null_rho_dist = np.array(null_rho_dist)\n",
    "                    if real_rho > 0:\n",
    "                        real_pval = np.mean(null_rho_dist > real_rho)\n",
    "                    else:\n",
    "                        real_pval = np.mean(null_rho_dist < real_rho)\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    if real_pval < 0.05:\n",
    "                        sig = '*'\n",
    "                    else:\n",
    "                        sig = ' '\n",
    "                                        \n",
    "                    # Cache and Print output\n",
    "                    beh_stats_table['Subgraph_ID'].append(fac_ii)\n",
    "                    beh_stats_table['Task'].append(task)\n",
    "                    beh_stats_table['Task_Cond'].append(prf[0])\n",
    "                    beh_stats_table['Expr_Type'].append(mod_dir[0])\n",
    "                    beh_stats_table['rho'].append(real_rho)\n",
    "                    beh_stats_table['pval'].append(real_pval)\n",
    "                    \n",
    "                    print('%s, %s, %0.4f, %0.4f, %s' % \n",
    "                          (prf[0], mod_dir[0], real_rho, real_pval, sig))\n",
    "\n",
    "                    \"\"\"\n",
    "                    # First, plot the 2D real distribution and ellipsoid errors\n",
    "                    plt.figure()\n",
    "                    ax = plt.subplot(111)\n",
    "\n",
    "                    ax.scatter(res2, res1,\n",
    "                               s=20, lw=0, color=[0.5, 0.5, 0.5])        \n",
    "\n",
    "\n",
    "                    # Next, plot the linear fits\n",
    "                    x = np.array([res2.min(), res2.max()])\n",
    "                    y = real_m*x + real_b\n",
    "                    ax.plot(x, y, color='k', lw=1.0)   \n",
    "                    ax.text(0.75*(x.max()+x.min()),\n",
    "                            0.75*(y.max()+y.min()),\n",
    "                            'r=%0.3f\\np=%0.3f' % (real_rho, real_pval))  \n",
    "\n",
    "                    # Get the axis boundaries\n",
    "                    x_bound = 1.05*np.max([np.abs(res2.min()),\n",
    "                                           np.abs(res2.max())])\n",
    "                    y_bound = 1.05*np.max([np.abs(res1.min()),\n",
    "                                           np.abs(res1.max())])\n",
    "                    ax.set_xlim([-x_bound, x_bound])\n",
    "                    ax.set_ylim([-y_bound, y_bound])                \n",
    "\n",
    "                    plt.savefig('{}/{}.Subgraph_{}.{}.{}.svg'.format(path_Figures, task, llbl,\n",
    "                                                                     prf[0], mod_dir[0]))\n",
    "\n",
    "                    plt.close()\n",
    "                    \"\"\"\n",
    "    df_stats_table = pd.DataFrame(beh_stats_table, columns=beh_stats_table.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Regional Contribution to Modulation in Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_subgraph = np.array([subg['full_subg'] for subg in sys_subgraph])\n",
    "all_subg_cfg = convert_adj_matr_to_cfg_matr(all_subgraph)\n",
    "\n",
    "roi_subg_partc = np.mean(all_subgraph, axis=2)\n",
    "\n",
    "### Surrogate ROI Participation Coefficient\n",
    "\"\"\"\n",
    "n_perm = 1000\n",
    "null_roi_subg_partc = []\n",
    "for null_ii in xrange(n_perm):\n",
    "    null_subg_cfg = np.array([convert_conn_vec_to_adj_matr(subg)\n",
    "                              for subg in np.random.permutation(all_subg_cfg.T).T])    \n",
    "    null_roi_subg_partc.append(np.mean(null_subg_cfg, axis=2))\n",
    "null_roi_subg_partc = np.array(null_roi_subg_partc)\n",
    "\"\"\"\n",
    "\n",
    "### Project Subgraph Performance to the ROI Participation Coefficient\n",
    "roi_corr_partc_thrshd = {}\n",
    "for task in np.unique(df_stats_table['Task']):\n",
    "    for task_cond in np.unique(df_stats_table['Task_Cond']):\n",
    "        sel_stats = df_stats_table.loc[(df_stats_table['Task'] == task) & \n",
    "                                       (df_stats_table['Task_Cond'] == task_cond)]\n",
    "\n",
    "        pos_rho = sel_stats[sel_stats['Expr_Type'] == 'Pos']['rho']\n",
    "        neg_rho = -1*sel_stats[sel_stats['Expr_Type'] == 'Neg']['rho']\n",
    "        subg_corr = (np.array(pos_rho) + np.array(neg_rho)) / 2.0\n",
    "        behpos_ix = subg_corr > 0\n",
    "        behneg_ix = subg_corr < 0        \n",
    "        \n",
    "        for perf_type in [('BehPos', behpos_ix),\n",
    "                          ('BehNeg', behneg_ix)]:\n",
    "            key_name = '{}.{}.{}'.format(task, task_cond, perf_type[0])\n",
    "            \n",
    "            if perf_type[0] == 'BehNeg':\n",
    "                sel_subg_corr = -1*subg_corr[perf_type[1]]\n",
    "            else:\n",
    "                sel_subg_corr = subg_corr[perf_type[1]]\n",
    "                \n",
    "            roi_corr_partc = np.dot(sel_subg_corr, roi_subg_partc[perf_type[1], :])\n",
    "\n",
    "            ### Threshold using the null distribution\n",
    "            null_roi_corr_partc = []\n",
    "            for null_ii in xrange(n_perm):\n",
    "                null_roi_corr_partc.append(np.dot(sel_subg_corr,  null_roi_subg_partc[null_ii, :, :][perf_type[1], :]))\n",
    "            null_roi_corr_partc = np.array([null_roi_corr_partc]).reshape(-1)\n",
    "\n",
    "            null_max_thr = np.percentile(null_roi_corr_partc, 100)\n",
    "\n",
    "            roi_corr_partc_thrshd[key_name] = roi_corr_partc.copy()\n",
    "            roi_corr_partc_thrshd[key_name][roi_corr_partc < null_max_thr] = np.nan\n",
    "            \n",
    "\n",
    "            # Compute the histogram bin range using the\n",
    "            # real and null distribution range\n",
    "            xmin = roi_corr_partc.min()\n",
    "            xmax = roi_corr_partc.max()\n",
    "            real_bin_range = np.linspace(xmin, xmax, 50)            \n",
    "            null_xmin = null_roi_corr_partc.min()\n",
    "            null_xmax = null_roi_corr_partc.max()\n",
    "            null_bin_range = np.linspace(null_xmin, null_xmax, 1000)            \n",
    "\n",
    "            ### Histogram Plots            \n",
    "            fig = plt.figure(figsize=(3,3), dpi=300)\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.hist(roi_corr_partc, bins=real_bin_range,\n",
    "                    color='r', alpha=0.3, lw=0, normed=True)\n",
    "            ax.hist(null_roi_corr_partc, bins=null_bin_range,\n",
    "                    color='k', alpha=0.3, lw=0, normed=True)\n",
    "            ax.vlines(null_xmin, 0, 800)\n",
    "            ax.vlines(null_xmax, 0, 800)            \n",
    "            ax.xaxis.set_ticks_position('bottom')\n",
    "            ax.yaxis.set_ticks_position('left')\n",
    "            ax.set_xlim([0.0, 0.01])\n",
    "            ax.set_ylim([0.0, 5000])            \n",
    "            ax.set_title(key_name)\n",
    "            fig.savefig('{}/ROI_Partc_Perf.{}.svg'.format(path_Figures, key_name))\n",
    "            plt.close()\n",
    "            \n",
    "            ### Print an ordered list of the significant brain regions\n",
    "            print\n",
    "            print\n",
    "            print('***** {} *****'.format(key_name))\n",
    "            good_ix = ~np.isnan(np.sort(roi_corr_partc_thrshd[key_name])[::-1])\n",
    "            sig_roi = atlas_lbl[np.argsort(roi_corr_partc_thrshd[key_name])[::-1]][good_ix] \n",
    "            sig_roi, ind = np.unique([roi.split('_')[1] for roi in sig_roi], return_index=True)\n",
    "            print(sig_roi[np.argsort(ind)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage, TextArea\n",
    "from mayavi import mlab\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "view_angle = {'Sag_PA': [0.0, 90.0],\n",
    "              'Sag_AP': [180.0, 90.0]}\n",
    "\n",
    "# Get the pial surface recons\n",
    "pial_hemi = {'LH': {},\n",
    "             'RH': {}}\n",
    "pial_hemi['LH']['vert'], pial_hemi['LH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/lh.pial'.format(path_CoreData))\n",
    "pial_hemi['RH']['vert'], pial_hemi['RH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/rh.pial'.format(path_CoreData))\n",
    "\n",
    "# Get the Lausanne label files for each ROI\n",
    "label_files = []\n",
    "for roi in df_system['lausanne_labels']:\n",
    "    hemi = roi.split('_')[0].lower()\n",
    "\n",
    "    # Parse the atlas name and find the label file if it exists\n",
    "    if len(roi.split('_')) == 2:\n",
    "        lbl_file = ('%s.%s.label' % tuple(roi.split('_'))).lower()\n",
    "    elif len(roi.split('_')) == 3:\n",
    "        lbl_file = ('%s.%s_%s.label' % tuple(roi.split('_'))).lower()\n",
    "    else:\n",
    "        raise Exception\n",
    "    lbl_file = lbl_file.replace(' ', '')\n",
    "\n",
    "    label_files.append('{}/BrainRenderSubject15/label/regenerated_{}_125/{}'.format(path_CoreData, hemi, lbl_file))\n",
    "\n",
    "    \n",
    "# Iterate over experimental conditions\n",
    "for corr_key in roi_corr_partc_thrshd.keys():\n",
    "    xmin = np.percentile(roi_corr_partc_thrshd[corr_key][~np.isnan(roi_corr_partc_thrshd[corr_key])], 0)\n",
    "    xmax = np.percentile(roi_corr_partc_thrshd[corr_key][~np.isnan(roi_corr_partc_thrshd[corr_key])], 95)\n",
    "    \n",
    "    pixmap = {}\n",
    "    for hemi in pial_hemi.keys():\n",
    "        n_vert = len(pial_hemi[hemi]['vert'])\n",
    "        pial_scalars = np.zeros(n_vert)\n",
    "\n",
    "        # Iterate over ROIs\n",
    "        for roi_ix, (roi, lbl_file) in enumerate(zip(df_system['lausanne_labels'],\n",
    "                                                     label_files)):\n",
    "            if roi.split('_')[0] != hemi:\n",
    "                continue\n",
    "\n",
    "            if not os.path.exists(lbl_file):\n",
    "                continue\n",
    "\n",
    "            # Load the file and add scalar to the vertices\n",
    "            parc_lbl = nib.freesurfer.io.read_label(lbl_file)   \n",
    "            if not np.isnan(roi_corr_partc_thrshd[corr_key][roi_ix]):\n",
    "                pial_scalars[parc_lbl] = roi_corr_partc_thrshd[corr_key][roi_ix]\n",
    "\n",
    "        # Plot the colored Brain System\n",
    "        fig = mlab.figure(bgcolor=(1.0, 1.0, 1.0))\n",
    "        src = mlab.pipeline.triangular_mesh_source(pial_hemi[hemi]['vert'][:,0],\n",
    "                                                   pial_hemi[hemi]['vert'][:,1],\n",
    "                                                   pial_hemi[hemi]['vert'][:,2],\n",
    "                                                   pial_hemi[hemi]['tria'], scalars=pial_scalars, opacity=0.45, figure=fig)\n",
    "        norms = mlab.pipeline.poly_data_normals(src, figure=fig)\n",
    "        norms.filter.splitting = False\n",
    "        surf = mlab.pipeline.surface(norms, figure=fig)\n",
    "        if corr_key.split('.')[-1] == 'BehNeg':\n",
    "            cmap = 'Blues'\n",
    "        else:\n",
    "            cmap = 'Reds'\n",
    "        surf.parent.scalar_lut_manager.set(lut_mode=cmap, data_range=[xmin, xmax], use_default_range=False)\n",
    "        lut = surf.module_manager.scalar_lut_manager.lut.table.to_array()\n",
    "        surf.module_manager.scalar_lut_manager.lut.table = lut\n",
    "\n",
    "        # Rotate the view and save a screenshot\n",
    "        for ang in view_angle.keys():\n",
    "            mlab.view(azimuth=view_angle[ang][0],\n",
    "                      elevation=view_angle[ang][1])\n",
    "            pixmap['{}_{}'.format(hemi, ang)] = mlab.screenshot(mode='rgba')\n",
    "        mlab.close(all=True)\n",
    "    \n",
    "    ### Plot the pixmap\n",
    "    fig = plt.figure(figsize=(2,2), dpi=300)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    pixmap_key = [('LH_Sag_AP', False, (0.25, 0.575)),\n",
    "                  ('RH_Sag_PA', False, (0.75, 0.575)),\n",
    "                  ('LH_Sag_PA', True, (0.25, 0.225)),\n",
    "                  ('RH_Sag_AP', True, (0.75, 0.225))]\n",
    "\n",
    "    for px_key in pixmap_key:\n",
    "        if px_key[1] == True:\n",
    "            imagebox = OffsetImage(pixmap[px_key[0]][:, ::-1, :], zoom=0.65)\n",
    "        else:\n",
    "            imagebox = OffsetImage(pixmap[px_key[0]], zoom=0.65)\n",
    "        imagebox.axes = fig.axes[0]\n",
    "        ab = AnnotationBbox(imagebox, \n",
    "                            xy=px_key[2],\n",
    "                            xycoords='data',\n",
    "                            frameon=False,\n",
    "                            pad=0.0)\n",
    "        fig.axes[0].add_artist(ab)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title('{}\\n{}'.format(corr_key, xmax))\n",
    "    fig.savefig('{}/ROI_Partc_Perf.Atlas.{}.svg'.format(path_Figures, corr_key))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.subplot(211)\n",
    "mat = ax.imshow(pixmap[px_key[0]], cmap='Blues')\n",
    "ax.set_axis_off()\n",
    "plt.colorbar(mat, ax=ax)\n",
    "\n",
    "ax = plt.subplot(221)\n",
    "mat = ax.imshow(pixmap[px_key[0]], cmap='Reds')\n",
    "ax.set_axis_off()\n",
    "plt.colorbar(mat, ax=ax)\n",
    "\n",
    "plt.savefig('{}/Blues_Reds_CB.svg'.format(path_Figures))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "282px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "897px",
    "left": "0px",
    "right": "1707px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "376px",
   "left": "1514.75px",
   "right": "20px",
   "top": "210px",
   "width": "327px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
