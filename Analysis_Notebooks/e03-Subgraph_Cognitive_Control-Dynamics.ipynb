{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev1 toc-item\"><a href=\"#Generate-list-of-data\" data-toc-modified-id=\"Generate-list-of-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Generate list of data</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load Data</a></div><div class=\"lev2 toc-item\"><a href=\"#Organize-DataFrame\" data-toc-modified-id=\"Organize-DataFrame-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Organize DataFrame</a></div><div class=\"lev1 toc-item\"><a href=\"#Rank-Subgraphs-Based-on-Sparsity\" data-toc-modified-id=\"Rank-Subgraphs-Based-on-Sparsity-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Rank Subgraphs Based on Sparsity</a></div><div class=\"lev1 toc-item\"><a href=\"#Task-Related-Constrasts\" data-toc-modified-id=\"Task-Related-Constrasts-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Task-Related Constrasts</a></div><div class=\"lev2 toc-item\"><a href=\"#Check-Biases\" data-toc-modified-id=\"Check-Biases-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Check Biases</a></div><div class=\"lev3 toc-item\"><a href=\"#Task-Type\" data-toc-modified-id=\"Task-Type-411\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Task Type</a></div><div class=\"lev3 toc-item\"><a href=\"#Interaction-Type\" data-toc-modified-id=\"Interaction-Type-412\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Interaction Type</a></div><div class=\"lev2 toc-item\"><a href=\"#Between-Task-Subgraph-Contrast\" data-toc-modified-id=\"Between-Task-Subgraph-Contrast-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Between-Task Subgraph Contrast</a></div><div class=\"lev2 toc-item\"><a href=\"#Within-Task-Subgraph-Contrast\" data-toc-modified-id=\"Within-Task-Subgraph-Contrast-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Within-Task Subgraph Contrast</a></div><div class=\"lev1 toc-item\"><a href=\"#Task-Performance\" data-toc-modified-id=\"Task-Performance-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Task Performance</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "\n",
    "path_Remotes = '/Users/akhambhati/Remotes'\n",
    "path_CoreData = path_Remotes + '/CORE.fMRI_cogcontrol.medaglia'\n",
    "path_PeriphData = path_Remotes + '/RSRCH.NMF_CogControl'\n",
    "path_InpData = path_PeriphData + '/e02b-FuncSubg'\n",
    "path_ExpData = path_PeriphData + '/e03-FuncSubg_Dynamics'\n",
    "path_Figures = './e03-Figures/'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate list of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load Subgraph Data\n",
    "df_system = np.load('{}/Subgraph.All.npz'.format(path_InpData))\n",
    "sys_subgraph = df_system['system_subgraph']\n",
    "n_subgraph = len(sys_subgraph)\n",
    "key_type = df_system['task_key']\n",
    "\n",
    "task_order = ['Stroop', 'Navon']\n",
    "intr_order = ['pos', 'neg']\n",
    "cond_order = ['rs', 'lo', 'hi']\n",
    "n_subj = sys_subgraph[0]['expr_coef'].shape[0]\n",
    "n_block = sys_subgraph[0]['expr_coef'].shape[2]\n",
    "\n",
    "\n",
    "# Load Behavioral Data\n",
    "df_blk = io.loadmat('{}/BlockwiseDataCorrectTrialsOnly.mat'.format(path_CoreData))\n",
    "bad_subj_ix = [1, 6]\n",
    "good_subj_ix = np.setdiff1d(np.arange(n_subj+2), bad_subj_ix)\n",
    "df_perf = {'Stroop': {'lo': df_blk['StroopData'][good_subj_ix, 4, :],\n",
    "                      'hi': df_blk['StroopData'][good_subj_ix, 2, :]},\n",
    "           'Navon' : {'lo': df_blk['NavonData'][good_subj_ix, 4, :],\n",
    "                      'hi': df_blk['NavonData'][good_subj_ix, 2, :]}}\n",
    "\n",
    "\"\"\"\n",
    "'high control accuracy', 'low control accuracy', 'high control mean RT',\n",
    "'high control median RT', 'low control mean RT', 'low control median RT'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Load Motion Data\n",
    "df_motion = {'Stroop': io.loadmat('{}/StroopMove.mat'.format(path_CoreData))['move'][:, 0],\n",
    "             'Navon': io.loadmat('{}/NavonMove.mat'.format(path_CoreData))['move'][:, 0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fac_expr_dict = {'Subgraph_ID': [],\n",
    "                 'Subject_ID': [],\n",
    "                 'Block_ID': [],\n",
    "                 'Performance': [],\n",
    "                 'Task_Type': [],\n",
    "                 'Intr_Type': [],\n",
    "                 'Cond_Type': [],\n",
    "                 'Expression': []}\n",
    "\n",
    "for fac_ii in xrange(n_subgraph):    \n",
    "    for task in task_order:        \n",
    "        for intr in intr_order:\n",
    "            for cond in cond_order:\n",
    "                key_ix = np.flatnonzero(key_type == 'adj_{}_{}_{}'.format(cond, intr, task))\n",
    "                subj_coef = sys_subgraph[fac_ii]['expr_coef'][:, key_ix, :].squeeze()\n",
    "                                \n",
    "                for subj_id in xrange(n_subj):\n",
    "                    for block_id in xrange(n_block):\n",
    "                        \n",
    "                        # performance\n",
    "                        try:\n",
    "                            perf = df_perf[task][cond][subj_id, block_id]\n",
    "                        except:\n",
    "                            perf = np.nan\n",
    "\n",
    "                        fac_expr_dict['Subgraph_ID'].append(fac_ii)\n",
    "                        fac_expr_dict['Subject_ID'].append(subj_id)\n",
    "                        fac_expr_dict['Block_ID'].append(block_id)\n",
    "                        fac_expr_dict['Performance'].append(perf)\n",
    "                        fac_expr_dict['Task_Type'].append(task)\n",
    "                        fac_expr_dict['Intr_Type'].append(intr)\n",
    "                        fac_expr_dict['Cond_Type'].append(cond)\n",
    "                        fac_expr_dict['Expression'].append(subj_coef[subj_id, block_id]) \n",
    "df = pd.DataFrame(fac_expr_dict, columns=fac_expr_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Subgraphs Based on Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_sparsity = np.array([np.mean(sys_subgraph[fac_ii]['expr_coef'] == 0)\n",
    "                                for fac_ii in xrange(n_subgraph)])\n",
    "\n",
    "subgraph_rank = np.argsort(expression_sparsity)[::-1]\n",
    "letter_lbl = np.array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'])\n",
    "for fac_ii in xrange(n_subgraph):\n",
    "    print(subgraph_rank[fac_ii], letter_lbl[fac_ii])\n",
    "    \n",
    "    \n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(expression_sparsity[subgraph_rank])\n",
    "ax.set_xlim([-0.5, 16.5])\n",
    "ax.set_ylim([0, 1.0])\n",
    "\n",
    "ax.set_xlabel('Ranked Subgraphs')\n",
    "ax.set_ylabel('Expression Sparsity')\n",
    "ax.set_xticks(np.arange(0, 16))\n",
    "ax.set_xticklabels(letter_lbl)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig('{}/Subgraph_Rank.svg'.format(path_Figures))\n",
    "\n",
    "plt.show()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-Related Constrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_task = df.groupby(['Subject_ID', 'Task_Type']).mean().unstack()\n",
    "print(stats.ttest_rel(subj_task['Expression']['Navon'],\n",
    "                      subj_task['Expression']['Stroop']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_task = df.groupby(['Subject_ID', 'Intr_Type']).mean().unstack()\n",
    "print(stats.ttest_rel(subj_task['Expression']['pos'],\n",
    "                      subj_task['Expression']['neg']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Between-Task Subgraph Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "    \n",
    "# Subgraph/Task Bias Plot\n",
    "for intr in df['Intr_Type'].unique():\n",
    "    sel_intr = df[df['Intr_Type'] == intr]\n",
    "    subg_task = sel_intr.groupby(['Subgraph_ID', 'Subject_ID', 'Cond_Type', 'Task_Type']).mean().unstack()\n",
    "    \n",
    "    # Get the expression difference\n",
    "    diff_distrib_task = (subg_task['Expression']['Stroop'] - subg_task['Expression']['Navon']).unstack()\n",
    "    diff_distrib = np.array((0.5*diff_distrib_task['hi'] + 0.5*diff_distrib_task['lo']).unstack())\n",
    "    diff_means = diff_distrib.mean(axis=1)\n",
    "    diff_stderrs = diff_distrib.std(axis=1) / np.sqrt(diff_distrib.shape[1]) \n",
    "    \n",
    "    print(stats.f_oneway(*diff_distrib))\n",
    "        \n",
    "    # Permutation test\n",
    "    diff_distrib_null = []\n",
    "    for n_i in xrange(1000):\n",
    "        diff_distrib_null.append(np.random.permutation(diff_distrib.reshape(-1)).reshape(n_subgraph, -1).mean(axis=1))\n",
    "    min_null_thr = np.percentile(diff_distrib_null, 2.5)\n",
    "    max_null_thr = np.percentile(diff_distrib_null, 97.5)    \n",
    "    \n",
    "    # Color based on permutation test\n",
    "    colors = []\n",
    "    for fac_ii in xrange(n_subgraph):\n",
    "        if diff_means[fac_ii] < min_null_thr:\n",
    "            colors.append('r')\n",
    "        elif diff_means[fac_ii] > max_null_thr:\n",
    "                colors.append('b')\n",
    "        else:\n",
    "            colors.append('k')\n",
    "    colors = np.array(colors)    \n",
    "\n",
    "    # Reorder factors based on the expression difference\n",
    "    ord_ix = np.argsort(diff_means)[::-1]\n",
    "    print(ord_ix)\n",
    "    print([letter_lbl[subgraph_rank == o_ii][0] for o_ii in ord_ix])\n",
    "        \n",
    "    # Plot routine\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    ax.barh(np.arange(n_subgraph),\n",
    "            diff_means[ord_ix],\n",
    "            xerr=diff_stderrs[ord_ix], \n",
    "            color=colors[ord_ix])\n",
    "    \n",
    "    ax.fill_between(np.linspace(min_null_thr, max_null_thr, 100),\n",
    "                    y1=-1, y2=n_subgraph, lw=0, alpha=0.2)\n",
    "    ax.vlines(0, -1, n_subgraph, color='k')\n",
    "    \n",
    "    max_expr = np.max(np.abs(diff_means)) + np.max(diff_stderrs)\n",
    "    ax.set_xlim([-1.1*max_expr, 1.1*max_expr])\n",
    "    ax.set_ylim([-1, n_subgraph])\n",
    "    \n",
    "    ax.set_xlabel('Difference in Expression')\n",
    "    ax.set_ylabel('Ranked Subgraphs')\n",
    "    ax.set_title(intr)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    plt.savefig('{}/Task_Specificity.{}.svg'.format(path_Figures, intr))\n",
    "    \n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Within-Task Subgraph Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "clr = [plt.cm.Set1(float(ii)/n_subgraph) for ii in xrange(n_subgraph)]\n",
    "\n",
    "\n",
    "for task in df['Task_Type'].unique():\n",
    "    \n",
    "    sel_task = df[df['Task_Type'] == task]\n",
    "    subg_task = sel_task.groupby(['Subgraph_ID', 'Subject_ID', 'Intr_Type', 'Cond_Type']).mean().unstack()\n",
    "\n",
    "    rs_pos = np.array(subg_task['Expression']['rs'].unstack()['pos'].unstack())\n",
    "    rs_neg = np.array(subg_task['Expression']['rs'].unstack()['neg'].unstack())    \n",
    "    hi_pos = np.array(subg_task['Expression']['hi'].unstack()['pos'].unstack())\n",
    "    hi_neg = np.array(subg_task['Expression']['hi'].unstack()['neg'].unstack())\n",
    "    lo_pos = np.array(subg_task['Expression']['lo'].unstack()['pos'].unstack())\n",
    "    lo_neg = np.array(subg_task['Expression']['lo'].unstack()['neg'].unstack())\n",
    "            \n",
    "    hi_perf = subg_task['Performance']['hi'].unstack()['pos'].unstack().mean(axis=0)\n",
    "    lo_perf = subg_task['Performance']['lo'].unstack()['pos'].unstack().mean(axis=0)\n",
    "    cost_perf = hi_perf-lo_perf    \n",
    "    \n",
    "    prf_pairs = [('Lo-Rs', lo_perf), ('Hi-Lo', cost_perf)]\n",
    "    pos_pairs = [[lo_pos, rs_pos], [hi_pos, lo_pos]]\n",
    "    neg_pairs = [[lo_neg, rs_neg], [hi_neg, lo_neg]]\n",
    "    \n",
    "    \n",
    "    print('\\n\\n\\n\\n\\n*****{}*****'.format(task))\n",
    "    for prf, pos, neg in zip(prf_pairs, pos_pairs, neg_pairs):\n",
    "        \n",
    "        pos_idx = (pos[0]-pos[1])\n",
    "        neg_idx = (neg[0]-neg[1])\n",
    "        \n",
    "        pos_idx_mean = pos_idx.mean(axis=1)\n",
    "        neg_idx_mean = neg_idx.mean(axis=1)        \n",
    "        pos_idx_stderr = pos_idx.std(axis=1) / np.sqrt(n_subj)\n",
    "        neg_idx_stderr = neg_idx.std(axis=1) / np.sqrt(n_subj)        \n",
    "        \n",
    "        real_m, real_b, _, _, _ = stats.linregress(pos_idx_mean, neg_idx_mean)\n",
    "        real_rho, real_pval = stats.spearmanr(pos_idx_mean, neg_idx_mean)\n",
    "\n",
    "        ### Permutation Tests\n",
    "        null_rho_dist = []\n",
    "        for n_i in xrange(10000):\n",
    "            pos_null_1 = np.random.permutation(pos[0].reshape(-1)).reshape(n_subgraph, n_subj)\n",
    "            pos_null_2 = np.random.permutation(pos[1].reshape(-1)).reshape(n_subgraph, n_subj)\n",
    "            neg_null_1 = np.random.permutation(neg[0].reshape(-1)).reshape(n_subgraph, n_subj)\n",
    "            neg_null_2 = np.random.permutation(neg[1].reshape(-1)).reshape(n_subgraph, n_subj)\n",
    "            \n",
    "            pos_null_idx = (pos_null_1-pos_null_2).mean(axis=1)\n",
    "            neg_null_idx = (neg_null_1-neg_null_2).mean(axis=1)            \n",
    "            \n",
    "            null_rho, _ = stats.spearmanr(pos_null_idx, neg_null_idx)\n",
    "            null_rho_dist.append(null_rho)\n",
    "\n",
    "        null_rho_dist = np.array(null_rho_dist)\n",
    "        if real_rho > 0:\n",
    "            real_pval = np.mean(null_rho_dist > real_rho)\n",
    "        else:\n",
    "            real_pval = np.mean(null_rho_dist < real_rho)\n",
    "            \n",
    "        ## Print out salient control subgraphs\n",
    "        # Find the subgraphs in each quadrant\n",
    "        q1 = np.intersect1d(np.flatnonzero(pos_idx_mean > 0),\n",
    "                            np.flatnonzero(neg_idx_mean > 0))\n",
    "        q2 = np.intersect1d(np.flatnonzero(pos_idx_mean < 0),\n",
    "                            np.flatnonzero(neg_idx_mean > 0))\n",
    "        q3 = np.intersect1d(np.flatnonzero(pos_idx_mean < 0),\n",
    "                            np.flatnonzero(neg_idx_mean < 0))\n",
    "        q4 = np.intersect1d(np.flatnonzero(pos_idx_mean > 0),\n",
    "                            np.flatnonzero(neg_idx_mean < 0))\n",
    "\n",
    "        # Order by distance away from (0,0)\n",
    "        for qi, qq in enumerate([q1, q2, q3, q4]):\n",
    "            qq_dist = qq[np.argsort(np.sqrt(pos_idx_mean[qq]**2 + neg_idx_mean[qq]**2))]  \n",
    "            qq_letter = [letter_lbl[np.flatnonzero(subgraph_rank == subg_id)][0]\n",
    "                         for subg_id in qq_dist]\n",
    "            print('Quadrant {}: {}'.format(qi+1, qq_letter))\n",
    "        \n",
    "        \n",
    "        # First, plot the 2D real distribution and ellipsoid errors\n",
    "        plt.figure()\n",
    "        ax = plt.subplot(111)\n",
    "        \n",
    "        for ii, fac_ii in enumerate(subgraph_rank):\n",
    "            \"\"\"\n",
    "            ang = (np.arctan2(pos_mod_idx_mean[fac_ii] - pos_mod_idx[fac_ii, :],\n",
    "                              neg_mod_idx_mean[fac_ii] - neg_mod_idx[fac_ii, :])\n",
    "                   * 180/np.pi)\n",
    "\n",
    "\n",
    "            ell = Ellipse(xy=(pos_mod_idx_mean[fac_ii],\n",
    "                              neg_mod_idx_mean[fac_ii]),\n",
    "                          width=pos_mod_idx_stderr[fac_ii],\n",
    "                          height=neg_mod_idx_stderr[fac_ii],\n",
    "                          angle=np.nanmean(ang))\n",
    "\n",
    "            #ax.add_artist(ell)\n",
    "            ell.set_alpha(0.4)\n",
    "            ell.set_facecolor(clr[ii])\n",
    "            ell.set_linewidth(0.0)\n",
    "            \"\"\"\n",
    "            ax.scatter(pos_idx_mean[fac_ii], neg_idx_mean[fac_ii],\n",
    "                       s=50, lw=0, color=clr[ii])        \n",
    "        \n",
    "        ax.legend(letter_lbl)  \n",
    "\n",
    "        # Next, plot the linear fits\n",
    "        x = np.array([-2.5, 2.5])\n",
    "        y = real_m*x + real_b\n",
    "        ax.plot(x, y, color='k', lw=1.0)   \n",
    "        ax.text(1.0, 0.3, 'rho=%0.3f\\np=%0.3f' % (real_rho, real_pval))     \n",
    "        \n",
    "        ax.set_xlim([-3.2, 3.2])\n",
    "        ax.set_ylim([-0.6, 0.6])\n",
    "        \n",
    "        plt.savefig('{}/{}_Control_Matrix.{}.svg'.format(path_Figures, task, prf[0]))\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.graphics.regressionplots as regplot\n",
    "\n",
    "for task in df['Task_Type'].unique():\n",
    "    \n",
    "    sel_task = df[df['Task_Type'] == task]\n",
    "    subg_task = sel_task.groupby(['Subgraph_ID', 'Subject_ID', 'Intr_Type', 'Cond_Type']).mean().unstack()\n",
    "\n",
    "    rs_pos = np.array(subg_task['Expression']['rs'].unstack()['pos'].unstack())\n",
    "    rs_neg = np.array(subg_task['Expression']['rs'].unstack()['neg'].unstack())    \n",
    "    hi_pos = np.array(subg_task['Expression']['hi'].unstack()['pos'].unstack())\n",
    "    hi_neg = np.array(subg_task['Expression']['hi'].unstack()['neg'].unstack())\n",
    "    lo_pos = np.array(subg_task['Expression']['lo'].unstack()['pos'].unstack())\n",
    "    lo_neg = np.array(subg_task['Expression']['lo'].unstack()['neg'].unstack())\n",
    "            \n",
    "    hi_perf = subg_task['Performance']['hi'].unstack()['pos'].unstack().mean(axis=0)\n",
    "    lo_perf = subg_task['Performance']['lo'].unstack()['pos'].unstack().mean(axis=0)\n",
    "    cost_perf = hi_perf-lo_perf    \n",
    "    \n",
    "    prf_pairs = [('Lo-Rs', lo_perf), ('Hi-Lo', cost_perf)]\n",
    "    pos_pairs = [[lo_pos, rs_pos], [hi_pos, lo_pos]]\n",
    "    neg_pairs = [[lo_neg, rs_neg], [hi_neg, lo_neg]]\n",
    "    \n",
    "    print('\\n\\n\\n\\n\\n*****{}*****'.format(task))\n",
    "    for fac_ii in xrange(n_subgraph):\n",
    "        llbl = letter_lbl[subgraph_rank == fac_ii][0]\n",
    "        print(llbl)\n",
    "        \n",
    "        for prf, pos, neg in zip(prf_pairs, pos_pairs, neg_pairs):\n",
    "            model1 = sm.OLS(prf[1], df_motion[task].T)\n",
    "            res1 = model1.fit().resid           \n",
    "            \n",
    "            for mod_dir in [('Pos', pos),\n",
    "                            ('Neg', neg)]:\n",
    "                \n",
    "                mod_idx = mod_dir[1][0][fac_ii, :]-mod_dir[1][1][fac_ii, :]\n",
    "                \n",
    "                model2 = sm.OLS(mod_idx, df_motion[task].T)\n",
    "                res2 = mod_idx #model2.fit().resid           \n",
    "                \n",
    "                real_rho, real_pval = stats.spearmanr(res2, res1)\n",
    "                \n",
    "                real_m, real_b, _, _, _ = stats.linregress(res2, res1)\n",
    "                \n",
    "                ### Permutation Tests\n",
    "                null_rho_dist = []\n",
    "                for n_i in xrange(10000):\n",
    "                    null_expr = np.random.permutation(np.array(subg_task['Expression']).reshape(-1)).reshape(n_subgraph, n_subj, 6)\n",
    "                    null_expr_1 = null_expr[fac_ii, :, 0]\n",
    "                    null_expr_2 = null_expr[fac_ii, :, 1]\n",
    "                    mod_idx_null = null_expr_1-null_expr_2\n",
    "                    \n",
    "                    model3 = sm.OLS(mod_idx_null, df_motion[task].T)\n",
    "                    res3 = mod_idx_null\n",
    "                    \n",
    "                    null_rho, _ = stats.spearmanr(res3, res1)\n",
    "                    null_rho_dist.append(null_rho)\n",
    "                    \n",
    "                null_rho_dist = np.array(null_rho_dist)\n",
    "                if real_rho > 0:\n",
    "                    real_pval = np.mean(null_rho_dist > real_rho)\n",
    "                else:\n",
    "                    real_pval = np.mean(null_rho_dist < real_rho)\n",
    "                    \n",
    "                if real_pval < 0.05:\n",
    "                    sig = '*'\n",
    "                else:\n",
    "                    sig = ' '\n",
    "                    \n",
    "                # Print output\n",
    "                print('%s, %s, %0.4f, %0.4f, %s' % \n",
    "                      (prf[0], mod_dir[0], real_rho, real_pval, sig))\n",
    "                \n",
    "                \n",
    "                # First, plot the 2D real distribution and ellipsoid errors\n",
    "                plt.figure()\n",
    "                ax = plt.subplot(111)\n",
    "\n",
    "                ax.scatter(res2, res1,\n",
    "                           s=20, lw=0, color=[0.5, 0.5, 0.5])        \n",
    "\n",
    "            \n",
    "                # Next, plot the linear fits\n",
    "                x = np.array([res2.min(), res2.max()])\n",
    "                y = real_m*x + real_b\n",
    "                ax.plot(x, y, color='k', lw=1.0)   \n",
    "                ax.text(0.75*(x.max()+x.min()),\n",
    "                        0.75*(y.max()+y.min()),\n",
    "                        'r=%0.3f\\np=%0.3f' % (real_rho, real_pval))  \n",
    "                \n",
    "                # Get the axis boundaries\n",
    "                x_bound = 1.05*np.max([np.abs(res2.min()),\n",
    "                                       np.abs(res2.max())])\n",
    "                y_bound = 1.05*np.max([np.abs(res1.min()),\n",
    "                                       np.abs(res1.max())])\n",
    "                ax.set_xlim([-x_bound, x_bound])\n",
    "                ax.set_ylim([-y_bound, y_bound])                \n",
    "\n",
    "                plt.savefig('{}/{}.Subgraph_{}.{}.{}.svg'.format(path_Figures, task, llbl,\n",
    "                                                                 prf[0], mod_dir[0]))\n",
    "\n",
    "                plt.close()\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "282px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "897px",
    "left": "0px",
    "right": "1707px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "376px",
   "left": "1514.75px",
   "right": "20px",
   "top": "210px",
   "width": "327px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
