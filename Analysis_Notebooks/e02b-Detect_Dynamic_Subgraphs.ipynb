{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev2 toc-item\"><a href=\"#Generate-List-of-Data\" data-toc-modified-id=\"Generate-List-of-Data-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Generate List of Data</a></div><div class=\"lev2 toc-item\"><a href=\"#Construct-Configuration-Matrices\" data-toc-modified-id=\"Construct-Configuration-Matrices-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Construct Configuration Matrices</a></div><div class=\"lev1 toc-item\"><a href=\"#Optimize-Dynamic-Subgraphs\" data-toc-modified-id=\"Optimize-Dynamic-Subgraphs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Optimize Dynamic Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Generate-Cross-Validation-Parameter-Sets\" data-toc-modified-id=\"Generate-Cross-Validation-Parameter-Sets-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Generate Cross-Validation Parameter Sets</a></div><div class=\"lev2 toc-item\"><a href=\"#SGE-Helper-Script-for-NMF-Cross-Validation\" data-toc-modified-id=\"SGE-Helper-Script-for-NMF-Cross-Validation-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>SGE Helper Script for NMF Cross-Validation</a></div><div class=\"lev2 toc-item\"><a href=\"#Quality-Measures-in-Parameter-Space\" data-toc-modified-id=\"Quality-Measures-in-Parameter-Space-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Quality Measures in Parameter Space</a></div><div class=\"lev1 toc-item\"><a href=\"#Detect-Dynamic-Subgraphs\" data-toc-modified-id=\"Detect-Dynamic-Subgraphs-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Detect Dynamic Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Run-Non-Negative-Matrix-Factorization-Algorithm\" data-toc-modified-id=\"Run-Non-Negative-Matrix-Factorization-Algorithm-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Run Non-Negative Matrix Factorization Algorithm</a></div><div class=\"lev2 toc-item\"><a href=\"#Consensus-Clustering-of-Dynamic-Subgraphs\" data-toc-modified-id=\"Consensus-Clustering-of-Dynamic-Subgraphs-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Consensus Clustering of Dynamic Subgraphs</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-Subgraphs\" data-toc-modified-id=\"Plot-Subgraphs-321\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Plot Subgraphs</a></div><div class=\"lev1 toc-item\"><a href=\"#Subgraphs-of-Brain-Systems\" data-toc-modified-id=\"Subgraphs-of-Brain-Systems-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Subgraphs of Brain Systems</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Subgraphs-and-Expression\" data-toc-modified-id=\"Load-Subgraphs-and-Expression-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Load Subgraphs and Expression</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Atlas\" data-toc-modified-id=\"Load-Atlas-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Load Atlas</a></div><div class=\"lev3 toc-item\"><a href=\"#Render-brain-systems\" data-toc-modified-id=\"Render-brain-systems-421\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Render brain systems</a></div><div class=\"lev2 toc-item\"><a href=\"#Condense-Subgraphs-into-a-Dictionary\" data-toc-modified-id=\"Condense-Subgraphs-into-a-Dictionary-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Condense Subgraphs into a Dictionary</a></div><div class=\"lev2 toc-item\"><a href=\"#Filter-Subgraphs-with-Sparse-Expression\" data-toc-modified-id=\"Filter-Subgraphs-with-Sparse-Expression-44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Filter Subgraphs with Sparse Expression</a></div><div class=\"lev2 toc-item\"><a href=\"#Circle-Plot\" data-toc-modified-id=\"Circle-Plot-45\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Circle Plot</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "echobase_path = '/Users/akhambhati/Developer/hoth_research/Echobase'\n",
    "sys.path.append(echobase_path)\n",
    "import Echobase\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "subgraph = Echobase.Network.Partitioning.Subgraph\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "\n",
    "path_Remotes = '/Users/akhambhati/Remotes'\n",
    "path_CoreData = path_Remotes + '/CORE.fMRI_cogcontrol.medaglia'\n",
    "path_PeriphData = path_Remotes + '/RSRCH.NMF_CogControl'\n",
    "path_InpData = path_PeriphData + '/e01-FuncNetw'\n",
    "path_ExpData = path_PeriphData + '/e02b-FuncSubg'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate List of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inp_fname = glob.glob('{}/*.npz'.format(path_InpData))\n",
    "\n",
    "expr_dict = {}\n",
    "for fname in inp_fname:\n",
    "    subj_id = fname.split('/')[-1].split('.')[0]\n",
    "    expr_id = fname.split('/')[-1].split('.')[1]\n",
    "    \n",
    "    try:\n",
    "        expr_dict[expr_id]['adj_files'].append(fname)\n",
    "    except:\n",
    "        expr_dict[expr_id] = {}\n",
    "        expr_dict[expr_id]['adj_files'] = []\n",
    "        expr_dict[expr_id]['adj_files'].append(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Construct Configuration Matrices\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove all existing output (retains pipe/pipeline definitions)\n",
    "rm_outp = glob.glob(\"{}/NMF_Optimization.CfgMatr.npz\".format(path_ExpData))\n",
    "\n",
    "for rm_type in [rm_outp]:\n",
    "    for path in rm_type:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            print(\"{} not found\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populate the network configuration matrix over the whole population\n",
    "key_ord = ['adj_rs_pos', 'adj_rs_neg',\n",
    "           'adj_lo_pos', 'adj_lo_neg',\n",
    "           'adj_hi_pos', 'adj_hi_neg']\n",
    "\n",
    "cfg_list = []\n",
    "cfg_key = []\n",
    "for expr_id in expr_dict.keys():    \n",
    "    for fname in expr_dict[expr_id]['adj_files']:\n",
    "        df = np.load(fname)\n",
    "        \n",
    "        for key in key_ord:\n",
    "            cfg_matr = convert_adj_matr_to_cfg_matr(df[key])\n",
    "            for cfg_vec in cfg_matr:\n",
    "                cfg_list.append(cfg_vec)\n",
    "                cfg_key.append('{}_{}'.format(key, expr_id))\n",
    "cfg_matr=np.array(cfg_list)\n",
    "cfg_key=np.array(cfg_key)\n",
    "\n",
    "# Generate a lookup table for the observations of cfg_matr\n",
    "# subjects, task conditions + pos/neg interactions, blocks\n",
    "n_obs, n_conn = cfg_matr.shape\n",
    "key_type = np.unique(cfg_key)\n",
    "n_key = len(key_type)\n",
    "n_block = 6 \n",
    "n_subj = n_obs / (n_key*n_block)\n",
    "\n",
    "cfg_obs_idx = np.arange(n_obs)\n",
    "cfg_obs_lut = np.zeros((n_subj, n_key, n_block))\n",
    "for key_ii, key in enumerate(key_type):\n",
    "    key_ix = np.flatnonzero(cfg_key == key)\n",
    "    cfg_obs_lut[:, key_ii, :] = cfg_obs_idx[key_ix].reshape(n_subj, n_block)\n",
    "\n",
    "np.savez('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData),\n",
    "         cfg_matr=cfg_matr,\n",
    "         cfg_key=cfg_key,\n",
    "         cfg_obs_lut=cfg_obs_lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Optimize Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate Cross-Validation Parameter Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load configuration matrix\n",
    "cfg_data = np.load('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData))\n",
    "cfg_matr = cfg_data['cfg_matr']\n",
    "cfg_obs_lut = cfg_data['cfg_obs_lut']\n",
    "\n",
    "# Generate folds\n",
    "n_subj_per_fold = 2\n",
    "subj_obs = cfg_obs_lut.reshape(cfg_obs_lut.shape[0], -1)\n",
    "fold_obs = subj_obs.reshape(-1, n_subj_per_fold, subj_obs.shape[-1])\n",
    "fold_obs = fold_obs.reshape(fold_obs.shape[0], -1)\n",
    "fold_list = [list(ff) for ff in fold_obs]\n",
    "\n",
    "# Cross-Validation Progress\n",
    "str_path = '{}/NMF_CrossValidation.Progress.txt'.format(path_ExpData)\n",
    "if os.path.exists(str_path):\n",
    "    os.remove(str_path)\n",
    "\n",
    "# Get parameter search space\n",
    "param_list = Echobase.Network.Partitioning.Subgraph.optimize_nmf.gen_random_sampling_paramset(\n",
    "    rank_range=(2, 51),\n",
    "    alpha_range=(0.01, 1.0),\n",
    "    beta_range=(0.01, 1.0),\n",
    "    n_param=1000,\n",
    "    fold_list=fold_list,\n",
    "    str_path=str_path)\n",
    "\n",
    "# Save param_list for sge run\n",
    "np.savez('{}/NMF_CrossValidation.Param_List.npz'.format(path_ExpData),\n",
    "         param_list=param_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGE Helper Script for NMF Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "job_str = './NMF_xval.py {} {}'.format(echobase_path, path_ExpData)\n",
    "qsub_str = 'qsub -cwd -l h_vmem=10.1G, xvmem=10G -q all.q,basic.q'\n",
    "\n",
    "os.chdir('./e02b-SGE_Scripts/')\n",
    "!sh {job_str}\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Quality Measures in Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt_dict = np.load('{}/NMF_Optimization.Error.npz'.format(path_ExpData), mmap_mode='r')\n",
    "opt_params = {}\n",
    "opt_params['rank'] = int(opt_dict['rank'][opt_dict['error'] < np.percentile(opt_dict['error'], 25)].mean().round())\n",
    "opt_params['alpha'] = opt_dict['alpha'][opt_dict['error'] < np.percentile(opt_dict['error'], 25)].mean()\n",
    "opt_params['beta'] = opt_dict['beta'][opt_dict['error'] < np.percentile(opt_dict['error'], 25)].mean()\n",
    "print('Optimal Rank: {}'.format(opt_params['rank']))\n",
    "print('Optimal Alpha: {}'.format(opt_params['alpha']))\n",
    "print('Optimal Beta: {}'.format(opt_params['beta']))\n",
    "\n",
    "# Generate quality measure plots\n",
    "for qmeas in ['error', 'pct_sparse_subgraph', 'pct_sparse_coef']:\n",
    "    for param in ['rank', 'alpha', 'beta']:\n",
    "\n",
    "        param_unq = np.unique(opt_dict[param])\n",
    "        qmeas_mean = [np.mean(opt_dict[qmeas][opt_dict[param]==pp]) for pp in param_unq]\n",
    "        \n",
    "        ax_jp = sns.jointplot(opt_dict[param], opt_dict[qmeas], kind='kde', \n",
    "                              space=0, n_levels=60, shade_lowest=False)\n",
    "        ax = ax_jp.ax_joint\n",
    "        ax.plot([opt_params[param], opt_params[param]], \n",
    "                [ax.get_ylim()[0], ax.get_ylim()[1]],\n",
    "                lw=1.0, alpha=0.75, linestyle='--')\n",
    "\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.set_xlabel(param)\n",
    "        ax.set_ylabel(qmeas)\n",
    "        \n",
    "        plt.savefig('./e02b-Figures/NMF_Optimization.{}.{}.svg'.format(param, qmeas))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "opt_dict.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Detect Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run Non-Negative Matrix Factorization Algorithm\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove all existing output (retains pipe/pipeline definitions)\n",
    "rm_outp = glob.glob(\"{}/*.subgraph_seed-*.npz\".format(path_ExpData))\n",
    "\n",
    "for rm_type in [rm_outp]:\n",
    "    for path in rm_type:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            print(\"{} not found\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#param = {'rank': 51,\n",
    "#         'alpha': 0.327,\n",
    "#         'beta': 0.577}\n",
    "param = {'rank': 32,\n",
    "         'alpha': 0.55,\n",
    "         'beta': 0.34}\n",
    "n_seed = 100\n",
    "\n",
    "from multiprocessing import Pool\n",
    "parallel_run = True\n",
    "\n",
    "# Generate a processing joblist\n",
    "cfg_matr_path = glob.glob(\"{}/NMF_Optimization.CfgMatr.npz\".format(path_ExpData))[0]\n",
    "proc_list = []\n",
    "for seed in xrange(n_seed):\n",
    "    proc_list.append({'path': cfg_matr_path,\n",
    "                      'param': param,\n",
    "                      'seed': seed+1})\n",
    "    \n",
    "# Setup helper function to map pipeline run\n",
    "def _nmf_helper(proc_item):\n",
    "    \n",
    "    # Load the file\n",
    "    #if os.path.exists(inp_path):\n",
    "    #    return 0\n",
    "    print(\" -- Processing Seed: {}\".format(proc_item['seed']))\n",
    "    data = np.load(proc_item['path'], mmap_mode='r')\n",
    "    \n",
    "    # Initialize the factors for NMF\n",
    "    fac_subnet = np.random.uniform(low=0, high=1.0,\n",
    "                                   size=(proc_item['param']['rank'],\n",
    "                                         data['cfg_matr'].shape[1]))\n",
    "    fac_coef = np.random.uniform(low=0, high=1.0,\n",
    "                                 size=(proc_item['param']['rank'],\n",
    "                                       data['cfg_matr'].shape[0]))\n",
    "\n",
    "    # Run NMF Algorithm\n",
    "    #fac_subnet, fac_coef, err = nmf.snmf_bcd(\n",
    "    fac_coef, fac_subnet, err = nmf.snmf_bcd(\n",
    "        data['cfg_matr'],\n",
    "        alpha=proc_item['param']['alpha'],\n",
    "        beta=proc_item['param']['beta'],\n",
    "        fac_subnet_init=fac_subnet,\n",
    "        fac_coef_init=fac_coef,\n",
    "        max_iter=100, verbose=False)\n",
    "    \n",
    "    # Cache the NMF result\n",
    "    np.savez(\"{}/NMF_Optimization.subgraph_seed-{}.npz\".format(path_ExpData,\n",
    "                                                               proc_item['seed']),\n",
    "             fac_subnet=fac_subnet, fac_coef=fac_coef, err=err,\n",
    "             param=proc_item['param'], path=proc_item['path'])\n",
    "\n",
    "if parallel_run:\n",
    "    mp = Pool(5)\n",
    "    mp.map(_nmf_helper, proc_list)\n",
    "else:\n",
    "    map(_nmf_helper, proc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Consensus Clustering of Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seed_paths = glob.glob(\"{}/NMF_Optimization.subgraph_seed-*.npz\".format(path_ExpData))\n",
    "\n",
    "# Aggregate the estimated subgraphs of each seed\n",
    "fac_subnet_seeds = []\n",
    "for ii, path in enumerate(seed_paths):\n",
    "    data = np.load(path, mmap_mode='r')\n",
    "    fac_subnet = data['fac_subnet'][:, :]\n",
    "    data.close()\n",
    "\n",
    "    n_fac = fac_subnet.shape[0]\n",
    "    n_conn = fac_subnet.shape[1]\n",
    "\n",
    "    for iy in xrange(fac_subnet.shape[0]):\n",
    "        fac_subnet_seeds.append(fac_subnet[iy, :])\n",
    "fac_subnet_seeds = np.array(fac_subnet_seeds)\n",
    "\n",
    "n_obs = fac_subnet_seeds.shape[0]\n",
    "n_conn = fac_subnet_seeds.shape[1]\n",
    "\n",
    "# Consensus Subgraphs\n",
    "fac_cons_subnet, fac_cons_seeds, err = nmf.snmf_bcd(\n",
    "    fac_subnet_seeds,\n",
    "    alpha=0.0,\n",
    "    beta=0.0,\n",
    "    fac_subnet_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_conn)),\n",
    "    fac_coef_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_obs)),\n",
    "    max_iter=100, verbose=False)\n",
    "\n",
    "# Consensus Coefficients\n",
    "cfg_matr_path = glob.glob(\"{}/NMF_Optimization.CfgMatr.npz\".format(path_ExpData))[0]\n",
    "data_cfg = np.load(cfg_matr_path, mmap_mode='r')\n",
    "n_win = data_cfg['cfg_matr'].shape[0]\n",
    "fac_cons_subnet_2, fac_cons_coef_2, err = nmf.snmf_bcd(\n",
    "    data_cfg['cfg_matr'],\n",
    "    alpha=0.0,\n",
    "    beta=0.0,\n",
    "    fac_subnet_init=fac_cons_subnet,\n",
    "    fac_coef_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_win)),\n",
    "    max_iter=100, verbose=False)\n",
    "\n",
    "# Cache the Consensus NMF result\n",
    "np.savez(\"{}/NMF_Optimization.consensus_subgraph.npz\".format(path_ExpData),\n",
    "         fac_subnet=fac_cons_subnet_2, fac_coef=fac_cons_coef_2, err=err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Plot Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the consensus data\n",
    "data = np.load(\"{}/NMF_Optimization.consensus_subgraph.npz\".format(path_ExpData),\n",
    "               mmap_mode='r')\n",
    "fac_subnet = data['fac_subnet']\n",
    "fac_coef = data['fac_coef']\n",
    "\n",
    "# Normalize\n",
    "fac_subnet = fac_subnet / fac_subnet.max()\n",
    "fac_coef = fac_coef / fac_coef.max()\n",
    "\n",
    "n_fac = fac_subnet.shape[0]\n",
    "n_conn = fac_subnet.shape[1]\n",
    "n_win = fac_coef.shape[1]\n",
    "\n",
    "# Plot subgraph matrix\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "mat = ax.matshow(fac_subnet.T, aspect=n_fac/n_conn, cmap='rainbow', vmin=0, vmax=1)\n",
    "plt.colorbar(mat, ax=ax)\n",
    "\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "#ax.set_xticks(np.linspace(0, 80, 5))\n",
    "ax.set_ylabel('Functional Interactions')\n",
    "ax.set_xlabel('Subgraphs')\n",
    "\n",
    "plt.savefig('./e02b-Figures/Subgraph-Cfg_Matrix.svg')\n",
    "plt.close()      \n",
    "\n",
    "# Plot subgraph adjacency\n",
    "plt.figure()\n",
    "n_row = np.floor(np.sqrt(n_fac))\n",
    "n_col = np.ceil(n_fac / n_row)\n",
    "for ii, subg in enumerate(fac_subnet):\n",
    "    adj = convert_conn_vec_to_adj_matr(subg)\n",
    "\n",
    "    ax = plt.subplot(n_row, n_col, ii+1)\n",
    "    mat = ax.matshow(adj, cmap='rainbow', vmin=0, vmax=1)\n",
    "    #plt.colorbar(mat, ax=ax)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "plt.savefig('./e02b-Figures/Subgraph-Adj_Matrices.svg')\n",
    "plt.show()\n",
    "plt.close()      \n",
    "\n",
    "# Plot Coefficients\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "fac_coef = fac_coef.T\n",
    "norm_fac = fac_coef - fac_coef.mean(axis=0)\n",
    "for ff in xrange(n_fac):\n",
    "    ax.plot(ff + norm_fac[:, ff] / (3*np.std(norm_fac[:, ff])), color=[66/256., 152/256., 221./256])\n",
    "\n",
    "# Axis Settings\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_ylim([-1, n_fac+1])\n",
    "ax.set_ylabel('Subgraphs')\n",
    "ax.set_xlabel('Time Windows')\n",
    "\n",
    "plt.savefig('./e02b-Figures/Subgraph-Coefs.svg')\n",
    "plt.show()\n",
    "plt.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Subgraphs of Brain Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Subgraphs and Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Grab the subgraphs and expression from consensus NMF\n",
    "df_nmf = np.load(\"{}/NMF_Optimization.consensus_subgraph.npz\".format(path_ExpData),\n",
    "                 mmap_mode='r')\n",
    "fac_subnet = df_nmf['fac_subnet']\n",
    "fac_coef = df_nmf['fac_coef']\n",
    "n_fac = fac_subnet.shape[0]\n",
    "n_conn = fac_subnet.shape[1]\n",
    "n_node = np.int(np.ceil(np.sqrt(n_conn*2)))\n",
    "n_obs = fac_coef.shape[1]\n",
    "\n",
    "# Retrieve the configuration matrix\n",
    "# Get expression for: subgraphs, subjects, task conditions + pos/neg interactions, blocks\n",
    "path_cfg_expr = glob.glob('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData))[0]\n",
    "df_cfg = np.load(path_cfg_expr, mmap_mode='r')\n",
    "cfg_key = df_cfg['cfg_key']\n",
    "key_type = np.unique(cfg_key)\n",
    "n_key = len(key_type)\n",
    "n_block = 6 \n",
    "n_subj = n_obs / (n_key*n_block)\n",
    "fac_coef_subj = np.zeros((n_fac, n_subj, n_key, n_block))\n",
    "for key_ii, key in enumerate(key_type):\n",
    "    key_ix = np.flatnonzero(cfg_key == key)\n",
    "    fac_coef_subj[:, :, key_ii, :] = fac_coef[:, key_ix].reshape(n_fac, n_subj, n_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Get the Lausanne Labels\n",
    "df_parcel = pd.read_csv('{}/LausanneScale125.csv'.format(path_CoreData))\n",
    "\n",
    "lausanne_lbl = []\n",
    "for lbl_id, lbl_roi, lbl_hemi in zip(df_parcel.Label_ID, df_parcel.ROI, df_parcel.Hemisphere):\n",
    "    roi_name = '{}_{}'.format(lbl_hemi, lbl_roi)\n",
    "    lausanne_lbl.append(roi_name)\n",
    "lausanne_lbl = np.array(lausanne_lbl)\n",
    "\n",
    "### Get the system assignments for each ROI\n",
    "df_sys = h5py.File('{}/sysInfo234.mat'.format(path_CoreData), 'r')\n",
    "system_lbl = [''.join(unichr(c) for c in df_sys[rr])\n",
    "              for rr in df_sys['sysInfo']['system'][0, :]]\n",
    "for ii in xrange(len(system_lbl), n_node):\n",
    "    system_lbl.append(u'cerebellum')\n",
    "system_lbl = np.array(system_lbl)\n",
    "system_name = np.unique(system_lbl)\n",
    "\n",
    "### Get the sizes for each system\n",
    "system_size = []\n",
    "for sys_name in system_name:\n",
    "    system_size.append(len(np.flatnonzero(system_lbl == sys_name)))\n",
    "\n",
    "### Reorder systems by alternating size\n",
    "system_ix = np.argsort(system_size)[::-1]\n",
    "system_ix_large = system_ix[:len(system_ix)//2]\n",
    "system_ix_small = system_ix[len(system_ix)//2:][::-1]\n",
    "system_ord = []\n",
    "for ii, ij in zip(system_ix_large, system_ix_small):\n",
    "    system_ord.append(ii)\n",
    "    system_ord.append(ij)\n",
    "if len(system_ord)+1 == len(system_ix):\n",
    "    system_ord.append(system_ix_small[-1])\n",
    "    \n",
    "new_system_name = system_name.copy()\n",
    "for ii, sys_ix in enumerate(system_ord):\n",
    "    new_system_name[ii] = system_name[sys_ix]\n",
    "system_name = np.array(new_system_name)\n",
    "\n",
    "### Reorder the parcellation based on re-ordered systems labels\n",
    "srt_system_ix = []\n",
    "for sys_name in system_name:\n",
    "    for ll_ix in np.flatnonzero(system_lbl == sys_name):\n",
    "        srt_system_ix.append(ll_ix)\n",
    "srt_system_ix = np.array(srt_system_ix)\n",
    "srt_system_lbl = system_lbl[srt_system_ix]\n",
    "srt_lausanne_lbl = lausanne_lbl[srt_system_ix]\n",
    "\n",
    "df_sys.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Render brain systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from mayavi import mlab\n",
    "import nibabel as nib\n",
    "\n",
    "brain_system_pixmap = []\n",
    "\n",
    "sys_scalar = [5, 18, 2, 0, 3, 4, 6, 8, 10, 9, 15]\n",
    "view_angle = {'Sag_PA': [0.0, 90.0],\n",
    "              'Sag_AP': [180.0, 90.0]}\n",
    "\n",
    "# Get the pial surface recons\n",
    "pial_hemi = {'LH': {},\n",
    "             'RH': {}}\n",
    "pial_hemi['LH']['vert'], pial_hemi['LH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/lh.pial'.format(path_CoreData))\n",
    "pial_hemi['RH']['vert'], pial_hemi['RH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/rh.pial'.format(path_CoreData))\n",
    "\n",
    "# Get the Lausanne label files for each ROI\n",
    "label_files = []\n",
    "for roi in lausanne_lbl:\n",
    "    hemi = roi.split('_')[0].lower()\n",
    "    \n",
    "    # Parse the atlas name and find the label file if it exists\n",
    "    if len(roi.split('_')) == 2:\n",
    "        lbl_file = ('%s.%s.label' % tuple(roi.split('_'))).lower()\n",
    "    elif len(roi.split('_')) == 3:\n",
    "        lbl_file = ('%s.%s_%s.label' % tuple(roi.split('_'))).lower()\n",
    "    else:\n",
    "        raise Exception\n",
    "    lbl_file = lbl_file.replace(' ', '')\n",
    "\n",
    "    label_files.append('{}/BrainRenderSubject15/label/regenerated_{}_125/{}'.format(path_CoreData, hemi, lbl_file))\n",
    "\n",
    "# Iterate over hemisphere of the pial surface\n",
    "for hemi in pial_hemi.keys():\n",
    "    n_vert = len(pial_hemi[hemi]['vert'])\n",
    "    \n",
    "    # Iterate over brain system\n",
    "    for sys_id, sys_lbl in enumerate(system_name):\n",
    "        print(sys_lbl)\n",
    "        sys_ix = np.flatnonzero(system_lbl == sys_lbl)\n",
    "        \n",
    "        # Find the label file for each ROI and get vertices\n",
    "        if sys_lbl == 'subcortical':\n",
    "            pial_scalars = sys_scalar[sys_id]*np.ones(n_vert)\n",
    "        else:\n",
    "            pial_scalars = 15*np.ones(n_vert)\n",
    "        for roi_ix, (roi, lbl_file) in enumerate(zip(lausanne_lbl, label_files)):\n",
    "            if roi.split('_')[0] != hemi:\n",
    "                continue\n",
    "\n",
    "            if not os.path.exists(lbl_file):\n",
    "                continue\n",
    "\n",
    "            # Load the file and add scalar to the vertices\n",
    "            parc_lbl = nib.freesurfer.io.read_label(lbl_file)                \n",
    "            if roi_ix in sys_ix:\n",
    "                pial_scalars[parc_lbl] = sys_scalar[sys_id]\n",
    "            else:\n",
    "                pial_scalars[parc_lbl] = 15               \n",
    "            \n",
    "        # Plot the colored Brain System\n",
    "        fig = mlab.figure(bgcolor=(1.0, 1.0, 1.0))\n",
    "        src = mlab.pipeline.triangular_mesh_source(pial_hemi[hemi]['vert'][:,0],\n",
    "                                                   pial_hemi[hemi]['vert'][:,1],\n",
    "                                                   pial_hemi[hemi]['vert'][:,2],\n",
    "                                                   pial_hemi[hemi]['tria'], scalars=pial_scalars, opacity=0.75, figure=fig)\n",
    "        norms = mlab.pipeline.poly_data_normals(src, figure=fig)\n",
    "        norms.filter.splitting = False\n",
    "        surf = mlab.pipeline.surface(norms, figure=fig)\n",
    "        surf.parent.scalar_lut_manager.set(lut_mode='Vega20', data_range=[0, 19], use_default_range=False)\n",
    "        lut = surf.module_manager.scalar_lut_manager.lut.table.to_array()\n",
    "        lut[188:213, 3] = 220\n",
    "        surf.module_manager.scalar_lut_manager.lut.table = lut\n",
    "        \n",
    "        # Rotate the view and save a screenshot\n",
    "        pixmap = {}\n",
    "        for ang in view_angle.keys():\n",
    "            mlab.view(azimuth=view_angle[ang][0],\n",
    "                      elevation=view_angle[ang][1])\n",
    "            pixmap['{}_{}'.format(hemi, ang)] = mlab.screenshot(mode='rgba')\n",
    "        brain_system_pixmap.append(pixmap)\n",
    "        mlab.close(all=True)\n",
    "        \n",
    "np.savez('./e02b-Figures/brain_system_pixmap.npz',\n",
    "         brain_system_pixmap=brain_system_pixmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Condense Subgraphs into a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "system_subgraph = []\n",
    "for fac_i, subg in enumerate(fac_subnet):\n",
    "    print('Processed: {} of {}'.format(fac_i+1, len(fac_subnet)))\n",
    "    \n",
    "    adj = convert_conn_vec_to_adj_matr(subg)\n",
    "    adj = adj[srt_system_ix, :][:, srt_system_ix]\n",
    "    coef = fac_coef_subj[fac_i, ...]\n",
    "    \n",
    "    # Generate subgraph dictionary\n",
    "    system_subgraph.append({'Subgraph_ID': fac_i+1,\n",
    "                            'full_subg': adj[srt_system_ix, :][:, srt_system_ix],\n",
    "                            'expr_coef': coef})\n",
    "\n",
    "np.savez('{}/Subgraph.All.npz'.format(path_ExpData),\n",
    "         system_subgraph=system_subgraph,\n",
    "         lausanne_labels=srt_lausanne_lbl,\n",
    "         system_labels=srt_system_lbl,\n",
    "         system_names=system_name,\n",
    "         brain_system_pixmap=brain_system_pixmap,\n",
    "         task_key=key_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Filter Subgraphs with Sparse Expression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load in the System-Level subgraph data\n",
    "df_subg = np.load('{}/Subgraph.All.npz'.format(path_ExpData))\n",
    "sys_subgraph = df_subg['system_subgraph']\n",
    "n_fac = len(sys_subgraph)\n",
    "\n",
    "pct_sparse_mean = []\n",
    "pct_sparse_std = []\n",
    "for fac_ix in xrange(n_fac):\n",
    "    fac_coef = sys_subgraph[fac_ix]['expr_coef']\n",
    "    pct_sparse = (fac_coef == 0).reshape(fac_coef.shape[0], -1).mean(axis=-1)\n",
    "    pct_sparse_mean.append(pct_sparse.mean())\n",
    "    pct_sparse_std.append(pct_sparse.std() / np.sqrt(fac_coef.shape[0]))\n",
    "pct_sparse_mean = np.array(pct_sparse_mean)\n",
    "pct_sparse_std = np.array(pct_sparse_std)\n",
    "\n",
    "# Find the sparsity order\n",
    "fac_ord_ix = np.argsort(pct_sparse_mean)\n",
    "fac_thresh = 20\n",
    "\n",
    "# Plot the distribution of temporal sparsity over subgraphs\n",
    "% matplotlib inline\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(np.arange(n_fac), pct_sparse_mean[fac_ord_ix], 'k')\n",
    "ax.fill_between(np.arange(n_fac),\n",
    "                pct_sparse_mean[fac_ord_ix]-pct_sparse_std[fac_ord_ix],\n",
    "                pct_sparse_mean[fac_ord_ix]+pct_sparse_std[fac_ord_ix])\n",
    "ax.vlines(fac_thresh, 0, 1, 'r')\n",
    "\n",
    "ax.set_xlim([-0.5, n_fac-0.5])        \n",
    "plt.xticks(np.arange(0, n_fac+1, 6),\n",
    "           np.arange(0, n_fac+1, 6))\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_xlabel('Ranked Subgraphs')\n",
    "\n",
    "ax.set_ylim([0, 1])        \n",
    "ax.set_yticks(np.linspace(0, 1.0, 5))\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.set_ylabel('Percent Sparse Coefficients')\n",
    "plt.savefig('./e02b-Figures/Sparse_Coefs.svg')\n",
    "plt.show()\n",
    "\n",
    "sys_subgraph = sys_subgraph[fac_ord_ix[:fac_thresh]]\n",
    "\n",
    "np.savez('{}/Subgraph.Filtered.npz'.format(path_ExpData),\n",
    "         system_subgraph=sys_subgraph,\n",
    "         lausanne_labels=df_subg['lausanne_labels'],\n",
    "         system_labels=df_subg['system_labels'],\n",
    "         system_names=df_subg['system_names'],         \n",
    "         brain_system_pixmap=df_subg['brain_system_pixmap'],\n",
    "         task_key=df_subg['task_key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Circle Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "from scipy import ndimage\n",
    "\n",
    "df_subg = np.load('{}/Subgraph.Filtered.npz'.format(path_ExpData))\n",
    "sys_subgraph = df_subg['system_subgraph']\n",
    "sys_name = df_subg['system_names']\n",
    "sys_label = df_subg['system_labels']\n",
    "sys_pixmap = df_subg['brain_system_pixmap']\n",
    "n_sys = len(sys_name)\n",
    "n_lbl = len(sys_label)\n",
    "\n",
    "vega20_cmap = np.array([[31, 119, 180],\n",
    "                        [174, 199, 232],\n",
    "                        [255, 127, 14],\n",
    "                        [255, 187, 120],\n",
    "                        [44, 160, 44],\n",
    "                        [152, 223, 138],\n",
    "                        [214, 39, 40],\n",
    "                        [255, 152, 150],\n",
    "                        [148, 103, 189],\n",
    "                        [197, 176, 213],\n",
    "                        [140, 86, 75],\n",
    "                        [196, 156, 148],\n",
    "                        [227, 119, 194],\n",
    "                        [247, 182, 210],\n",
    "                        [127, 127, 127],\n",
    "                        [199, 199, 199],\n",
    "                        [188, 189, 34],\n",
    "                        [219, 219, 141], \n",
    "                        [23, 190, 207],\n",
    "                        [158, 218, 229]])\n",
    "vega20_sys = np.array([5, 18, 2, 0, 3, 4, 6, 8, 10, 9, 15])\n",
    "node_clr = np.array([vega20_cmap[vega20_sys[sys_name == sys_lbl]][0, :] / 255.  for sys_lbl in sys_label])\n",
    "\n",
    "\n",
    "system_pos = []\n",
    "node_rads = np.linspace(0, 2*np.pi - (2*np.pi/n_lbl), n_lbl)\n",
    "for sys_ii, sys_nm in enumerate(sys_name):\n",
    "    sys_rad = np.mean(node_rads[sys_label == sys_nm])\n",
    "    if sys_ii % 2 == 0:\n",
    "        dd = 12\n",
    "    else:\n",
    "        dd = 12   \n",
    "    system_pos.append((sys_rad, dd))\n",
    "        \n",
    "        \n",
    "for f_ii, sys_subg in enumerate(sys_subgraph):\n",
    "    sys_con = convert_adj_matr_to_cfg_matr(sys_subg['full_subg'].reshape(1, \n",
    "                                                                         sys_subg['full_subg'].shape[0],\n",
    "                                                                         sys_subg['full_subg'].shape[0])).squeeze()\n",
    "    fig, ax = Echobase.Plotting.render_circle_connectivity.draw(conn_list=sys_con,\n",
    "                                                                conn_pct=[99, 100],\n",
    "                                                                conn_linewidth=2.0,\n",
    "                                                                node_color=node_clr)\n",
    "    \n",
    "    fig.axes[0].set_ylim(0, 20)\n",
    "\n",
    "    for sys_ii in xrange(n_sys):\n",
    "        if sys_name[sys_ii] in ['dorsal_attention', 'cerebellum', 'subcortical', 'default_mode']:\n",
    "            arr = sys_pixmap[sys_ii+11]['LH_Sag_PA']\n",
    "        elif sys_name[sys_ii] in ['ventral_attention']:\n",
    "            arr = sys_pixmap[sys_ii+11]['LH_Sag_AP']\n",
    "            arr = np.fliplr(arr)\n",
    "        else:\n",
    "            arr = sys_pixmap[sys_ii]['RH_Sag_PA']\n",
    "        arr = ndimage.rotate(arr, (system_pos[sys_ii][0] - np.pi/2) * 180/np.pi, reshape=False)\n",
    "\n",
    "        imagebox = OffsetImage(arr, zoom=0.20)\n",
    "        imagebox.axes = fig.axes[0]\n",
    "\n",
    "        ab = AnnotationBbox(imagebox, \n",
    "                            xy=system_pos[sys_ii],\n",
    "                            xycoords='data',\n",
    "                            frameon=False,\n",
    "                            pad=0.0)\n",
    "\n",
    "        fig.axes[0].add_artist(ab)\n",
    "    fig.savefig('./e02b-Figures/Circle_Subgraph.{}.svg'.format(f_ii))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "897px",
    "left": "0px",
    "right": "1707px",
    "top": "106px",
    "width": "329px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
