{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev2 toc-item\"><a href=\"#Generate-List-of-Data\" data-toc-modified-id=\"Generate-List-of-Data-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Generate List of Data</a></div><div class=\"lev2 toc-item\"><a href=\"#Construct-Configuration-Matrices\" data-toc-modified-id=\"Construct-Configuration-Matrices-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Construct Configuration Matrices</a></div><div class=\"lev1 toc-item\"><a href=\"#Optimize-Dynamic-Subgraphs\" data-toc-modified-id=\"Optimize-Dynamic-Subgraphs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Optimize Dynamic Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#NMF-Cross-Validation-Optimizaion\" data-toc-modified-id=\"NMF-Cross-Validation-Optimizaion-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>NMF Cross-Validation Optimizaion</a></div><div class=\"lev2 toc-item\"><a href=\"#Quality-Measures-in-Parameter-Space\" data-toc-modified-id=\"Quality-Measures-in-Parameter-Space-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Quality Measures in Parameter Space</a></div><div class=\"lev1 toc-item\"><a href=\"#Detect-Dynamic-Subgraphs\" data-toc-modified-id=\"Detect-Dynamic-Subgraphs-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Detect Dynamic Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Run-Non-Negative-Matrix-Factorization-Algorithm\" data-toc-modified-id=\"Run-Non-Negative-Matrix-Factorization-Algorithm-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Run Non-Negative Matrix Factorization Algorithm</a></div><div class=\"lev2 toc-item\"><a href=\"#Consensus-Clustering-of-Dynamic-Subgraphs\" data-toc-modified-id=\"Consensus-Clustering-of-Dynamic-Subgraphs-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Consensus Clustering of Dynamic Subgraphs</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-Subgraphs\" data-toc-modified-id=\"Plot-Subgraphs-321\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Plot Subgraphs</a></div><div class=\"lev1 toc-item\"><a href=\"#Subgraphs-of-Brain-Systems\" data-toc-modified-id=\"Subgraphs-of-Brain-Systems-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Subgraphs of Brain Systems</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Subgraphs-and-Expression\" data-toc-modified-id=\"Load-Subgraphs-and-Expression-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Load Subgraphs and Expression</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Atlas\" data-toc-modified-id=\"Load-Atlas-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Load Atlas</a></div><div class=\"lev3 toc-item\"><a href=\"#Render-brain-systems\" data-toc-modified-id=\"Render-brain-systems-421\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Render brain systems</a></div><div class=\"lev2 toc-item\"><a href=\"#Convert-ROI-Subgraphs-to-Brain-System-Subgraphs\" data-toc-modified-id=\"Convert-ROI-Subgraphs-to-Brain-System-Subgraphs-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Convert ROI Subgraphs to Brain System Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Filter-Subgraphs-with-Sparse-Expression\" data-toc-modified-id=\"Filter-Subgraphs-with-Sparse-Expression-44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Filter Subgraphs with Sparse Expression</a></div><div class=\"lev2 toc-item\"><a href=\"#Plot-all-Brain-System-Subgraphs\" data-toc-modified-id=\"Plot-all-Brain-System-Subgraphs-45\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Plot all Brain System Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Circle-Plot\" data-toc-modified-id=\"Circle-Plot-46\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Circle Plot</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "nmf = Echobase.Network.Partitioning.Subgraph.nmf\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "\n",
    "path_Remotes = '/Users/akhambhati/Remotes'\n",
    "path_CoreData = path_Remotes + '/CORE.fMRI_cogcontrol.medaglia'\n",
    "path_PeriphData = path_Remotes + '/RSRCH.NMF_CogControl'\n",
    "path_InpData = path_PeriphData + '/e01-FuncNetw'\n",
    "path_ExpData = path_PeriphData + '/e02b-FuncSubg'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate List of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inp_fname = glob.glob('{}/*.npz'.format(path_InpData))\n",
    "\n",
    "expr_dict = {}\n",
    "for fname in inp_fname:\n",
    "    subj_id = fname.split('/')[-1].split('.')[0]\n",
    "    expr_id = fname.split('/')[-1].split('.')[1]\n",
    "    \n",
    "    try:\n",
    "        expr_dict[expr_id]['adj_files'].append(fname)\n",
    "    except:\n",
    "        expr_dict[expr_id] = {}\n",
    "        expr_dict[expr_id]['adj_files'] = []\n",
    "        expr_dict[expr_id]['adj_files'].append(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Construct Configuration Matrices\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove all existing output (retains pipe/pipeline definitions)\n",
    "rm_outp = glob.glob(\"{}/NMF_Optimization.CfgMatr.npz\".format(path_ExpData))\n",
    "\n",
    "for rm_type in [rm_outp]:\n",
    "    for path in rm_type:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            print(\"{} not found\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "key_ord = ['adj_rs_pos', 'adj_rs_neg',\n",
    "           'adj_lo_pos', 'adj_lo_neg',\n",
    "           'adj_hi_pos', 'adj_hi_neg']\n",
    "\n",
    "cfg_list = []\n",
    "cfg_key = []\n",
    "for expr_id in expr_dict.keys():    \n",
    "    for fname in expr_dict[expr_id]['adj_files']:\n",
    "        df = np.load(fname)\n",
    "        \n",
    "        for key in key_ord:\n",
    "            cfg_matr = convert_adj_matr_to_cfg_matr(df[key])\n",
    "            for cfg_vec in cfg_matr:\n",
    "                cfg_list.append(cfg_vec)\n",
    "                cfg_key.append('{}_{}'.format(key, expr_id))\n",
    "cfg_matr=np.array(cfg_list)\n",
    "cfg_key=np.array(cfg_key)\n",
    "\n",
    "np.savez('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData),\n",
    "         cfg_matr=cfg_matr,\n",
    "         cfg_key=cfg_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Optimize Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## NMF Cross-Validation Optimizaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load configuration matrix\n",
    "cfg_data = np.load('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData))\n",
    "cfg_matr = cfg_data['cfg_matr']\n",
    "\n",
    "# Set search params\n",
    "search_alpha = list(np.random.uniform(low=0.01, high=1.0, size=1000))\n",
    "search_beta = list(np.random.uniform(low=0.01, high=1.0, size=1000))\n",
    "search_rank = list(np.random.randint(low=2, high=61, size=1000))\n",
    "search_fold = 10\n",
    "\n",
    "# Cross-Validation Optimization\n",
    "str_path = '{}/NMF_Optimization.Error.txt'.format(path_ExpData)\n",
    "if os.path.exists(str_path):\n",
    "    os.remove(str_path)\n",
    "    \n",
    "param_list = Echobase.Network.Partitioning.Subgraph.optimize_nmf.cross_validation(\n",
    "    cfg_matr, search_alpha, search_beta, search_rank, search_fold, n_proc=14,\n",
    "    str_path=str_path)\n",
    "\n",
    "np.savez('{}/NMF_Optimization.Error.npz'.format(path_ExpData),\n",
    "         alpha=param_list['alpha'],\n",
    "         beta=param_list['beta'],\n",
    "         rank=param_list['rank'],\n",
    "         error=param_list['error'],\n",
    "         pct_sparse_subgraph=param_list['pct_sparse_subgraph'],\n",
    "         pct_sparse_coef=param_list['pct_sparse_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Quality Measures in Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt_dict = np.load('{}/NMF_Optimization.Error.npz'.format(path_ExpData), mmap_mode='r')\n",
    "#opt_params = Echobase.Network.Partitioning.Subgraph.optimize_nmf.min_crossval_param(dict(opt_dict))\n",
    "\n",
    "error_ix = np.flatnonzero(opt_dict['error'] < np.percentile(opt_dict['error'], 25))\n",
    "sparse_subg_ix = np.flatnonzero(opt_dict['pct_sparse_subgraph'] > np.percentile(opt_dict['pct_sparse_subgraph'], 75))\n",
    "sparse_coef_ix = np.flatnonzero(opt_dict['pct_sparse_coef'] > np.percentile(opt_dict['pct_sparse_coef'], 75))\n",
    "joint_ix = np.intersect1d(np.intersect1d(error_ix, sparse_subg_ix), sparse_coef_ix)\n",
    "\n",
    "opt_params = {}\n",
    "opt_params['rank'] = int(opt_dict['rank'][joint_ix].mean().round())\n",
    "opt_params['alpha'] = opt_dict['alpha'][joint_ix].mean()\n",
    "opt_params['beta'] = opt_dict['beta'][joint_ix].mean()\n",
    "print('Optimal Rank: {}'.format(opt_params['rank']))\n",
    "print('Optimal Alpha: {}'.format(opt_params['alpha']))\n",
    "print('Optimal Beta: {}'.format(opt_params['beta']))\n",
    "\n",
    "# Generate quality measure plots\n",
    "for qmeas in ['error', 'pct_sparse_subgraph', 'pct_sparse_coef']:\n",
    "    for param in ['rank', 'alpha', 'beta']:\n",
    "\n",
    "        ax_jp = sns.jointplot(opt_dict[param], opt_dict[qmeas], kind='kde', space=0, n_levels=5, shade_lowest=False)\n",
    "        ax = ax_jp.ax_joint\n",
    "        ax.plot([opt_params[param], opt_params[param]], \n",
    "                [ax.get_ylim()[0]*1.05, ax.get_ylim()[1]*0.95],\n",
    "                lw=1.0)\n",
    "\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.set_xlabel(param)\n",
    "        ax.set_ylabel(qmeas)\n",
    "        \n",
    "        #plt.savefig('./e02c-Figures/NMF_Optimization.{}.{}.svg'.format(param, qmeas))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "opt_dict.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Detect Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run Non-Negative Matrix Factorization Algorithm\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove all existing output (retains pipe/pipeline definitions)\n",
    "rm_outp = glob.glob(\"{}/*.subgraph_seed-*.npz\".format(path_ExpData))\n",
    "\n",
    "for rm_type in [rm_outp]:\n",
    "    for path in rm_type:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            print(\"{} not found\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param = {'rank': 51,\n",
    "         'alpha': 0.327,\n",
    "         'beta': 0.577}\n",
    "n_seed = 100\n",
    "\n",
    "from multiprocessing import Pool\n",
    "parallel_run = True\n",
    "\n",
    "# Generate a processing joblist\n",
    "cfg_matr_path = glob.glob(\"{}/NMF_Optimization.CfgMatr.npz\".format(path_ExpData))[0]\n",
    "proc_list = []\n",
    "for seed in xrange(n_seed):\n",
    "    proc_list.append({'path': cfg_matr_path,\n",
    "                      'param': param,\n",
    "                      'seed': seed+1})\n",
    "    \n",
    "# Setup helper function to map pipeline run\n",
    "def _nmf_helper(proc_item):\n",
    "    \n",
    "    # Load the file\n",
    "    #if os.path.exists(inp_path):\n",
    "    #    return 0\n",
    "    print(\" -- Processing Seed: {}\".format(proc_item['seed']))\n",
    "    data = np.load(proc_item['path'], mmap_mode='r')\n",
    "    \n",
    "    # Initialize the factors for NMF\n",
    "    fac_subnet = np.random.uniform(low=0, high=1.0,\n",
    "                                   size=(proc_item['param']['rank'],\n",
    "                                         data['cfg_matr'].shape[1]))\n",
    "    fac_coef = np.random.uniform(low=0, high=1.0,\n",
    "                                 size=(proc_item['param']['rank'],\n",
    "                                       data['cfg_matr'].shape[0]))\n",
    "\n",
    "    # Run NMF Algorithm\n",
    "    fac_subnet, fac_coef, err = nmf.snmf_bcd(\n",
    "        data['cfg_matr'],\n",
    "        alpha=proc_item['param']['alpha'],\n",
    "        beta=proc_item['param']['beta'],\n",
    "        fac_subnet_init=fac_subnet,\n",
    "        fac_coef_init=fac_coef,\n",
    "        max_iter=100, verbose=False)\n",
    "    \n",
    "    # Cache the NMF result\n",
    "    np.savez(\"{}/NMF_Optimization.subgraph_seed-{}.npz\".format(path_ExpData,\n",
    "                                                               proc_item['seed']),\n",
    "             fac_subnet=fac_subnet, fac_coef=fac_coef, err=err,\n",
    "             param=proc_item['param'], path=proc_item['path'])\n",
    "\n",
    "if parallel_run:\n",
    "    mp = Pool(10)\n",
    "    mp.map(_nmf_helper, proc_list)\n",
    "else:\n",
    "    map(_nmf_helper, proc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Consensus Clustering of Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seed_paths = glob.glob(\"{}/NMF_Optimization.subgraph_seed-*.npz\".format(path_ExpData))\n",
    "\n",
    "# Aggregate the estimated subgraphs of each seed\n",
    "fac_subnet_seeds = []\n",
    "for ii, path in enumerate(seed_paths):\n",
    "    data = np.load(path, mmap_mode='r')\n",
    "    fac_subnet = data['fac_subnet'][:, :]\n",
    "    data.close()\n",
    "\n",
    "    n_fac = fac_subnet.shape[0]\n",
    "    n_conn = fac_subnet.shape[1]\n",
    "\n",
    "    for iy in xrange(fac_subnet.shape[0]):\n",
    "        fac_subnet_seeds.append(fac_subnet[iy, :])\n",
    "fac_subnet_seeds = np.array(fac_subnet_seeds)\n",
    "\n",
    "n_obs = fac_subnet_seeds.shape[0]\n",
    "n_conn = fac_subnet_seeds.shape[1]\n",
    "\n",
    "# Consensus Subgraphs\n",
    "fac_cons_subnet, fac_cons_seeds, err = nmf.snmf_bcd(\n",
    "    fac_subnet_seeds,\n",
    "    alpha=0.0,\n",
    "    beta=0.0,\n",
    "    fac_subnet_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_conn)),\n",
    "    fac_coef_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_obs)),\n",
    "    max_iter=100, verbose=False)\n",
    "\n",
    "# Consensus Coefficients\n",
    "cfg_matr_path = glob.glob(\"{}/NMF_Optimization.CfgMatr.npz\".format(path_ExpData))[0]\n",
    "data_cfg = np.load(cfg_matr_path, mmap_mode='r')\n",
    "n_win = data_cfg['cfg_matr'].shape[0]\n",
    "fac_cons_subnet_2, fac_cons_coef_2, err = nmf.snmf_bcd(\n",
    "    data_cfg['cfg_matr'],\n",
    "    alpha=0.0,\n",
    "    beta=0.0,\n",
    "    fac_subnet_init=fac_cons_subnet,\n",
    "    fac_coef_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_win)),\n",
    "    max_iter=100, verbose=False)\n",
    "\n",
    "# Cache the Consensus NMF result\n",
    "np.savez(\"{}/NMF_Optimization.consensus_subgraph.npz\".format(path_ExpData),\n",
    "         fac_subnet=fac_cons_subnet_2, fac_coef=fac_cons_coef_2, err=err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Plot Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the consensus data\n",
    "data = np.load(\"{}/NMF_Optimization.consensus_subgraph.npz\".format(path_ExpData),\n",
    "               mmap_mode='r')\n",
    "fac_subnet = data['fac_subnet']\n",
    "fac_coef = data['fac_coef']\n",
    "\n",
    "# Normalize\n",
    "fac_subnet = fac_subnet / fac_subnet.max()\n",
    "fac_coef = fac_coef / fac_coef.max()\n",
    "\n",
    "n_fac = fac_subnet.shape[0]\n",
    "n_conn = fac_subnet.shape[1]\n",
    "n_win = fac_coef.shape[1]\n",
    "\n",
    "# Plot subgraph matrix\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "mat = ax.matshow(fac_subnet.T, aspect=n_fac/n_conn, cmap='rainbow', vmin=0, vmax=1)\n",
    "plt.colorbar(mat, ax=ax)\n",
    "\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "#ax.set_xticks(np.linspace(0, 80, 5))\n",
    "ax.set_ylabel('Functional Interactions')\n",
    "ax.set_xlabel('Subgraphs')\n",
    "\n",
    "plt.savefig('./e02b-Figures/Subgraph-Cfg_Matrix.svg')\n",
    "plt.close()      \n",
    "\n",
    "# Plot subgraph adjacency\n",
    "plt.figure()\n",
    "n_row = np.floor(np.sqrt(n_fac))\n",
    "n_col = np.ceil(n_fac / n_row)\n",
    "for ii, subg in enumerate(fac_subnet):\n",
    "    adj = convert_conn_vec_to_adj_matr(subg)\n",
    "\n",
    "    ax = plt.subplot(n_row, n_col, ii+1)\n",
    "    mat = ax.matshow(adj, cmap='rainbow', vmin=0, vmax=1)\n",
    "    #plt.colorbar(mat, ax=ax)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "plt.savefig('./e02b-Figures/Subgraph-Adj_Matrices.svg')\n",
    "plt.show()\n",
    "plt.close()      \n",
    "\n",
    "# Plot Coefficients\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "fac_coef = fac_coef.T\n",
    "norm_fac = fac_coef - fac_coef.mean(axis=0)\n",
    "for ff in xrange(n_fac):\n",
    "    ax.plot(ff + norm_fac[:, ff] / (3*np.std(norm_fac[:, ff])), color=[66/256., 152/256., 221./256])\n",
    "\n",
    "# Axis Settings\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_ylim([-1, n_fac+1])\n",
    "ax.set_ylabel('Subgraphs')\n",
    "ax.set_xlabel('Time Windows')\n",
    "\n",
    "plt.savefig('./e02b-Figures/Subgraph-Coefs.svg')\n",
    "plt.show()\n",
    "plt.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Subgraphs of Brain Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Subgraphs and Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Grab the subgraphs and expression from consensus NMF\n",
    "df_nmf = np.load(\"{}/NMF_Optimization.consensus_subgraph.npz\".format(path_ExpData),\n",
    "                 mmap_mode='r')\n",
    "fac_subnet = df_nmf['fac_subnet']\n",
    "fac_coef = df_nmf['fac_coef']\n",
    "n_fac = fac_subnet.shape[0]\n",
    "n_conn = fac_subnet.shape[1]\n",
    "n_node = np.int(np.ceil(np.sqrt(n_conn*2)))\n",
    "n_obs = fac_coef.shape[1]\n",
    "\n",
    "# Retrieve the configuration matrix\n",
    "# Get expression for: subgraphs, subjects, task conditions + pos/neg interactions, blocks\n",
    "path_cfg_expr = glob.glob('{}/NMF_Optimization.CfgMatr.npz'.format(path_ExpData))[0]\n",
    "df_cfg = np.load(path_cfg_expr, mmap_mode='r')\n",
    "cfg_key = df_cfg['cfg_key']\n",
    "key_type = np.unique(cfg_key)\n",
    "n_key = len(key_type)\n",
    "n_block = 6 \n",
    "n_subj = n_obs / (n_key*n_block)\n",
    "fac_coef_subj = np.zeros((n_fac, n_subj, n_key, n_block))\n",
    "for key_ii, key in enumerate(key_type):\n",
    "    key_ix = np.flatnonzero(cfg_key == key)\n",
    "    fac_coef_subj[:, :, key_ii, :] = fac_coef[:, key_ix].reshape(n_fac, n_subj, n_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Get the Lausanne Labels\n",
    "df_parcel = pd.read_csv('{}/LausanneScale125.csv'.format(path_CoreData))\n",
    "\n",
    "lausanne_lbl = []\n",
    "for lbl_id, lbl_roi, lbl_hemi in zip(df_parcel.Label_ID, df_parcel.ROI, df_parcel.Hemisphere):\n",
    "    roi_name = '{}_{}'.format(lbl_hemi, lbl_roi)\n",
    "    lausanne_lbl.append(roi_name)\n",
    "lausanne_lbl = np.array(lausanne_lbl)\n",
    "\n",
    "### Get the system assignments for each ROI\n",
    "df_sys = h5py.File('{}/sysInfo234.mat'.format(path_CoreData), 'r')\n",
    "\n",
    "system_lbl = [''.join(unichr(c) for c in df_sys[rr])\n",
    "              for rr in df_sys['sysInfo']['system'][0, :]]\n",
    "for ii in xrange(len(system_lbl), n_node):\n",
    "    system_lbl.append(u'cerebellum')\n",
    "system_lbl = np.array(system_lbl)\n",
    "\n",
    "system_name = np.unique(system_lbl)\n",
    "n_system = len(system_name)\n",
    "sys_triu_ix, sys_triu_iy = np.triu_indices(n_system, k=0)\n",
    "n_sys_conn = len(sys_triu_ix)\n",
    "\n",
    "df_sys.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Render brain systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from mayavi import mlab\n",
    "import nibabel as nib\n",
    "\n",
    "brain_system_pixmap = []\n",
    "\n",
    "sys_scalar = [5, 15, 2, 3, 4, 6, 8, 10, 9, 0, 18]\n",
    "view_angle = {'Sag_PA': [0.0, 90.0],\n",
    "              'Sag_AP': [180.0, 90.0]}\n",
    "\n",
    "# Get the pial surface recons\n",
    "pial_hemi = {'LH': {},\n",
    "             'RH': {}}\n",
    "pial_hemi['LH']['vert'], pial_hemi['LH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/lh.pial'.format(path_CoreData))\n",
    "pial_hemi['RH']['vert'], pial_hemi['RH']['tria'] = nib.freesurfer.io.read_geometry('{}/BrainRenderSubject15/surf/rh.pial'.format(path_CoreData))\n",
    "\n",
    "# Get the Lausanne label files for each ROI\n",
    "label_files = []\n",
    "for roi in lausanne_lbl:\n",
    "    hemi = roi.split('_')[0].lower()\n",
    "    \n",
    "    # Parse the atlas name and find the label file if it exists\n",
    "    if len(roi.split('_')) == 2:\n",
    "        lbl_file = ('%s.%s.label' % tuple(roi.split('_'))).lower()\n",
    "    elif len(roi.split('_')) == 3:\n",
    "        lbl_file = ('%s.%s_%s.label' % tuple(roi.split('_'))).lower()\n",
    "    else:\n",
    "        raise Exception\n",
    "    lbl_file = lbl_file.replace(' ', '')\n",
    "\n",
    "    label_files.append('{}/BrainRenderSubject15/label/regenerated_{}_125/{}'.format(path_CoreData, hemi, lbl_file))\n",
    "\n",
    "# Iterate over hemisphere of the pial surface\n",
    "for hemi in pial_hemi.keys():\n",
    "    n_vert = len(pial_hemi[hemi]['vert'])\n",
    "    \n",
    "    # Iterate over brain system\n",
    "    for sys_id, sys_lbl in enumerate(np.unique(system_lbl)):\n",
    "        print(sys_lbl)\n",
    "        sys_ix = np.flatnonzero(system_lbl == sys_lbl)\n",
    "        \n",
    "        # Find the label file for each ROI and get vertices\n",
    "        if sys_lbl == 'subcortical':\n",
    "            pial_scalars = sys_scalar[sys_id]*np.ones(n_vert)\n",
    "        else:\n",
    "            pial_scalars = 15*np.ones(n_vert)\n",
    "        for roi_ix, (roi, lbl_file) in enumerate(zip(lausanne_lbl, label_files)):\n",
    "            if roi.split('_')[0] != hemi:\n",
    "                continue\n",
    "\n",
    "            if not os.path.exists(lbl_file):\n",
    "                continue\n",
    "\n",
    "            # Load the file and add scalar to the vertices\n",
    "            parc_lbl = nib.freesurfer.io.read_label(lbl_file)                \n",
    "            if roi_ix in sys_ix:\n",
    "                pial_scalars[parc_lbl] = sys_scalar[sys_id]\n",
    "            else:\n",
    "                pial_scalars[parc_lbl] = 15               \n",
    "            \n",
    "        # Plot the colored Brain System\n",
    "        fig = mlab.figure(bgcolor=(1.0, 1.0, 1.0))\n",
    "        src = mlab.pipeline.triangular_mesh_source(pial_hemi[hemi]['vert'][:,0],\n",
    "                                                   pial_hemi[hemi]['vert'][:,1],\n",
    "                                                   pial_hemi[hemi]['vert'][:,2],\n",
    "                                                   pial_hemi[hemi]['tria'], scalars=pial_scalars, opacity=0.75, figure=fig)\n",
    "        norms = mlab.pipeline.poly_data_normals(src, figure=fig)\n",
    "        norms.filter.splitting = False\n",
    "        surf = mlab.pipeline.surface(norms, figure=fig)\n",
    "        surf.parent.scalar_lut_manager.set(lut_mode='Vega20', data_range=[0, 19], use_default_range=False)\n",
    "        lut = surf.module_manager.scalar_lut_manager.lut.table.to_array()\n",
    "        lut[188:213, 3] = 220\n",
    "        surf.module_manager.scalar_lut_manager.lut.table = lut\n",
    "        \n",
    "        # Rotate the view and save a screenshot\n",
    "        pixmap = {}\n",
    "        for ang in view_angle.keys():\n",
    "            mlab.view(azimuth=view_angle[ang][0],\n",
    "                      elevation=view_angle[ang][1])\n",
    "            #mlab.savefig('./e02b-Figures/Brain_System-{}_{}.{}.png'.format(hemi, sys_lbl, ang))\n",
    "            pixmap['{}_{}'.format(hemi, ang)] = mlab.screenshot(mode='rgba')\n",
    "        brain_system_pixmap.append(pixmap)\n",
    "        mlab.close(all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Convert ROI Subgraphs to Brain System Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_perm = 10000\n",
    "alpha = 0.05 / n_sys_conn\n",
    "\n",
    "system_subgraph = []\n",
    "for fac_i, subg in enumerate(fac_subnet):\n",
    "    print('Processed: {} of {}'.format(fac_i+1, len(fac_subnet)))\n",
    "    \n",
    "    adj = convert_conn_vec_to_adj_matr(subg)\n",
    "    \n",
    "    temp_system_subg = np.zeros(n_sys_conn)\n",
    "    for tr_ii, (tr_ix, tr_iy) in enumerate(zip(sys_triu_ix, sys_triu_iy)):        \n",
    "        ij_sys_ix = np.flatnonzero(system_lbl == system_name[tr_ix])\n",
    "        ik_sys_ix = np.flatnonzero(system_lbl == system_name[tr_iy])  \n",
    "        \n",
    "        ij_ik_sys_ix, ik_ij_sys_ix = np.meshgrid(ij_sys_ix, ik_sys_ix)\n",
    "        mean_conn = adj[ij_ik_sys_ix, ik_ij_sys_ix].mean()\n",
    "        \n",
    "        temp_system_subg[tr_ii] = mean_conn\n",
    "\n",
    "        \n",
    "    null_system_subg = np.zeros((n_perm, n_sys_conn))\n",
    "    for perm_i in xrange(n_perm):\n",
    "        for tr_ii, (tr_ix, tr_iy) in enumerate(zip(sys_triu_ix, sys_triu_iy)):\n",
    "            system_lbl_perm = np.random.permutation(system_lbl)\n",
    "            ij_sys_ix = np.flatnonzero(system_lbl_perm == system_name[tr_ix])\n",
    "            ik_sys_ix = np.flatnonzero(system_lbl_perm == system_name[tr_iy])  \n",
    "\n",
    "            ij_ik_sys_ix, ik_ij_sys_ix = np.meshgrid(ij_sys_ix, ik_sys_ix)\n",
    "            mean_conn = adj[ij_ik_sys_ix, ik_ij_sys_ix].mean()\n",
    "\n",
    "            null_system_subg[perm_i, tr_ii] = mean_conn\n",
    "        \n",
    "    pval_system_subg = np.mean(null_system_subg > temp_system_subg, axis=0)\n",
    "    filt_system_subg = pval_system_subg.copy()\n",
    "    filt_system_subg[pval_system_subg < alpha] = False\n",
    "    filt_system_subg[pval_system_subg >= alpha] = True\n",
    "    \n",
    "    filt_ix = np.nonzero(filt_system_subg)\n",
    "    thrsh_system_subg = temp_system_subg.copy()\n",
    "    thrsh_system_subg[filt_ix] = 0\n",
    "    \n",
    "    temp_system_adj = np.zeros((n_system, n_system))\n",
    "    temp_system_adj[sys_triu_ix, sys_triu_iy] = temp_system_subg\n",
    "    temp_system_adj += np.triu(temp_system_adj, k=1).T\n",
    "\n",
    "    thrsh_system_adj = np.zeros((n_system, n_system))\n",
    "    thrsh_system_adj[sys_triu_ix, sys_triu_iy] = thrsh_system_subg\n",
    "    thrsh_system_adj += np.triu(thrsh_system_adj, k=1).T\n",
    "    \n",
    "    \n",
    "    # Format the system string output\n",
    "    system_str = '\\n'\n",
    "    system_pair = []\n",
    "    for sys_sig_ix in np.flatnonzero(filt_system_subg == 0):\n",
    "        system_pair.append((system_name[sys_triu_ix[sys_sig_ix]],\n",
    "                            system_name[sys_triu_iy[sys_sig_ix]]))\n",
    "        system_str += '%20s <--> %-20s\\n' % (system_pair[-1][0],\n",
    "                                             system_pair[-1][1])\n",
    "    \n",
    "    # Generate subgraph dictionary\n",
    "    system_subgraph.append({'Subgraph_ID': fac_i+1,\n",
    "                            'filt_system_subg': thrsh_system_adj,\n",
    "                            'system_pairs': system_pair,\n",
    "                            'system_string': system_str,\n",
    "                            'expr_coef': fac_coef_subj[fac_i, ...]})\n",
    "\n",
    "np.savez('{}/Subgraph.11System.npz'.format(path_ExpData),\n",
    "         system_subgraph=system_subgraph,\n",
    "         system_labels=system_lbl,\n",
    "         system_names=system_name,\n",
    "         lausanne_labels=lausanne_lbl,\n",
    "         task_key=key_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Filter Subgraphs with Sparse Expression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load in the System-Level subgraph data\n",
    "df_subg = np.load('{}/Subgraph.11System.npz'.format(path_ExpData))\n",
    "sys_subgraph = df_subg['system_subgraph']\n",
    "n_fac = len(sys_subgraph)\n",
    "\n",
    "pct_sparse_mean = []\n",
    "pct_sparse_std = []\n",
    "for fac_ix in xrange(n_fac):\n",
    "    fac_coef = sys_subgraph[fac_ix]['expr_coef']\n",
    "    pct_sparse = (fac_coef == 0).reshape(fac_coef.shape[0], -1).mean(axis=-1)\n",
    "    pct_sparse_mean.append(pct_sparse.mean())\n",
    "    pct_sparse_std.append(pct_sparse.std() / np.sqrt(fac_coef.shape[0]))\n",
    "pct_sparse_mean = np.array(pct_sparse_mean)\n",
    "pct_sparse_std = np.array(pct_sparse_std)\n",
    "\n",
    "# Find the sparsity order\n",
    "fac_ord_ix = np.argsort(pct_sparse_mean)\n",
    "fac_thresh = 12\n",
    "\n",
    "# Plot the distribution of temporal sparsity over subgraphs\n",
    "% matplotlib inline\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(np.arange(n_fac), pct_sparse_mean[fac_ord_ix], 'k')\n",
    "ax.fill_between(np.arange(n_fac),\n",
    "                pct_sparse_mean[fac_ord_ix]-pct_sparse_std[fac_ord_ix],\n",
    "                pct_sparse_mean[fac_ord_ix]+pct_sparse_std[fac_ord_ix])\n",
    "ax.vlines(fac_thresh, 0, 1, 'r')\n",
    "\n",
    "ax.set_xlim([-0.5, n_fac-0.5])        \n",
    "plt.xticks(np.arange(0, n_fac+1, 6),\n",
    "           np.arange(0, n_fac+1, 6))\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_xlabel('Ranked Subgraphs')\n",
    "\n",
    "ax.set_ylim([0, 1])        \n",
    "ax.set_yticks(np.linspace(0, 1.0, 5))\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.set_ylabel('Percent Sparse Coefficients')\n",
    "plt.savefig('./e02b-Figures/Sparse_Coefs.svg')\n",
    "plt.show()\n",
    "\n",
    "sys_subgraph = sys_subgraph[fac_ord_ix[:fac_thresh]]\n",
    "\n",
    "np.savez('{}/Subgraph.11System.Filtered.npz'.format(path_ExpData),\n",
    "         system_subgraph=sys_subgraph,\n",
    "         system_labels=df_subg['system_labels'],\n",
    "         system_names=df_subg['system_names'],\n",
    "         lausanne_labels=df_subg['lausanne_labels'],\n",
    "         task_key=df_subg['task_key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plot all Brain System Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "df_subg = np.load('{}/Subgraph.11System.Filtered.npz'.format(path_ExpData))\n",
    "sys_subgraph = df_subg['system_subgraph']\n",
    "\n",
    "\n",
    "# Plot each result\n",
    "for fac_ix in xrange(len(sys_subgraph)):\n",
    "    f_sys_subgraph = sys_subgraph[fac_ix]\n",
    "    sys_subg = f_sys_subgraph['filt_system_subg']\n",
    "    subg_degr = np.sum(sys_subg, axis=0)\n",
    "    good_sys = np.flatnonzero(subg_degr != 0)\n",
    "    \n",
    "    sys_lbl_condense = np.unique(df_subg['system_labels'])[good_sys]\n",
    "    sys_subg_condense = sys_subg[good_sys, :][:, good_sys]\n",
    "    nnz_min = np.unique(sys_subg_condense)[1]\n",
    "    nnz_max = np.unique(sys_subg_condense)[-1]\n",
    "    edge_wgt = (sys_subg_condense - nnz_min + 10**(-3.5)) / (nnz_max - nnz_min)\n",
    "    edge_wgt[edge_wgt < 0] = 0\n",
    "    \n",
    "    print('\\n\\n\\n')\n",
    "    print('****************************** Subgraph {} ******************************'.format(fac_ix+1))    \n",
    "    #print(f_sys_subgraph['system_string'])\n",
    "    \n",
    "    plt.close()\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    mds = manifold.MDS(n_components=2, max_iter=3000, eps=1e-9,\n",
    "                       dissimilarity=\"precomputed\", n_jobs=1)\n",
    "    pos = mds.fit(1 - sys_subg_condense).embedding_\n",
    "            \n",
    "    # Plot subgraph edges\n",
    "    triu_ix, triu_iy = np.triu_indices_from(sys_subg_condense)\n",
    "    for ix, iy in zip(triu_ix, triu_iy):\n",
    "        if sys_subg_condense[ix, iy] != 0:\n",
    "            ax.plot([pos[ix, 0], pos[iy, 0]],\n",
    "                    [pos[ix, 1], pos[iy, 1]],\n",
    "                    color=[0.2, 0.2, 0.2],\n",
    "                    lw=2*edge_wgt[ix, iy])\n",
    "    \n",
    "    # Plot subgraph positions\n",
    "    for subg_id, subg in enumerate(pos):\n",
    "        # Get the brain system icon\n",
    "        if sys_lbl_condense[subg_id] in ['subcortical', 'default_mode', ]:\n",
    "            arr = brain_system_pixmap[good_sys[subg_id]]['RH_Sag_AP']\n",
    "        else:\n",
    "            arr = brain_system_pixmap[good_sys[subg_id]]['RH_Sag_PA']\n",
    "        \n",
    "        asp = arr.shape[0] / arr.shape[1]\n",
    "        shift_ltd = 0.3\n",
    "        shift_lng = shift_ltd*asp\n",
    "\n",
    "        my_cmap = plt.cm.get_cmap()\n",
    "        my_cmap.set_bad(alpha=0)\n",
    "        ax.imshow(arr, aspect='equal', extent=(subg[0]-shift_ltd, \n",
    "                                               subg[0]+shift_ltd,\n",
    "                                               subg[1]-shift_lng,\n",
    "                                               subg[1]+shift_lng),\n",
    "                  cmap=my_cmap,\n",
    "                  zorder=30)\n",
    "    \n",
    "    xmin, ymin = pos.min(axis=0)-shift_ltd\n",
    "    xmax, ymax = pos.max(axis=0)+shift_ltd   \n",
    "    ax.set_xlim([xmin, xmax])\n",
    "    ax.set_ylim([ymin, ymax])\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    plt.savefig('./e02b-Figures/Spatial_Subgraph.{}.svg'.format(fac_ix+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circle Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "fig, ax = mne.viz.plot_connectivity_circle(con=fac_subnet[14, :],\n",
    "                                           node_names=list(lausanne_lbl[:-1]),\n",
    "                                           indices=tuple(np.triu_indices(261, k=1)),\n",
    "                                           n_lines=1000, linewidth=1.0,\n",
    "                                           fontsize_names=5,\n",
    "                                           facecolor='white', textcolor='black',\n",
    "                                           colorbar=False,\n",
    "                                           fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "897px",
    "left": "0px",
    "right": "1707px",
    "top": "106px",
    "width": "329px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
